{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ae88ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from torchvision.transforms import GaussianBlur\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import cv2\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont, ImageFilter\n",
    "current_dir = os.getcwd()\n",
    "from pathlib import Path\n",
    "# 현재 작업 경로 가져오기\n",
    "current_dir = Path.cwd()\n",
    "# 상위 폴더 가져오기\n",
    "parent_dir = current_dir.parent\n",
    "# sys.path에 추가 (문자열로 변환 필요)\n",
    "sys.path.append(str(parent_dir))\n",
    "print(f\"Added to sys.path: {parent_dir}\")\n",
    "# 경로 설정이 완료된 후 import 해야 합니다.\n",
    "from VLM_model_dot_relative import QwenVLModel, MetricsTracker\n",
    "from file_managing import (\n",
    "    load_selected_samples,\n",
    "    get_actual_path,\n",
    "    get_gt_path,\n",
    ")\n",
    "from config import AGD20K_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2201a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ground_truth(gt_path):\n",
    "    \"\"\"\n",
    "    Load and process ground truth image\n",
    "    Args:\n",
    "        gt_path (str): Path to the ground truth image\n",
    "    Returns:\n",
    "        torch.Tensor: Processed ground truth tensor normalized to [0, 1]\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the ground truth image\n",
    "        gt_img = Image.open(gt_path)\n",
    "        \n",
    "        # Convert to grayscale if image is RGB\n",
    "        if gt_img.mode == 'RGB':\n",
    "            gt_img = gt_img.convert('L')\n",
    "        \n",
    "        # Convert to tensor\n",
    "        gt_tensor = transforms.ToTensor()(gt_img).squeeze(0)\n",
    "        \n",
    "        # Normalize to [0, 1]\n",
    "        if gt_tensor.max() > 0:\n",
    "            gt_tensor = (gt_tensor - gt_tensor.min()) / (gt_tensor.max() - gt_tensor.min())\n",
    "        \n",
    "        return gt_tensor\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Failed to load ground truth image: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def create_heatmap_from_dots_v2(image_size, dots):\n",
    "    \"\"\"\n",
    "    Create a heatmap from dot coordinates using Gaussian kernels with dynamic sigma.\n",
    "    Args:\n",
    "        image_size (tuple): Size of the image (height, width)\n",
    "        dots (list): List of dot coordinates [x, y]\n",
    "    Returns:\n",
    "        torch.Tensor: Heatmap tensor\n",
    "    \"\"\"\n",
    "    height, width = image_size\n",
    "\n",
    "    # Dynamic sigma based on image dimensions (simple linear scaling)\n",
    "    base_size = 640  # Reference size\n",
    "    base_sigma = 60\n",
    "    scale_factor = ((height + width) / 2) / base_size\n",
    "    sigma = int( base_sigma * scale_factor)\n",
    "    heatmap = torch.zeros((height, width))\n",
    "    for dot in dots:\n",
    "        # Convert coordinates to integers\n",
    "        x, y = map(int, dot)\n",
    "        # Ensure coordinates are within image bounds\n",
    "        x = max(0, min(x, width-1))\n",
    "        y = max(0, min(y, height-1))\n",
    "        # Create coordinate grids for the entire image\n",
    "        y_grid, x_grid = torch.meshgrid(\n",
    "            torch.arange(height, dtype=torch.float32),\n",
    "            torch.arange(width, dtype=torch.float32),\n",
    "            indexing='ij'\n",
    "        )\n",
    "        # Calculate Gaussian values centered at the dot\n",
    "        gaussian = torch.exp(\n",
    "            -((x_grid - x)**2 + (y_grid - y)**2) / (2 * sigma**2)\n",
    "        )\n",
    "        # Add to heatmap\n",
    "        heatmap += gaussian\n",
    "    # Normalize heatmap\n",
    "    if heatmap.max() > 0:\n",
    "        heatmap = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min() + 1e-10)\n",
    "    return heatmap\n",
    "\n",
    "def draw_dots_on_image( image_path, dots, gt_path, action, exo_path=None, exo_type=None, output_path=None):\n",
    "    \"\"\"\n",
    "    Draw dots and create heatmap, save results side by side with GT\n",
    "    Args:\n",
    "        image_path (str): Path to the ego image\n",
    "        dots (list): List of dot coordinates [x, y]\n",
    "        gt_path (str): Path to the ground truth image\n",
    "        action (str): Action name for the filename\n",
    "        exo_path (str, optional): Path to the exo image (if provided, creates 3x2 layout)\n",
    "        exo_type (str, optional): Type of exo image ('random' or 'selected')\n",
    "        output_path (str, optional): Path to save the result image\n",
    "    Returns:\n",
    "        str: Path to the saved image\n",
    "        torch.Tensor: Generated heatmap for metric calculation\n",
    "    \"\"\"\n",
    "    # Load the ego image\n",
    "    ego_img = Image.open(image_path)\n",
    "    if exo_path is not None:\n",
    "        exo_file_name = os.path.basename(exo_path)\n",
    "    width, height = ego_img.size\n",
    "    \n",
    "    # Load exo image if provided\n",
    "    exo_img = None\n",
    "    if exo_path:\n",
    "        exo_img = Image.open(exo_path)\n",
    "    \n",
    "    # Create heatmap from dots\n",
    "    heatmap_tensor = create_heatmap_from_dots_v2((height, width), dots)\n",
    "    \n",
    "    # Convert heatmap to RGB image\n",
    "    heatmap_img = transforms.ToPILImage()(heatmap_tensor.unsqueeze(0).repeat(3, 1, 1))\n",
    "    \n",
    "    # Create a copy for dot drawing\n",
    "    dot_img = draw_dots_on_single_image(ego_img, dots, color='red', radius=15)\n",
    "    \n",
    "    # Determine layout based on image aspect ratio\n",
    "    aspect_ratio = width / height\n",
    "    \n",
    "    # For very wide images (aspect ratio > 2), adjust font size based on width\n",
    "    if aspect_ratio > 2:\n",
    "        font_size = min(50, width // 12)  # Larger font for wide images\n",
    "        header_height = 110  # Increased header height\n",
    "        spacing = 30  # Normal spacing\n",
    "    elif aspect_ratio > 1.5:  # For moderately wide images\n",
    "        font_size = min(55, width // 10)  # Larger font for moderately wide images\n",
    "        header_height = 120  # Increased header height\n",
    "        spacing = 35  # Slightly increased spacing\n",
    "    else:\n",
    "        font_size = max(60, width // 8)  # Largest font size for normal images\n",
    "        header_height = 130  # Normal header height\n",
    "        spacing = 40  # Normal spacing\n",
    "    \n",
    "    # Create a new image with 3x2 layout\n",
    "    combined_width = width * 3\n",
    "    combined_height = height * 2 + header_height * 2 + spacing * 3 + 40  # Dynamic height\n",
    "    combined_img = Image.new('RGB', (combined_width, combined_height), 'white')\n",
    "    \n",
    "    # Try to load fonts (size proportional to image width and aspect ratio)\n",
    "    try:\n",
    "        # Try to load a font that supports Korean\n",
    "        font = ImageFont.truetype(\"/usr/share/fonts/truetype/nanum/NanumGothic.ttf\", font_size)\n",
    "    except:\n",
    "        try:\n",
    "            # Fallback to DejaVu font\n",
    "            font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\", font_size)\n",
    "        except:\n",
    "            # Last resort: default font\n",
    "            font = ImageFont.load_default()\n",
    "\n",
    "    # Get file names\n",
    "    ego_filename = os.path.basename(image_path)\n",
    "    gt_filename = os.path.basename(gt_path) if gt_path else \"No GT\"\n",
    "    \n",
    "    # Draw file names and titles for 3x2 layout\n",
    "    draw = ImageDraw.Draw(combined_img)\n",
    "    \n",
    "    # Configure headers based on whether exo image is provided\n",
    "    if exo_img:\n",
    "        exo_filename = os.path.basename(exo_path)\n",
    "        # Top row headers for exo version\n",
    "        top_headers = [\n",
    "            (\"Ego\", ego_filename),\n",
    "            (\"Exo\", exo_filename),\n",
    "            (\"\", \"\")  # Empty space\n",
    "        ]\n",
    "    else:\n",
    "        # Top row headers for ego only version\n",
    "        top_headers = [\n",
    "            (\"Original\", ego_filename),\n",
    "            (\"\", \"\"),  # Empty space\n",
    "            (\"\", \"\")   # Empty space\n",
    "        ]\n",
    "    \n",
    "    # Bottom row headers (same for both versions)\n",
    "    bottom_headers = [\n",
    "        (\"Dots\", action+\"_\"+ego_filename),\n",
    "        (\"Heatmap\", action+\"_\"+ ego_filename),\n",
    "        (\"GT\", action+\"_\"+gt_filename)\n",
    "    ]\n",
    "    \n",
    "    # Draw top row headers with background\n",
    "    for idx, (title, filename) in enumerate(top_headers):\n",
    "        if title:  # Only draw if not empty\n",
    "            section_width = width\n",
    "            section_x = idx * section_width\n",
    "            \n",
    "            # Draw white background for text area\n",
    "            draw.rectangle([section_x, 0, section_x + section_width, header_height], fill='white', outline='lightgray')\n",
    "            \n",
    "            # Draw title\n",
    "            title_width = draw.textlength(title, font=font)\n",
    "            title_x = section_x + (section_width - title_width) // 2\n",
    "            draw.text((title_x, 5), title, fill='black', font=font)\n",
    "            \n",
    "            # Draw filename (truncate if too long)\n",
    "            max_filename_width = section_width - 20\n",
    "            filename_truncated = filename\n",
    "            while draw.textlength(filename_truncated + \"...\", font=font) > max_filename_width and len(filename_truncated) > 0:\n",
    "                filename_truncated = filename_truncated[:-1]\n",
    "            if filename_truncated != filename:\n",
    "                filename_truncated += \"...\"\n",
    "            \n",
    "            filename_width = draw.textlength(filename_truncated, font=font)\n",
    "            filename_x = section_x + (section_width - filename_width) // 2\n",
    "            draw.text((filename_x, header_height // 2 + 5), filename_truncated, fill='black', font=font)\n",
    "    \n",
    "    # Draw bottom row headers with background\n",
    "    for idx, (title, filename) in enumerate(bottom_headers):\n",
    "        section_width = width\n",
    "        section_x = idx * section_width\n",
    "        section_y = height + header_height + spacing  # Position below first row\n",
    "        \n",
    "        # Draw white background for text area\n",
    "        draw.rectangle([section_x, section_y - 10, section_x + section_width, section_y + header_height], fill='white', outline='lightgray')\n",
    "        \n",
    "        # Draw title\n",
    "        title_width = draw.textlength(title, font=font)\n",
    "        title_x = section_x + (section_width - title_width) // 2\n",
    "        draw.text((title_x, section_y), title, fill='black', font=font)\n",
    "        \n",
    "        # Draw filename (truncate if too long)\n",
    "        max_filename_width = section_width - 20\n",
    "        filename_truncated = filename\n",
    "        while draw.textlength(filename_truncated + \"...\", font=font) > max_filename_width and len(filename_truncated) > 0:\n",
    "            filename_truncated = filename_truncated[:-1]\n",
    "        if filename_truncated != filename:\n",
    "            filename_truncated += \"...\"\n",
    "        \n",
    "        filename_width = draw.textlength(filename_truncated, font=font)\n",
    "        filename_x = section_x + (section_width - filename_width) // 2\n",
    "        draw.text((filename_x, section_y + header_height // 2), filename_truncated, fill='black', font=font)\n",
    "    \n",
    "    # Paste images in 3x2 layout\n",
    "    # Top row: Ego image and optionally Exo image\n",
    "    top_image_y = header_height + spacing\n",
    "    combined_img.paste(ego_img, (0, top_image_y))  # Ego\n",
    "    if exo_img:\n",
    "        combined_img.paste(exo_img, (width, top_image_y))  # Exo\n",
    "    \n",
    "    # Bottom row: Dots, Heatmap, GT\n",
    "    bottom_image_y = height + header_height * 2 + spacing * 2\n",
    "    combined_img.paste(dot_img, (0, bottom_image_y))  # Image with dots\n",
    "    combined_img.paste(heatmap_img, (width, bottom_image_y))  # Heatmap\n",
    "    \n",
    "    # Add GT image and calculate metrics\n",
    "    gt_map = load_ground_truth(gt_path)\n",
    "    metrics_text = \"No GT provided\"\n",
    "    \n",
    "    if gt_map is not None:\n",
    "        if isinstance(gt_map, torch.Tensor):\n",
    "            gt_img = transforms.ToPILImage()(gt_map.unsqueeze(0).repeat(3, 1, 1))\n",
    "        else:\n",
    "            gt_map_tensor = torch.tensor(gt_map)\n",
    "            gt_img = transforms.ToPILImage()(gt_map_tensor.unsqueeze(0).repeat(3, 1, 1))\n",
    "        combined_img.paste(gt_img, (width * 2, bottom_image_y))  # GT heatmap\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics = calculate_metrics(heatmap_tensor, gt_map)\n",
    "        metrics_text = f\"KLD: {metrics['KLD']:.4f} | SIM: {metrics['SIM']:.4f} | NSS: {metrics['NSS']:.4f}\"\n",
    "    else:\n",
    "        # If no GT provided, create blank white image\n",
    "        blank_img = Image.new('RGB', (width, height), 'white')\n",
    "        combined_img.paste(blank_img, (width * 2, bottom_image_y))\n",
    "        metrics_text = \"ERRRR\"\n",
    "    \n",
    "    # Draw metrics text at the bottom with background\n",
    "    text_width = draw.textlength(metrics_text, font=font)\n",
    "    text_x = (combined_width - text_width) // 2\n",
    "    text_y = bottom_image_y + height + spacing\n",
    "    \n",
    "    # Draw white background for metrics text\n",
    "    padding = 10\n",
    "    draw.rectangle([text_x - padding, text_y - padding, \n",
    "                    text_x + text_width + padding, text_y + font_size + padding], \n",
    "                    fill='white', outline='gray')\n",
    "    \n",
    "    draw.text((text_x, text_y), metrics_text, fill='black', font=font)\n",
    "    \n",
    "    # Create res_images directory if it doesn't exist\n",
    "    script_dir = os.path.dirname(os.path.abspath(current_dir ))\n",
    "    if exo_type is None:\n",
    "        res_dir = os.path.join(script_dir, f'dot_images')\n",
    "        os.makedirs(res_dir, exist_ok=True)\n",
    "        os.makedirs(os.path.join(res_dir, \"with_exo\"), exist_ok=True)\n",
    "        os.makedirs(os.path.join(res_dir, \"only_ego\"), exist_ok=True)\n",
    "    else:\n",
    "        res_dir = os.path.join(script_dir, f'dot_images_{exo_type}')\n",
    "        os.makedirs(res_dir, exist_ok=True)\n",
    "        os.makedirs(os.path.join(res_dir, \"with_exo\"), exist_ok=True)\n",
    "        os.makedirs(os.path.join(res_dir, f\"{exo_type}\"), exist_ok=True)\n",
    "        os.makedirs(os.path.join(res_dir, \"only_ego\"), exist_ok=True)            \n",
    "        \n",
    "    # Generate output path if not provided\n",
    "    if output_path is None:\n",
    "        base_name = os.path.splitext(ego_filename)[0]\n",
    "        ext = os.path.splitext(ego_filename)[1]\n",
    "        if exo_img and exo_type:\n",
    "            # Format: skis_002829_jump_exo_random.jpg or skis_002829_jump_exo_selected.jpg\n",
    "            output_filename = f\"{base_name}_{action}_exo_{exo_type}{ext}\"\n",
    "            output_path = os.path.join(res_dir, f\"with_exo/{output_filename}\")\n",
    "        elif exo_img:\n",
    "            # Fallback if exo_type not specified\n",
    "            output_filename = f\"{base_name}_{action}_exo_{exo_file_name}\"\n",
    "            output_path = os.path.join(res_dir, f\"with_exo/{output_filename}\")\n",
    "        elif exo_type is not None:\n",
    "            output_filename = f\"{base_name}_{action}_exo_{exo_type}{ext}\"\n",
    "            output_path = os.path.join(res_dir, f\"{exo_type}/{output_filename}\")\n",
    "        else:\n",
    "            # Format: skis_002829_jump.jpg\n",
    "            output_filename = f\"{base_name}_{action}{ext}\"\n",
    "            output_path = os.path.join(res_dir, f\"only_ego/{output_filename}\")\n",
    "    \n",
    "    # Save the combined image\n",
    "    combined_img.save(output_path)\n",
    "    # print(f\"✅ Saved comparison image with heatmap and GT: {output_path}\")\n",
    "    \n",
    "    return output_path, heatmap_tensor\n",
    "\n",
    "def draw_dots_on_single_image( image, dots, color='red', radius=15):\n",
    "    \"\"\"\n",
    "    Draw dots on an image\n",
    "    Args:\n",
    "        image (PIL.Image): Image to draw on\n",
    "        dots (list): List of dot coordinates [x, y]\n",
    "        color (str): Color of the dots\n",
    "        radius (int): Radius of the dots\n",
    "    Returns:\n",
    "        PIL.Image: Image with dots drawn\n",
    "    \"\"\"\n",
    "    img_copy = image.copy()\n",
    "    draw = ImageDraw.Draw(img_copy)\n",
    "    \n",
    "    for dot in dots:\n",
    "        x, y = map(int, dot)\n",
    "        # Draw circle\n",
    "        draw.ellipse([x-radius, y-radius, x+radius, y+radius], \n",
    "                    fill=color, outline=color)\n",
    "    \n",
    "    return img_copy\n",
    "\n",
    "\n",
    "def calculate_metrics(pred_heatmap, gt_map):\n",
    "    \"\"\"\n",
    "    Calculate comparison metrics between predicted heatmap and GT (following original metric.py)\n",
    "    Args:\n",
    "        pred_heatmap (torch.Tensor): Predicted heatmap\n",
    "        gt_map (torch.Tensor): Ground truth map\n",
    "    Returns:\n",
    "        dict: Dictionary containing KLD, SIM, and NSS metrics\n",
    "    \"\"\"\n",
    "    # Ensure inputs are proper tensors\n",
    "    if not isinstance(pred_heatmap, torch.Tensor):\n",
    "        pred_heatmap = torch.tensor(pred_heatmap)\n",
    "    if not isinstance(gt_map, torch.Tensor):\n",
    "        gt_map = torch.tensor(gt_map)\n",
    "    \n",
    "    # Flatten tensors and add batch dimension for compatibility\n",
    "    pred = pred_heatmap.flatten().float().unsqueeze(0)  # [1, H*W]\n",
    "    gt = gt_map.flatten().float().unsqueeze(0)          # [1, H*W]\n",
    "    \n",
    "    eps = 1e-10\n",
    "    \n",
    "    # Calculate KLD following original implementation\n",
    "    # Normalize to probability distributions\n",
    "    pred_norm = pred / pred.sum(dim=1, keepdim=True)\n",
    "    gt_norm = gt / gt.sum(dim=1, keepdim=True)\n",
    "    pred_norm += eps\n",
    "    kld = F.kl_div(pred_norm.log(), gt_norm, reduction=\"batchmean\").item()\n",
    "    \n",
    "    # Calculate SIM following original implementation\n",
    "    pred_sim = pred / pred.sum(dim=1, keepdim=True)\n",
    "    gt_sim = gt / gt.sum(dim=1, keepdim=True)\n",
    "    sim = torch.minimum(pred_sim, gt_sim).sum().item() / len(pred_sim)\n",
    "    \n",
    "    # Calculate NSS following original implementation\n",
    "    # First normalize by max values\n",
    "    pred_nss = pred / pred.max(dim=1, keepdim=True).values\n",
    "    gt_nss = gt / gt.max(dim=1, keepdim=True).values\n",
    "    \n",
    "    # Calculate z-score for prediction\n",
    "    std = pred_nss.std(dim=1, keepdim=True)\n",
    "    u = pred_nss.mean(dim=1, keepdim=True)\n",
    "    smap = (pred_nss - u) / (std + eps)\n",
    "    \n",
    "    # Create fixation map from GT\n",
    "    fixation_map = (gt_nss - torch.min(gt_nss, dim=1, keepdim=True).values) / (\n",
    "        torch.max(gt_nss, dim=1, keepdim=True).values - torch.min(gt_nss, dim=1, keepdim=True).values + eps)\n",
    "    fixation_map = (fixation_map >= 0.1).float()\n",
    "    \n",
    "    # Calculate NSS\n",
    "    nss_values = smap * fixation_map\n",
    "    nss = nss_values.sum(dim=1) / (fixation_map.sum(dim=1) + eps)\n",
    "    nss = nss.mean().item()\n",
    "    \n",
    "    return {\n",
    "        'KLD': kld,\n",
    "        'SIM': sim,\n",
    "        'NSS': nss\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e768f374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "      <th>object</th>\n",
       "      <th>filename</th>\n",
       "      <th>dots</th>\n",
       "      <th>veri_result</th>\n",
       "      <th>veri_reason</th>\n",
       "      <th>final_dot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jump</td>\n",
       "      <td>skis</td>\n",
       "      <td>skis_002829.jpg</td>\n",
       "      <td>[[280, 490], [720, 490], [280, 900], [720, 900]]</td>\n",
       "      <td>[Fail, Fail, Fail, Fail]</td>\n",
       "      <td>[The query point (280,490) is on the upper par...</td>\n",
       "      <td>[[280, 490], [720, 490], [280, 900], [720, 900]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jump</td>\n",
       "      <td>skateboard</td>\n",
       "      <td>skateboard_002387.jpg</td>\n",
       "      <td>[[500, 350], [350, 650], [650, 650]]</td>\n",
       "      <td>[Fail, Fail, Fail]</td>\n",
       "      <td>[The query point (500,350) is on the deck of t...</td>\n",
       "      <td>[[500, 350], [350, 650], [650, 650]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jump</td>\n",
       "      <td>surfboard</td>\n",
       "      <td>surfboard_000658.jpg</td>\n",
       "      <td>[[200, 200], [500, 500], [800, 800]]</td>\n",
       "      <td>[Fail, Fail, Fail]</td>\n",
       "      <td>[The point (200,200) is on the deck of the sur...</td>\n",
       "      <td>[[200, 200], [500, 500], [800, 800]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jump</td>\n",
       "      <td>snowboard</td>\n",
       "      <td>snowboard_001704.jpg</td>\n",
       "      <td>[[250, 200], [500, 500], [750, 200]]</td>\n",
       "      <td>[Fail, Fail, Fail]</td>\n",
       "      <td>[The query point (250,200) is on the top surfa...</td>\n",
       "      <td>[[250, 200], [500, 500], [750, 200]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  action      object               filename  \\\n",
       "0   jump        skis        skis_002829.jpg   \n",
       "1   jump  skateboard  skateboard_002387.jpg   \n",
       "2   jump   surfboard   surfboard_000658.jpg   \n",
       "3   jump   snowboard   snowboard_001704.jpg   \n",
       "\n",
       "                                               dots               veri_result  \\\n",
       "0  [[280, 490], [720, 490], [280, 900], [720, 900]]  [Fail, Fail, Fail, Fail]   \n",
       "1              [[500, 350], [350, 650], [650, 650]]        [Fail, Fail, Fail]   \n",
       "2              [[200, 200], [500, 500], [800, 800]]        [Fail, Fail, Fail]   \n",
       "3              [[250, 200], [500, 500], [750, 200]]        [Fail, Fail, Fail]   \n",
       "\n",
       "                                         veri_reason  \\\n",
       "0  [The query point (280,490) is on the upper par...   \n",
       "1  [The query point (500,350) is on the deck of t...   \n",
       "2  [The point (200,200) is on the deck of the sur...   \n",
       "3  [The query point (250,200) is on the top surfa...   \n",
       "\n",
       "                                          final_dot  \n",
       "0  [[280, 490], [720, 490], [280, 900], [720, 900]]  \n",
       "1              [[500, 350], [350, 650], [650, 650]]  \n",
       "2              [[200, 200], [500, 500], [800, 800]]  \n",
       "3              [[250, 200], [500, 500], [750, 200]]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fin = pd.read_pickle('test_verify_qwen3_2b.pkl')\n",
    "df_fin.loc[df_fin['final_dot'].apply(lambda x : len(x))==0,'final_dot']= df_fin.loc[df_fin['final_dot'].apply(lambda x : len(x))==0,'dots']\n",
    "df_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c39d270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 4 samples...\n",
      "==================================================\n",
      "Action : jump, Object : skis image_name : skis_002829.jpg\n",
      "parsed dots!!! : [[280, 490], [720, 490], [280, 900], [720, 900]]\n",
      "restored_dots!!! : [[157, 735], [403, 735], [157, 1350], [403, 1350]]\n",
      "\n",
      "==================================================\n",
      "Metrics for only_ego skis_002829.jpg:\n",
      " only_ego Current - KLD: 1.1155 | SIM: 0.3736 | NSS: 1.4524\n",
      "\n",
      "Cumulative only_ego  Averages over 1 samples:\n",
      "Average - KLD: 1.1155 | SIM: 0.3736 | NSS: 1.4524\n",
      "==================================================\n",
      "\n",
      "Action : jump, Object : skateboard image_name : skateboard_002387.jpg\n",
      "parsed dots!!! : [[500, 350], [350, 650], [650, 650]]\n",
      "restored_dots!!! : [[750, 332], [525, 617], [975, 617]]\n",
      "\n",
      "==================================================\n",
      "Metrics for only_ego skateboard_002387.jpg:\n",
      " only_ego Current - KLD: 3.6953 | SIM: 0.3071 | NSS: 0.5182\n",
      "\n",
      "Cumulative only_ego  Averages over 2 samples:\n",
      "Average - KLD: 2.4054 | SIM: 0.3404 | NSS: 0.9853\n",
      "==================================================\n",
      "\n",
      "Action : jump, Object : surfboard image_name : surfboard_000658.jpg\n",
      "parsed dots!!! : [[200, 200], [500, 500], [800, 800]]\n",
      "restored_dots!!! : [[160, 300], [401, 750], [642, 1200]]\n",
      "\n",
      "==================================================\n",
      "Metrics for only_ego surfboard_000658.jpg:\n",
      " only_ego Current - KLD: 2.7645 | SIM: 0.2552 | NSS: -0.1193\n",
      "\n",
      "Cumulative only_ego  Averages over 3 samples:\n",
      "Average - KLD: 2.5251 | SIM: 0.3120 | NSS: 0.6171\n",
      "==================================================\n",
      "\n",
      "Action : jump, Object : snowboard image_name : snowboard_001704.jpg\n",
      "parsed dots!!! : [[250, 200], [500, 500], [750, 200]]\n",
      "restored_dots!!! : [[150, 300], [301, 750], [451, 300]]\n",
      "\n",
      "==================================================\n",
      "Metrics for only_ego snowboard_001704.jpg:\n",
      " only_ego Current - KLD: 3.4961 | SIM: 0.2005 | NSS: -0.2501\n",
      "\n",
      "Cumulative only_ego  Averages over 4 samples:\n",
      "Average - KLD: 2.7679 | SIM: 0.2841 | NSS: 0.4003\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get total number of samples\n",
    "total_samples = len(df_fin)\n",
    "metrics_tracker_ego = MetricsTracker(name=\"only_ego\")\n",
    "# Process each sample\n",
    "print(f\"Processing {total_samples} samples...\")\n",
    "print(\"=\" * 50)    \n",
    "for idx, row in df_fin.iterrows():\n",
    "    object_name = row['object']\n",
    "    action = row['action']\n",
    "    filename = row['filename']\n",
    "    dot_list =  row['dots']\n",
    "    image_path = f\"{AGD20K_PATH}/Seen/testset/egocentric/{action}/{object_name}/{filename}\"\n",
    "    gt_path = get_gt_path(image_path) \n",
    "    image_name = image_path.split('/')[-1]\n",
    "    print(f\"Action : {action}, Object : {object_name} image_name : {image_name}\")\n",
    "    final_dots = row['final_dot']\n",
    "    print(f\"parsed dots!!! : {final_dots}\")\n",
    "\n",
    "    raw_image = Image.open(image_path).convert(\"RGB\")\n",
    "    orig_width, orig_height = raw_image.size\n",
    "\n",
    "    dots = [\n",
    "                [int(x * (orig_width / 1000)), int(y * (orig_height / 1000))] \n",
    "                for x, y in final_dots\n",
    "            ]\n",
    "    print(f\"restored_dots!!! : {dots}\")\n",
    "\n",
    "    dot_image_path, heatmap_tensor = draw_dots_on_image(image_path, dots, gt_path, action)\n",
    "\n",
    "    # Save heatmap image\n",
    "    script_dir = os.path.dirname(os.path.abspath(current_dir))\n",
    "    res_dir = os.path.join(script_dir, f'dot_images', 'heatmaps')\n",
    "    os.makedirs(res_dir, exist_ok=True)\n",
    "    \n",
    "    base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    ext = os.path.splitext(image_path)[1]\n",
    "    heatmap_filename = f\"{base_name}_{action}_heatmap{ext}\"\n",
    "    heatmap_path = os.path.join(res_dir, heatmap_filename)\n",
    "    \n",
    "    # Convert heatmap tensor to image and save\n",
    "    heatmap_img = transforms.ToPILImage()(heatmap_tensor.unsqueeze(0).repeat(3, 1, 1))\n",
    "    heatmap_img.save(heatmap_path)\n",
    "\n",
    "    # Save dot image separately for validation  \n",
    "    dot_res_dir = os.path.join(script_dir, f'dot_images', 'dots_only')\n",
    "    os.makedirs(dot_res_dir, exist_ok=True)\n",
    "    dot_only_filename = f\"{base_name}_{action}_dots{ext}\"\n",
    "    dot_only_path = os.path.join(dot_res_dir, dot_only_filename)\n",
    "        \n",
    "    # Create dot image (ego image with dots)\n",
    "    ego_img = Image.open(image_path)\n",
    "    dot_only_img = draw_dots_on_single_image(ego_img, dots, color='red', radius=15)\n",
    "    dot_only_img.save(dot_only_path)\n",
    "    \n",
    "    # Calculate metrics if GT is available\n",
    "    metrics = None\n",
    "    gt_map = load_ground_truth(gt_path)\n",
    "    if gt_map is not None and len(dots) > 0:\n",
    "        metrics = calculate_metrics(heatmap_tensor, gt_map)\n",
    "    \n",
    "    dot_images_res =  {\n",
    "        'dots': dots,\n",
    "        'dot_image_path': dot_image_path,\n",
    "        'dot_only_image_path': dot_only_path,\n",
    "        'heatmap_image_path': heatmap_path,\n",
    "        'heatmap_tensor': heatmap_tensor,\n",
    "        'metrics': metrics,\n",
    "    }\n",
    "\n",
    "    metrics_ego = dot_images_res['metrics']\n",
    "\n",
    "    if metrics_ego:\n",
    "        # Update and print metrics\n",
    "        metrics_tracker_ego.update(metrics_ego)\n",
    "        metrics_tracker_ego.print_metrics(metrics_ego, image_path.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "59269b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KLD': 1.638624616398299,\n",
       " 'SIM': 0.48650581333478377,\n",
       " 'NSS': 1.5015618012109695}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_tracker_ego.get_averages()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
