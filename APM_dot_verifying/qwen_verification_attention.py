
from PIL import Image
import io
import sys
import base64

import matplotlib.pyplot as plt
import matplotlib.patches as patches

# (ë£¨í”„ ë‚´ë¶€ë¼ê³  ê°€ì •)
from PIL import Image
import cv2
import os
import matplotlib.pyplot as plt
# nohup python -u ego_only.py > GPT5_relative_coord.log 2>&1 & tail -f GPT5_relative_coord.log
import os
import torch
import random
import json
import numpy as np
from PIL import Image
# ------------------------------------------------------
# 2. System Path Setup (ë¡œì»¬ ëª¨ë“ˆ ê²½ë¡œ ì„¤ì •)
# ------------------------------------------------------
# í˜„ì¬ íŒŒì¼ ìœ„ì¹˜ ê¸°ì¤€ ìƒìœ„ í´ë”ë¥¼ ì‹œìŠ¤í…œ ê²½ë¡œì— ì¶”ê°€
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.append(parent_dir)

from file_managing import (
    load_selected_samples,
    get_actual_path,
    get_gt_path,
)
from config import AGD20K_PATH, model_name
from VLM_model_dot_relative import QwenVLModel, MetricsTracker

import os
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
os.environ["PYTORCH_ENABLE_SDPA"] = "1"


import re
import pandas as pd
import ast  # ë¬¸ìì—´ë¡œ ëœ ë¦¬ìŠ¤íŠ¸ë¥¼ ì‹¤ì œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ê¸° ìœ„í•´ ì‚¬ìš©

import json
import re


from io import BytesIO
def make_input_image(file_name_real):
    # 1. ì´ë¯¸ì§€ ì—´ê¸° ë° ë¦¬ì‚¬ì´ì¦ˆ
    with Image.open(file_name_real) as img:
        img = img.convert("RGB")
        resized_image = img.resize((1000, 1000))
        
        # 2. í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ë²„í¼ ìƒì„± (with êµ¬ë¬¸ ì‚¬ìš© ì¶”ì²œ X -> getvalue í›„ì—” ìë™ GCë¨)
        buffered = BytesIO()
        # 3. ë²„í¼ì— ì €ì¥ (ë©”ëª¨ë¦¬ì— JPEG ìƒì„±)
        resized_image.save(buffered, format="JPEG")
        
        # 4. ë°”ë¡œ ì¸ì½”ë”© í›„ ë¦¬í„´ (í•œ ì¤„ë¡œ ì²˜ë¦¬)
        return base64.b64encode(buffered.getvalue()).decode('utf-8')

# 2. ê°•ë ¥í•œ í”„ë¡¬í”„íŠ¸ ì‘ì„±
system_prompt = """
You are an expert in Visual Affordance Grounding. 
Your task is to evaluate whether a specific pixel coordinate on an image is a valid region for a human to perform a specific action on an object.
"""


def input_prompt(action, object_name, dot):
    return f"""
    Analyze the provided image with the following details:

    1. **Target Action**: {action}
    2. **Target Object**: {object_name}
    3. **Query Point**: ({dot[0]},{dot[1]}) 
    4. **Image Resolution**: 1000x1000

    **Task**:
    Evaluate if the "Query Point" falls within the **affordance region** specific to the "{action}" on the "{object_name}". 
    (e.g., If action is 'jump' on 'skateboard', the point should be on the deck where feet act, not on the wheels or background.)
    **Output Format**:
    Provide the result in JSON format only:
    {{
        "result": <Pass or Fail>,
        "reason": "<in one sentence>"
    }}
    """



def parse_llm_json(text):
    """
    ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡(```json ... ```)ì„ ì œê±°í•˜ê³  JSONìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
    """
    try:
        # 1. ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ```json ê³¼ ``` ì‚¬ì´ì˜ ë‚´ìš©ë§Œ ì¶”ì¶œ
        # re.DOTALL: ì¤„ë°”ê¿ˆ(\n)ë„ í¬í•¨í•´ì„œ ì°¾ê¸° ìœ„í•¨
        match = re.search(r"```(?:json)?\s*(.*?)\s*```", text, re.DOTALL)
        
        if match:
            json_str = match.group(1)  # ì½”ë“œ ë¸”ë¡ ì•ˆì˜ ë‚´ìš©ë§Œ ê°€ì ¸ì˜´
        else:
            json_str = text  # ì½”ë“œ ë¸”ë¡ì´ ì—†ìœ¼ë©´ ì›ë³¸ ê·¸ëŒ€ë¡œ ì‚¬ìš© ì‹œë„
            
        # 2. JSON íŒŒì‹±
        return json.loads(json_str)
        
    except json.JSONDecodeError as e:
        print(f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        return None
import pandas as pd
import ast
import re

def parse_log_to_df(file_path):
    data_list = []
    
    # í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ìƒ˜í”Œì˜ ë©”íƒ€ë°ì´í„° ì„ì‹œ ì €ì¥ìš© (action, object, filename)
    current_meta = None 
    is_ego_section = False
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                
                # 1. Action ë¼ì¸ íŒŒì‹± (ìƒˆë¡œìš´ Ego ìƒ˜í”Œ ì‹œì‘)
                # í¬ë§·: Action : jump, Object : skis image_name : skis_002829.jpg
                if line.startswith("Action :"):
                    # ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ action, object, filename ì¶”ì¶œ
                    match = re.search(r"Action\s*:\s*(.*?),\s*Object\s*:\s*(.*?)\s+image_name\s*:\s*(.*)", line)
                    if match:
                        action = match.group(1).strip()
                        obj = match.group(2).strip()
                        filename = match.group(3).strip()
                        
                        current_meta = (action, obj, filename)
                        is_ego_section = True
                    continue

                # 2. Exo ë¼ì¸ ê°ì§€ (ì´ ì´í›„ì˜ dotsëŠ” ë¬´ì‹œ)
                if line.startswith("exo file name :"):
                    is_ego_section = False
                    continue

                # 3. Dots íŒŒì‹± ë° ë°ì´í„° ë³‘í•©
                if line.startswith("parsed dots!!! :"):
                    # Ego ì„¹ì…˜ì´ê³ , ë©”íƒ€ë°ì´í„°ê°€ í™•ë³´ëœ ìƒíƒœì¼ ë•Œë§Œ ì €ì¥
                    if is_ego_section and current_meta is not None:
                        try:
                            dots_str = line.split(":", 1)[1].strip()
                            dots = ast.literal_eval(dots_str)
                            
                            # [action, object, filename, dots] í˜•íƒœë¡œ ì¶”ê°€
                            data_list.append([current_meta[0], current_meta[1], current_meta[2], dots])
                            
                        except (ValueError, SyntaxError) as e:
                            print(f"Dots parsing error: {e} in line: {line}")
                            
    except FileNotFoundError:
        print(f"File not found: {file_path}")
        return pd.DataFrame()

    # --- DataFrame ìƒì„± ë° ì¤‘ë³µ ì²˜ë¦¬ (ìš”ì²­í•˜ì‹  ë¡œì§) ---
    df = pd.DataFrame(data_list)
    
    if not df.empty:
        df.columns = ['action', 'object', 'filename', 'dots']
        
        # action, object, filename ì¡°í•©ì´ ì¤‘ë³µë˜ëŠ” ê²½ìš° ì œê±°
        df_fin = df.loc[df[['action', 'object', 'filename']].drop_duplicates().index].reset_index(drop=True)
    else:
        # ë°ì´í„°ê°€ ì—†ì„ ê²½ìš° ë¹ˆ DF ë°˜í™˜
        df_fin = pd.DataFrame(columns=['action', 'object', 'filename', 'dots'])

    print(f">>>>> Total data Length : {len(df_fin)}")
    return df_fin


print(f"ğŸ¤– {model_name} ëª¨ë¸ ë¡œë”©ì¤‘...")
# 1. Processor ë¡œë“œ

from transformers import Qwen3VLForConditionalGeneration, AutoProcessor
# 2. Qwen3 Model ë¡œë“œ
# ì‚¬ìš©ìê°€ ì œê³µí•œ ì½”ë“œì— ë§ì¶° Qwen3VLForConditionalGeneration ì‚¬ìš©
# dtype="auto", device_map="auto" ì ìš©
model = Qwen3VLForConditionalGeneration.from_pretrained(
    model_name,
    dtype="auto",
    device_map="auto",
    attn_implementation="eager",
)
processor = AutoProcessor.from_pretrained(model_name)
# ëª¨ë¸ì´ ë¡œë“œëœ ì£¼ ë””ë°”ì´ìŠ¤ í™•ì¸ (DINOë¥¼ ê°™ì€ ê³³ì— ì˜¬ë¦¬ê¸° ìœ„í•´)
device = model.device




cnt_d = 0
# --- ì‹¤í–‰ ---
file_path = '/home/bongo/porter_notebook/research/qwen3/32B_ego_exo_relative_prompt5/ego_exo_prompt5_relative.log'
df_fin = parse_log_to_df(file_path).head(1)
df_fin
threshold_ratio = 0.5
print(f"length of Data : {len(df_fin)}, threshold_ratio : {threshold_ratio}")

result_row = []
reason_row = []
final_dot_row = []
for index, row in df_fin.iterrows():
    object_name = row['object']
    action = row['action']
    filename = row['filename']
    dot_list =  row['dots']
    file_name_real = f"{AGD20K_PATH}/Seen/testset/egocentric/{action}/{object_name}/{filename}"
    # if (object_name=='cup')&(action =='drink_with'):
    print(index,object_name,action,filename)
    image_base64 = make_input_image(file_name_real)
    dot_res_list = []
    dot_reason_list = []
    dot_real_list = []

    for dot in dot_list:
        messages = [
            
        {
        "role": "system", 
        "content": [
            {"type": "text", "text": system_prompt}
        ]
        },
        {
        "role": "user",
        "content": [
            {"type": "text", "text": input_prompt(action, object_name, dot)},
            {"type": "image", "image": f"data:image/jpeg;base64,{image_base64}"}
                    ]
        }
        ]
        # 2. ì¶”ë¡  (OpenAI API í˜¸ì¶œ)
        inputs = processor.apply_chat_template(
            messages,
            tokenize=True,
            add_generation_prompt=True,
            return_dict=True,
            return_tensors="pt"
        )
        inputs = inputs.to(model.device)
        # Inference: Generation of the output
        # 2. ëª¨ë¸ ì¶”ë¡  & ì–´í…ì…˜ ì¶”ì¶œ
        with torch.no_grad():
            outputs = model.generate(
                **inputs,
                max_new_tokens=1024,
                return_dict_in_generate=True,
                output_attentions=True, 
            )
        print(f"outputs :{outputs.sequences.shape}")
        input_len = inputs.input_ids.shape[1]
        generated_ids_trimmed = outputs.sequences[0, input_len:]
        output_text = processor.decode(
            generated_ids_trimmed, 
            skip_special_tokens=True, 
            clean_up_tokenization_spaces=False
        )
        
        result = output_text
        print(f"{dot} : {result}")
        llM_result_json = parse_llm_json(result)
        dot_res_list.append(llM_result_json['result'])
        dot_reason_list.append(llM_result_json['reason'])
        if llM_result_json['result']=='Pass':
            dot_real_list.append(dot)

        # 3. ì–´í…ì…˜ ë°ì´í„° ì¤€ë¹„
        last_step_attentions = outputs.attentions[-1] 
        # print(f"last_step_attentions : {np.shape(last_step_attentions)} ")
        grid_t, grid_h, grid_w = inputs.image_grid_thw[0].cpu().numpy()

        # âœ¨ í•µì‹¬ ìˆ˜ì •: Qwen2.5-VLì€ 2x2 í’€ë§ì„ í•˜ë¯€ë¡œ ê·¸ë¦¬ë“œ í¬ê¸°ë¥¼ 2ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.
        llm_grid_h = grid_h // 2
        llm_grid_w = grid_w // 2
        num_image_tokens = llm_grid_h * llm_grid_w

        print(f"grid_h : {grid_h}, grid_w : {grid_w}, grid_t :{grid_t}, llm_grid_h : {llm_grid_h}, llm_grid_w : {llm_grid_w}")
        
        input_ids = inputs.input_ids[0].cpu().tolist()

        current_img_size = 1000 
        
        target_x = int(dot[0] / current_img_size * llm_grid_w)
        target_y = int(dot[1] / current_img_size *  llm_grid_h)

        # ì¸ë±ìŠ¤ ë²”ìœ„ ë²—ì–´ë‚˜ì§€ ì•Šê²Œ í´ë¦¬í•‘
        target_x = min(max(target_x, 0), llm_grid_w - 1)
        target_y = min(max(target_y, 0), llm_grid_h - 1)

        valid_heads_count = 0
        accumulated_heatmap = np.zeros((llm_grid_h, llm_grid_w), dtype=np.float32)
        
        print(f"Original Dot: {dot} -> Grid Coords: ({target_x}, {target_y}) / Grid Size: ({llm_grid_w}, {llm_grid_h})")
        all_heads_scores = []
        # 4. ëª¨ë“  ë ˆì´ì–´ & í—¤ë“œ ìˆœíšŒ
        for layer_idx, layer_attn in enumerate(last_step_attentions):
            heads_attn = layer_attn[0, :, -1, :] 
            num_heads = heads_attn.shape[0]
            
            for head_idx in range(num_heads):
                # print(f"Layer {layer_idx}, Head {head_idx}")
                this_head_attn = heads_attn[head_idx] 
                # img_attn_1d = this_head_attn[-num_image_tokens:]
                # [ìˆ˜ì •] íŠ¹ìˆ˜ í† í° ID ì°¾ê¸°
                vision_start_id = processor.tokenizer.convert_tokens_to_ids("<|vision_start|>")
                vision_end_id = processor.tokenizer.convert_tokens_to_ids("<|vision_end|>")
                
                # input_idsì—ì„œ ìœ„ì¹˜ ì°¾ê¸°
                # (ë°°ì¹˜ 0ë²ˆ ê¸°ì¤€)
                ids_list = inputs.input_ids[0].tolist()
                
                vis_start_idx = ids_list.index(vision_start_id)
                vis_end_idx = ids_list.index(vision_end_id)
                # print (f"vis_start_idx : {vis_start_idx}, vis_end_idx : {vis_end_idx}, vis_end_idx - vis_start_idx : {vis_end_idx - vis_start_idx}, num_image_tokens : {num_image_tokens}")


                # âœ¨ í•µì‹¬: Start ë‹¤ìŒë¶€í„° ~ End ì „ê¹Œì§€ (ìˆœìˆ˜ ì´ë¯¸ì§€ í† í°ë§Œ)
                # ì‹¤ì œ ì´ë¯¸ì§€ í† í° ì‹œì‘ = vis_start_idx + 1
                # ì‹¤ì œ ì´ë¯¸ì§€ í† í° ë = vis_end_idx
                
                # ìŠ¬ë¼ì´ì‹±
                img_attn_1d = this_head_attn[vis_start_idx + 1 : vis_end_idx]
                heatmap_2d = img_attn_1d.reshape(llm_grid_h, llm_grid_w).float().cpu().numpy()
                # ì •ê·œí™”
                if heatmap_2d.max() > 0:
                    heatmap_2d = (heatmap_2d - heatmap_2d.min()) / (heatmap_2d.max() - heatmap_2d.min())
                else:
                    print("heatmap_2d max is 0")
                    continue

                ## ì¶”ê°€ë¶€ë¶„ì•„ë˜
                point_value = heatmap_2d[target_y, target_x]
                
                # ë¦¬ìŠ¤íŠ¸ì— ì •ë³´ ì €ì¥ (ì ìˆ˜, ë ˆì´ì–´, í—¤ë“œ, íˆíŠ¸ë§µ)
                all_heads_scores.append({
                    "score": point_value,
                    "layer": layer_idx,
                    "head": head_idx,
                    "heatmap": heatmap_2d
                })

                # # ë³€í™˜ëœ ê·¸ë¦¬ë“œ ì¢Œí‘œ(target_x, target_y)ë¡œ ê°’ í™•ì¸
                # point_value = heatmap_2d[target_x, target_y]
                # threshold_value = 0 # heatmap_2d.max() * threshold_ratio                
                # if point_value > threshold_value:
                #     accumulated_heatmap += heatmap_2d
                #     valid_heads_count += 1
                #     # print(f"Point value: {point_value}, max value: {heatmap_2d.max()}, valid_heads_count: {valid_heads_count}")
                #     print(f" Grid Coords: ({target_x}, {target_y}) / âœ… Found valid head! Layer: {layer_idx}, Head: {head_idx} (Val: {point_value:.4f} / Max: {heatmap_2d.max():.4f}), threshold_value: {threshold_value}")

                #     # --- âœ¨ íˆíŠ¸ë§µ ì €ì¥ ì½”ë“œ ì‹œì‘ ---
                #     # 1. ì €ì¥í•  í´ë” ë§Œë“¤ê¸° (ì—†ìœ¼ë©´ ìƒì„±)
                #     save_dir = "valid_heads_visualization"
                #     os.makedirs(save_dir, exist_ok=True)
                    
                #     # 2. íŒŒì¼ ì´ë¦„ ìƒì„± (ë ˆì´ì–´_í—¤ë“œ ë²ˆí˜¸ í¬í•¨)
                #     # ì˜ˆ: valid_heads_visualization/layer05_head12.png
                #     save_filename = os.path.join(save_dir, f"{filename}_{dot[0]}_{dot[1]}_layer{layer_idx:02d}_head{head_idx:02d}.png")
                    
                #     # 3. ì´ë¯¸ì§€ë¡œ ì €ì¥ (cmap='jet'ìœ¼ë¡œ ì»¬ëŸ¬ íˆíŠ¸ë§µ ì ìš©)
                #     # vmin=0, vmax=1 ë¡œ ê³ ì •í•˜ë©´ ëª¨ë“  í—¤ë“œì˜ ìŠ¤ì¼€ì¼ì„ í†µì¼í•´ì„œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                #     plt.imsave(save_filename, heatmap_2d, cmap='jet', vmin=0, vmax=1)
                #     print(save_filename)
                #     # --- íˆíŠ¸ë§µ ì €ì¥ ì½”ë“œ ë ---
                # else:
                #     print(f"âŒ Invalid head! Layer: {layer_idx}, Head: {head_idx} (Val: {point_value:.4f} / Max: {heatmap_2d.max():.4f})")
        all_heads_scores.sort(key=lambda x: x["score"], reverse=True)
        # 2. ìƒìœ„ 5ê°œ ì„ íƒ
        top_k_heads = all_heads_scores[:5]
        
        print(f"âœ… Saving Top-{len(top_k_heads)} attention heads...")

        # 3. ì €ì¥ í´ë” ìƒì„±
        save_dir = "top_attention_heads"
        os.makedirs(save_dir, exist_ok=True)
        
        # 4. ì´ë¯¸ì§€ ì €ì¥
        for rank, item in enumerate(top_k_heads):
            score = item["score"]
            layer = item["layer"]
            head = item["head"]
            heatmap = item["heatmap"]
            
            print(f"Rank {rank+1}: Layer {layer}, Head {head}, Score {score:.4f}")
            save_filename = os.path.join(save_dir, f"{dot[0]}_{dot[1]}_rank{rank+1:02d}_L{layer:02d}_H{head:02d}_score_{score:.4f}.png")
            # --- âœ¨ ìˆ˜ì •: ë¹¨ê°„ ë„¤ëª¨ ê·¸ë¦¬ê¸° ---
            # 1. ìº”ë²„ìŠ¤(Figure) ìƒì„± (í”„ë ˆì„ ì—†ì´ ì´ë¯¸ì§€ í¬ê¸°ì— ë”± ë§ê²Œ ì„¤ì •í•˜ë ¤ë©´ ì¡°ê¸ˆ ë³µì¡í•˜ì§€ë§Œ, ì—¬ê¸°ì„  ë³´ê¸° ì¢‹ê²Œ ê·¸ë¦½ë‹ˆë‹¤)
            fig, ax = plt.subplots(figsize=(5, 5))

            # 2. íˆíŠ¸ë§µ ê·¸ë¦¬ê¸°
            ax.imshow(heatmap, cmap='gray_r', vmin=0, vmax=1)
            
            # 3. ë¹¨ê°„ ë„¤ëª¨ ì¶”ê°€
            # Rectangle((xì‹œì‘, yì‹œì‘), ë„ˆë¹„, ë†’ì´, ...)
            # í”½ì…€ì˜ ì¤‘ì‹¬ì´ (target_x, target_y)ì´ë¯€ë¡œ, -0.5ë¥¼ í•´ì„œ í”½ì…€ í…Œë‘ë¦¬ì— ë§ì¶¥ë‹ˆë‹¤.
            rect = patches.Rectangle(
                (target_x - 0.5, target_y - 0.5), # ì‹œì‘ ì¢Œí‘œ (x, y)
                1, 1,                             # ë„ˆë¹„, ë†’ì´ (1ì¹¸)
                linewidth=2,                      # ì„  êµµê¸°
                edgecolor='red',                  # ì„  ìƒ‰ìƒ
                facecolor='none'                  # ë‚´ë¶€ ì±„ìš°ê¸° ì—†ìŒ
            )
            ax.add_patch(rect)
            
            # 4. ì¶• ì œê±° ë° ì €ì¥
            ax.axis('off')
            # ì—¬ë°± ì—†ì´ ì €ì¥ (bbox_inches='tight', pad_inches=0)
            plt.savefig(save_filename, bbox_inches='tight', pad_inches=0)
            plt.close(fig) # ë©”ëª¨ë¦¬ í•´ì œë¥¼ ìœ„í•´ ë‹«ê¸°

            real_image = Image.open(file_name_real)
            real_w, real_h = real_image.size

            # 2. íˆíŠ¸ë§µì„ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ì—…ìƒ˜í”Œë§ (Interpolation: Cubic ì¶”ì²œ)
            # heatmapì€ í˜„ì¬ ì‘ì€ ê·¸ë¦¬ë“œ í¬ê¸°(ì˜ˆ: 31x31)ë¼ê³  ê°€ì •
            upsampled_heatmap = cv2.resize(heatmap, (real_w, real_h), interpolation=cv2.INTER_CUBIC)

            # 3. íŒŒì¼ ì´ë¦„ ìƒì„± (ìš”ì²­í•˜ì‹  í¬ë§·)
            # dot[0], dot[1]ì´ floatì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ í¬ë§·íŒ…ì„ ê¹”ë”í•˜ê²Œ í•˜ë ¤ë©´ :.0f ë“±ì„ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            save_filename2 = os.path.join(
                save_dir, 
                f"upsampled_{dot[0]}_{dot[1]}_rank{rank+1:02d}_L{layer:02d}_H{head:02d}_score_{score:.4f}.png"
            )

            # 4. ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€ ìƒì„± ë° ì €ì¥
            # ì´ë¯¸ì§€ í¬ê¸°ì— ë§ëŠ” Figure ìƒì„± (DPI ì¡°ì ˆë¡œ í•´ìƒë„ ìœ ì§€ ê°€ëŠ¥)
            fig, ax = plt.subplots(figsize=(10, 10)) 

            # (1) ì›ë³¸ ì´ë¯¸ì§€ ê¹”ê¸°
            ax.imshow(real_image)

            # (2) íˆíŠ¸ë§µ ë®ê¸° (alpha=0.5ë¡œ ë°˜íˆ¬ëª…í•˜ê²Œ)
            # cmap='jet': íŒŒë‘(ë‚®ìŒ) -> ë¹¨ê°•(ë†’ìŒ) (ì–´í…ì…˜ ë³´ê¸°ì— ê°€ì¥ ì¢‹ìŠµë‹ˆë‹¤)
            # cmap='gray_r': í°ìƒ‰(ë‚®ìŒ) -> ê²€ì€ìƒ‰(ë†’ìŒ) (ì´ì „ ì½”ë“œ ìŠ¤íƒ€ì¼)
            ax.imshow(upsampled_heatmap, cmap='gray_r', alpha=0.5, vmin=0, vmax=1)

            # (3) ì¶• ì œê±° ë° ì €ì¥
            ax.axis('off')
            plt.savefig(save_filename2, bbox_inches='tight', pad_inches=0)
            plt.close(fig)


        # break
    result_row.append(dot_res_list)
    reason_row.append(dot_reason_list)
    final_dot_row.append(dot_real_list)
    if cnt_d ==0 : 
        break
    cnt_d += 1
df_fin['veri_result'] = result_row
df_fin['veri_reason'] = reason_row
df_fin['final_dot'] = final_dot_row
print(df_fin)

# df_fin.to_pickle('test_verify_qwen3_2b.pkl')

    