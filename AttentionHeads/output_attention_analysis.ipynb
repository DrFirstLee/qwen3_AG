{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b351283e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/DATA/AGD20K'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from transformers import CLIPSegProcessor, CLIPSegForImageSegmentation\n",
    "\n",
    "clip_processor = CLIPSegProcessor.from_pretrained(\"CIDAS/clipseg-rd64-refined\")\n",
    "clip_model = CLIPSegForImageSegmentation.from_pretrained(\"CIDAS/clipseg-rd64-refined\")\n",
    "\n",
    "import os\n",
    "import sys\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(parent_dir)\n",
    "from config import AGD20K_PATH, model_name\n",
    "\n",
    "from VLM_model_dot_relative import MetricsTracker\n",
    "from file_managing import (\n",
    "    load_selected_samples,\n",
    "    get_actual_path,\n",
    "    get_gt_path,\n",
    "    load_ground_truth,\n",
    "    prompt_dict_obj,\n",
    "    get_clipseg_heatmap,\n",
    "    calculate_metrics,\n",
    "    prompt_dict_obj\n",
    ")\n",
    "\n",
    "def min_max_normalize(arr):\n",
    "    denom = arr.max() - arr.min()\n",
    "    if denom == 0:\n",
    "        return np.zeros_like(arr)\n",
    "    return (arr - arr.min()) / (denom + 1e-8)\n",
    "\n",
    "\n",
    "\n",
    "from transformers import Qwen3VLForConditionalGeneration, AutoProcessor\n",
    "model_name= f\"Qwen/Qwen3-VL-32B-Instruct\"\n",
    "processor = AutoProcessor.from_pretrained(model_name)\n",
    "tok = processor.tokenizer\n",
    "\n",
    "AGD20K_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28613512",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output = pd.read_pickle(\"output_results/attention_result_full_output_32B_1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2859e01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output = df_output.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8be5cc17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['action', 'object', 'filename', 'description', 'output_sentence',\n",
       "       'output_attentions'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18f380b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'When people cut an apple, they typically use the entire fruit, including the flesh, skin, and sometimes the core, depending on the purpose of the cut.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output.iloc[0,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75cd8797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def check_heatmap_containment(heatmap_top, heatmap_obj, threshold=0.15, containment_ratio=0.8):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        containment_ratio (float): Top 영역의 몇 % 이상이 Obj와 겹쳐야 포함으로 볼 것인지 (기본 0.9 = 90%)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. 텐서인 경우 numpy 변환\n",
    "    if hasattr(heatmap_top, 'cpu'):\n",
    "        heatmap_top = heatmap_top.detach().cpu().numpy()\n",
    "    if hasattr(heatmap_obj, 'cpu'):\n",
    "        heatmap_obj = heatmap_obj.detach().cpu().numpy()\n",
    "\n",
    "    # 2. 이진 마스크 생성\n",
    "    mask_top = heatmap_top > threshold\n",
    "    mask_obj = heatmap_obj > threshold\n",
    "\n",
    "    # 3. 면적 계산\n",
    "    area_top = np.sum(mask_top)\n",
    "    area_obj = np.sum(mask_obj)\n",
    "\n",
    "    # 예외 처리: Top 히트맵이 아예 활성화되지 않은 경우 (면적 0)\n",
    "    if area_top == 0:\n",
    "        return False\n",
    "\n",
    "    # 조건 1: Top의 면적이 Object 면적보다 작은가?\n",
    "    is_smaller = area_top < area_obj\n",
    "    \n",
    "    # 4. 포함 관계 확인 (수정된 부분)\n",
    "    # 교집합(Intersection) 영역 계산\n",
    "    intersection = np.logical_and(mask_top, mask_obj)\n",
    "    intersection_area = np.sum(intersection)\n",
    "\n",
    "    # [수정됨] 교집합 면적이 Top 전체 면적의 90% 이상인지 확인\n",
    "    # (intersection_area / area_top) >= 0.9 와 동일한 수식입니다.\n",
    "    is_inside = intersection_area >= (area_top * containment_ratio)\n",
    "\n",
    "    # 디버깅용: 실제 겹치는 비율 확인\n",
    "    # print(f\"Overlap Ratio: {intersection_area / area_top:.2f}\")\n",
    "\n",
    "    return is_smaller and is_inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ab1cad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Processing: cut - apple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input : apple\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output apple_000054.jpg:\n",
      " all_output Current - KLD: 0.6945 | SIM: 0.6284 | NSS: 0.7179\n",
      "\n",
      "Cumulative all_output  Averages over 1 samples:\n",
      "Average - KLD: 0.6945 | SIM: 0.6284 | NSS: 0.7179\n",
      "==================================================\n",
      "\n",
      "[1] Processing: eat - apple\n",
      "Selected CLIP input :  flesh\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output apple_001541.jpg:\n",
      " all_output Current - KLD: 0.2388 | SIM: 0.7479 | NSS: 1.1965\n",
      "\n",
      "Cumulative all_output  Averages over 2 samples:\n",
      "Average - KLD: 0.4667 | SIM: 0.6882 | NSS: 0.9572\n",
      "==================================================\n",
      "\n",
      "[2] Processing: peel - apple\n",
      "Selected CLIP input :  an\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output apple_001541.jpg:\n",
      " all_output Current - KLD: 0.0489 | SIM: 0.8916 | NSS: 1.3281\n",
      "\n",
      "Cumulative all_output  Averages over 3 samples:\n",
      "Average - KLD: 0.3274 | SIM: 0.7560 | NSS: 1.0808\n",
      "==================================================\n",
      "\n",
      "[3] Processing: hit - axe\n",
      "Selected CLIP input :  blade\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output axe_000961.jpg:\n",
      " all_output Current - KLD: 0.9041 | SIM: 0.4284 | NSS: 1.1537\n",
      "\n",
      "Cumulative all_output  Averages over 4 samples:\n",
      "Average - KLD: 0.4716 | SIM: 0.6741 | NSS: 1.0991\n",
      "==================================================\n",
      "\n",
      "[4] Processing: hold - axe\n",
      "Selected CLIP input :  handle\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output axe_001552.jpg:\n",
      " all_output Current - KLD: 0.3821 | SIM: 0.6542 | NSS: 2.5446\n",
      "\n",
      "Cumulative all_output  Averages over 5 samples:\n",
      "Average - KLD: 0.4537 | SIM: 0.6701 | NSS: 1.3882\n",
      "==================================================\n",
      "\n",
      "[5] Processing: hold - badminton_racket\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input :  handle\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output badminton_racket_002255.jpg:\n",
      " all_output Current - KLD: 0.8766 | SIM: 0.4337 | NSS: 2.0747\n",
      "\n",
      "Cumulative all_output  Averages over 6 samples:\n",
      "Average - KLD: 0.5242 | SIM: 0.6307 | NSS: 1.5026\n",
      "==================================================\n",
      "\n",
      "[6] Processing: swing - badminton_racket\n",
      "Selected CLIP input : inton\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output badminton_racket_003649.jpg:\n",
      " all_output Current - KLD: 5.0593 | SIM: 0.0110 | NSS: -0.4230\n",
      "\n",
      "Cumulative all_output  Averages over 7 samples:\n",
      "Average - KLD: 1.1721 | SIM: 0.5422 | NSS: 1.2275\n",
      "==================================================\n",
      "\n",
      "[7] Processing: cut - banana\n",
      "Selected CLIP input : banana\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output banana_002623.jpg:\n",
      " all_output Current - KLD: 0.1876 | SIM: 0.7674 | NSS: 1.4367\n",
      "\n",
      "Cumulative all_output  Averages over 8 samples:\n",
      "Average - KLD: 1.0490 | SIM: 0.5703 | NSS: 1.2537\n",
      "==================================================\n",
      "\n",
      "[8] Processing: eat - banana\n",
      "Selected CLIP input : banana\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output banana_002458.jpg:\n",
      " all_output Current - KLD: 0.1092 | SIM: 0.8322 | NSS: 1.7512\n",
      "\n",
      "Cumulative all_output  Averages over 9 samples:\n",
      "Average - KLD: 0.9446 | SIM: 0.5994 | NSS: 1.3089\n",
      "==================================================\n",
      "\n",
      "[9] Processing: peel - banana\n",
      "Selected CLIP input :  yellow\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output banana_000480.jpg:\n",
      " all_output Current - KLD: 1.3277 | SIM: 0.3253 | NSS: 0.9959\n",
      "\n",
      "Cumulative all_output  Averages over 10 samples:\n",
      "Average - KLD: 0.9829 | SIM: 0.5720 | NSS: 1.2776\n",
      "==================================================\n",
      "\n",
      "[10] Processing: throw - baseball\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input : baseball\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output baseball_002670.jpg:\n",
      " all_output Current - KLD: 0.2493 | SIM: 0.7717 | NSS: 3.3594\n",
      "\n",
      "Cumulative all_output  Averages over 11 samples:\n",
      "Average - KLD: 0.9162 | SIM: 0.5902 | NSS: 1.4669\n",
      "==================================================\n",
      "\n",
      "[11] Processing: hit - baseball_bat\n",
      "Selected CLIP input : baseball_bat\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output baseball_bat_001882.jpg:\n",
      " all_output Current - KLD: 2.0625 | SIM: 0.1589 | NSS: 0.3659\n",
      "\n",
      "Cumulative all_output  Averages over 12 samples:\n",
      "Average - KLD: 1.0117 | SIM: 0.5542 | NSS: 1.3751\n",
      "==================================================\n",
      "\n",
      "[12] Processing: hold - baseball_bat\n",
      "Selected CLIP input : baseball_bat\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output baseball_bat_002547.jpg:\n",
      " all_output Current - KLD: 2.1838 | SIM: 0.1434 | NSS: 1.4824\n",
      "\n",
      "Cumulative all_output  Averages over 13 samples:\n",
      "Average - KLD: 1.1019 | SIM: 0.5226 | NSS: 1.3834\n",
      "==================================================\n",
      "\n",
      "[13] Processing: swing - baseball_bat\n",
      "Selected CLIP input : baseball_bat\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output baseball_bat_001882.jpg:\n",
      " all_output Current - KLD: 2.0169 | SIM: 0.1656 | NSS: 0.4258\n",
      "\n",
      "Cumulative all_output  Averages over 14 samples:\n",
      "Average - KLD: 1.1672 | SIM: 0.4971 | NSS: 1.3150\n",
      "==================================================\n",
      "\n",
      "[14] Processing: throw - basketball\n",
      "Selected CLIP input : basketball\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output basketball_003534.jpg:\n",
      " all_output Current - KLD: 0.4993 | SIM: 0.6042 | NSS: 3.5098\n",
      "\n",
      "Cumulative all_output  Averages over 15 samples:\n",
      "Average - KLD: 1.1227 | SIM: 0.5043 | NSS: 1.4613\n",
      "==================================================\n",
      "\n",
      "[15] Processing: lie_on - bed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input :  mattress\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output bed_002880.jpg:\n",
      " all_output Current - KLD: 0.4077 | SIM: 0.6428 | NSS: 2.8591\n",
      "\n",
      "Cumulative all_output  Averages over 16 samples:\n",
      "Average - KLD: 1.0780 | SIM: 0.5129 | NSS: 1.5487\n",
      "==================================================\n",
      "\n",
      "[16] Processing: sit_on - bed\n",
      "Selected CLIP input :  the\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output bed_003622.jpg:\n",
      " all_output Current - KLD: 0.4249 | SIM: 0.6231 | NSS: 1.7428\n",
      "\n",
      "Cumulative all_output  Averages over 17 samples:\n",
      "Average - KLD: 1.0396 | SIM: 0.5194 | NSS: 1.5601\n",
      "==================================================\n",
      "\n",
      "[17] Processing: lie_on - bench\n",
      "Selected CLIP input : bench\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output bench_003727.jpg:\n",
      " all_output Current - KLD: 0.7333 | SIM: 0.5000 | NSS: 1.2494\n",
      "\n",
      "Cumulative all_output  Averages over 18 samples:\n",
      "Average - KLD: 1.0226 | SIM: 0.5183 | NSS: 1.5428\n",
      "==================================================\n",
      "\n",
      "[18] Processing: sit_on - bench\n",
      "Selected CLIP input : bench\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output bench_001877.jpg:\n",
      " all_output Current - KLD: 0.0721 | SIM: 0.8719 | NSS: 1.8440\n",
      "\n",
      "Cumulative all_output  Averages over 19 samples:\n",
      "Average - KLD: 0.9726 | SIM: 0.5369 | NSS: 1.5587\n",
      "==================================================\n",
      "\n",
      "[19] Processing: push - bicycle\n",
      "Selected CLIP input :  a\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output bicycle_002432.jpg:\n",
      " all_output Current - KLD: 2.6533 | SIM: 0.1108 | NSS: 0.0382\n",
      "\n",
      "Cumulative all_output  Averages over 20 samples:\n",
      "Average - KLD: 1.0566 | SIM: 0.5156 | NSS: 1.4827\n",
      "==================================================\n",
      "\n",
      "[20] Processing: ride - bicycle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input :  seat\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output bicycle_003046.jpg:\n",
      " all_output Current - KLD: 0.9712 | SIM: 0.4250 | NSS: 1.6790\n",
      "\n",
      "Cumulative all_output  Averages over 21 samples:\n",
      "Average - KLD: 1.0525 | SIM: 0.5113 | NSS: 1.4920\n",
      "==================================================\n",
      "\n",
      "[21] Processing: sit_on - bicycle\n",
      "Selected CLIP input :  seat\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output bicycle_002100.jpg:\n",
      " all_output Current - KLD: 2.0466 | SIM: 0.1698 | NSS: 1.2674\n",
      "\n",
      "Cumulative all_output  Averages over 22 samples:\n",
      "Average - KLD: 1.0977 | SIM: 0.4958 | NSS: 1.4818\n",
      "==================================================\n",
      "\n",
      "[22] Processing: look_out - binoculars\n",
      "Selected CLIP input : binoculars\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output binoculars_003630.jpg:\n",
      " all_output Current - KLD: 1.0029 | SIM: 0.4031 | NSS: 0.6133\n",
      "\n",
      "Cumulative all_output  Averages over 23 samples:\n",
      "Average - KLD: 1.0936 | SIM: 0.4918 | NSS: 1.4440\n",
      "==================================================\n",
      "\n",
      "[23] Processing: hold - book\n",
      "Selected CLIP input : book\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output book_001195.jpg:\n",
      " all_output Current - KLD: 0.7542 | SIM: 0.5019 | NSS: 1.2021\n",
      "\n",
      "Cumulative all_output  Averages over 24 samples:\n",
      "Average - KLD: 1.0795 | SIM: 0.4922 | NSS: 1.4340\n",
      "==================================================\n",
      "\n",
      "[24] Processing: open - book\n",
      "Selected CLIP input : book\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output book_003044.jpg:\n",
      " all_output Current - KLD: 0.6638 | SIM: 0.5103 | NSS: 2.4929\n",
      "\n",
      "Cumulative all_output  Averages over 25 samples:\n",
      "Average - KLD: 1.0628 | SIM: 0.4929 | NSS: 1.4763\n",
      "==================================================\n",
      "\n",
      "[25] Processing: drink_with - bottle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input :  the\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output bottle_003259.jpg:\n",
      " all_output Current - KLD: 1.5836 | SIM: 0.2269 | NSS: 1.9349\n",
      "\n",
      "Cumulative all_output  Averages over 26 samples:\n",
      "Average - KLD: 1.0829 | SIM: 0.4827 | NSS: 1.4940\n",
      "==================================================\n",
      "\n",
      "[26] Processing: hold - bottle\n",
      "Selected CLIP input : bottle\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output bottle_001227.jpg:\n",
      " all_output Current - KLD: 0.3552 | SIM: 0.6784 | NSS: 1.9411\n",
      "\n",
      "Cumulative all_output  Averages over 27 samples:\n",
      "Average - KLD: 1.0559 | SIM: 0.4899 | NSS: 1.5105\n",
      "==================================================\n",
      "\n",
      "[27] Processing: open - bottle\n",
      "Selected CLIP input :  cap\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output bottle_001033.jpg:\n",
      " all_output Current - KLD: 1.9420 | SIM: 0.1661 | NSS: 1.2531\n",
      "\n",
      "Cumulative all_output  Averages over 28 samples:\n",
      "Average - KLD: 1.0876 | SIM: 0.4784 | NSS: 1.5013\n",
      "==================================================\n",
      "\n",
      "[28] Processing: pour - bottle\n",
      "Selected CLIP input : bottle\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output bottle_002780.jpg:\n",
      " all_output Current - KLD: 2.0692 | SIM: 0.1893 | NSS: 0.0174\n",
      "\n",
      "Cumulative all_output  Averages over 29 samples:\n",
      "Average - KLD: 1.1214 | SIM: 0.4684 | NSS: 1.4502\n",
      "==================================================\n",
      "\n",
      "[29] Processing: hold - bowl\n",
      "Selected CLIP input : bowl\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output bowl_000546.jpg:\n",
      " all_output Current - KLD: 0.1283 | SIM: 0.7970 | NSS: 0.8913\n",
      "\n",
      "Cumulative all_output  Averages over 30 samples:\n",
      "Average - KLD: 1.0883 | SIM: 0.4793 | NSS: 1.4315\n",
      "==================================================\n",
      "\n",
      "[30] Processing: stir - bowl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input : bowl\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output bowl_000134.jpg:\n",
      " all_output Current - KLD: 1.1660 | SIM: 0.4030 | NSS: 0.5601\n",
      "\n",
      "Cumulative all_output  Averages over 31 samples:\n",
      "Average - KLD: 1.0908 | SIM: 0.4769 | NSS: 1.4034\n",
      "==================================================\n",
      "\n",
      "[31] Processing: wash - bowl\n",
      "Selected CLIP input : bowl\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output bowl_002825.jpg:\n",
      " all_output Current - KLD: 0.8018 | SIM: 0.5046 | NSS: 0.4879\n",
      "\n",
      "Cumulative all_output  Averages over 32 samples:\n",
      "Average - KLD: 1.0818 | SIM: 0.4777 | NSS: 1.3748\n",
      "==================================================\n",
      "\n",
      "[32] Processing: eat - broccoli\n",
      "Selected CLIP input : broccoli\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output broccoli_002796.jpg:\n",
      " all_output Current - KLD: 0.1765 | SIM: 0.7720 | NSS: 1.6093\n",
      "\n",
      "Cumulative all_output  Averages over 33 samples:\n",
      "Average - KLD: 1.0543 | SIM: 0.4867 | NSS: 1.3819\n",
      "==================================================\n",
      "\n",
      "[33] Processing: take_photo - camera\n",
      "Selected CLIP input :  the\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output camera_002534.jpg:\n",
      " all_output Current - KLD: 0.6938 | SIM: 0.5367 | NSS: 0.4049\n",
      "\n",
      "Cumulative all_output  Averages over 34 samples:\n",
      "Average - KLD: 1.0437 | SIM: 0.4881 | NSS: 1.3532\n",
      "==================================================\n",
      "\n",
      "[34] Processing: cut - carrot\n",
      "Selected CLIP input : carrot\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output carrot_001443.jpg:\n",
      " all_output Current - KLD: 1.0327 | SIM: 0.4126 | NSS: 2.8737\n",
      "\n",
      "Cumulative all_output  Averages over 35 samples:\n",
      "Average - KLD: 1.0434 | SIM: 0.4860 | NSS: 1.3966\n",
      "==================================================\n",
      "\n",
      "[35] Processing: eat - carrot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input : carrot\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output carrot_001443.jpg:\n",
      " all_output Current - KLD: 1.0820 | SIM: 0.3862 | NSS: 2.6868\n",
      "\n",
      "Cumulative all_output  Averages over 36 samples:\n",
      "Average - KLD: 1.0445 | SIM: 0.4832 | NSS: 1.4325\n",
      "==================================================\n",
      "\n",
      "[36] Processing: peel - carrot\n",
      "Selected CLIP input : carrot\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output carrot_003707.jpg:\n",
      " all_output Current - KLD: 0.4166 | SIM: 0.6353 | NSS: 2.0762\n",
      "\n",
      "Cumulative all_output  Averages over 37 samples:\n",
      "Average - KLD: 1.0275 | SIM: 0.4873 | NSS: 1.4499\n",
      "==================================================\n",
      "\n",
      "[37] Processing: take_photo - cell_phone\n",
      "Selected CLIP input :  camera\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output cell_phone_000601.jpg:\n",
      " all_output Current - KLD: 0.4549 | SIM: 0.6261 | NSS: 1.5143\n",
      "\n",
      "Cumulative all_output  Averages over 38 samples:\n",
      "Average - KLD: 1.0125 | SIM: 0.4910 | NSS: 1.4515\n",
      "==================================================\n",
      "\n",
      "[38] Processing: talk_on - cell_phone\n",
      "Selected CLIP input : cell_phone\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output cell_phone_000601.jpg:\n",
      " all_output Current - KLD: 0.7203 | SIM: 0.4965 | NSS: 1.3217\n",
      "\n",
      "Cumulative all_output  Averages over 39 samples:\n",
      "Average - KLD: 1.0050 | SIM: 0.4911 | NSS: 1.4482\n",
      "==================================================\n",
      "\n",
      "[39] Processing: text_on - cell_phone\n",
      "Selected CLIP input :  screen\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output cell_phone_003361.jpg:\n",
      " all_output Current - KLD: 0.7952 | SIM: 0.4708 | NSS: 1.5932\n",
      "\n",
      "Cumulative all_output  Averages over 40 samples:\n",
      "Average - KLD: 0.9997 | SIM: 0.4906 | NSS: 1.4518\n",
      "==================================================\n",
      "\n",
      "[40] Processing: sit_on - chair\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input :  seat\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output chair_002839.jpg:\n",
      " all_output Current - KLD: 0.8066 | SIM: 0.4800 | NSS: 1.2740\n",
      "\n",
      "Cumulative all_output  Averages over 41 samples:\n",
      "Average - KLD: 0.9950 | SIM: 0.4903 | NSS: 1.4475\n",
      "==================================================\n",
      "\n",
      "[41] Processing: lie_on - couch\n",
      "Selected CLIP input :  seat\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output couch_003293.jpg:\n",
      " all_output Current - KLD: 0.7022 | SIM: 0.5044 | NSS: 1.5780\n",
      "\n",
      "Cumulative all_output  Averages over 42 samples:\n",
      "Average - KLD: 0.9880 | SIM: 0.4907 | NSS: 1.4506\n",
      "==================================================\n",
      "\n",
      "[42] Processing: sit_on - couch\n",
      "Selected CLIP input :  seat\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output couch_000779.jpg:\n",
      " all_output Current - KLD: 0.7742 | SIM: 0.4744 | NSS: 1.9378\n",
      "\n",
      "Cumulative all_output  Averages over 43 samples:\n",
      "Average - KLD: 0.9831 | SIM: 0.4903 | NSS: 1.4619\n",
      "==================================================\n",
      "\n",
      "[43] Processing: drink_with - cup\n",
      "Selected CLIP input : cup\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output cup_000508.jpg:\n",
      " all_output Current - KLD: 0.5549 | SIM: 0.5606 | NSS: 2.7144\n",
      "\n",
      "Cumulative all_output  Averages over 44 samples:\n",
      "Average - KLD: 0.9733 | SIM: 0.4919 | NSS: 1.4904\n",
      "==================================================\n",
      "\n",
      "[44] Processing: hold - cup\n",
      "Selected CLIP input :  the\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output cup_002518.jpg:\n",
      " all_output Current - KLD: 0.6857 | SIM: 0.5489 | NSS: 2.6013\n",
      "\n",
      "Cumulative all_output  Averages over 45 samples:\n",
      "Average - KLD: 0.9669 | SIM: 0.4932 | NSS: 1.5151\n",
      "==================================================\n",
      "\n",
      "[45] Processing: pour - cup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input : cup\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output cup_001535.jpg:\n",
      " all_output Current - KLD: 1.2661 | SIM: 0.3585 | NSS: 1.9958\n",
      "\n",
      "Cumulative all_output  Averages over 46 samples:\n",
      "Average - KLD: 0.9734 | SIM: 0.4902 | NSS: 1.5255\n",
      "==================================================\n",
      "\n",
      "[46] Processing: sip - cup\n",
      "Selected CLIP input : cup\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output cup_001864.jpg:\n",
      " all_output Current - KLD: 0.4944 | SIM: 0.6032 | NSS: 0.9434\n",
      "\n",
      "Cumulative all_output  Averages over 47 samples:\n",
      "Average - KLD: 0.9633 | SIM: 0.4926 | NSS: 1.5132\n",
      "==================================================\n",
      "\n",
      "[47] Processing: wash - cup\n",
      "Selected CLIP input : cup\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output cup_003621.jpg:\n",
      " all_output Current - KLD: 1.0558 | SIM: 0.3659 | NSS: 1.8641\n",
      "\n",
      "Cumulative all_output  Averages over 48 samples:\n",
      "Average - KLD: 0.9652 | SIM: 0.4900 | NSS: 1.5205\n",
      "==================================================\n",
      "\n",
      "[48] Processing: throw - discus\n",
      "Selected CLIP input :  metal\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output discus_003558.jpg:\n",
      " all_output Current - KLD: 0.5092 | SIM: 0.5983 | NSS: 0.6829\n",
      "\n",
      "Cumulative all_output  Averages over 49 samples:\n",
      "Average - KLD: 0.9559 | SIM: 0.4922 | NSS: 1.5034\n",
      "==================================================\n",
      "\n",
      "[49] Processing: beat - drum\n",
      "Selected CLIP input : drum\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output drum_002586.jpg:\n",
      " all_output Current - KLD: 0.9525 | SIM: 0.4245 | NSS: 0.2289\n",
      "\n",
      "Cumulative all_output  Averages over 50 samples:\n",
      "Average - KLD: 0.9558 | SIM: 0.4909 | NSS: 1.4779\n",
      "==================================================\n",
      "\n",
      "[50] Processing: hold - fork\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input :  handle\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output fork_000804.jpg:\n",
      " all_output Current - KLD: 0.6820 | SIM: 0.5235 | NSS: 1.9527\n",
      "\n",
      "Cumulative all_output  Averages over 51 samples:\n",
      "Average - KLD: 0.9504 | SIM: 0.4915 | NSS: 1.4872\n",
      "==================================================\n",
      "\n",
      "[51] Processing: lift - fork\n",
      "Selected CLIP input : fork\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output fork_001691.jpg:\n",
      " all_output Current - KLD: 1.5281 | SIM: 0.2634 | NSS: 0.3242\n",
      "\n",
      "Cumulative all_output  Averages over 52 samples:\n",
      "Average - KLD: 0.9615 | SIM: 0.4871 | NSS: 1.4648\n",
      "==================================================\n",
      "\n",
      "[52] Processing: stick - fork\n",
      "Selected CLIP input : fork\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output fork_000095.jpg:\n",
      " all_output Current - KLD: 0.7510 | SIM: 0.4895 | NSS: 1.9462\n",
      "\n",
      "Cumulative all_output  Averages over 53 samples:\n",
      "Average - KLD: 0.9576 | SIM: 0.4872 | NSS: 1.4739\n",
      "==================================================\n",
      "\n",
      "[53] Processing: wash - fork\n",
      "Selected CLIP input : fork\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output fork_001691.jpg:\n",
      " all_output Current - KLD: 0.9168 | SIM: 0.4249 | NSS: 2.0423\n",
      "\n",
      "Cumulative all_output  Averages over 54 samples:\n",
      "Average - KLD: 0.9568 | SIM: 0.4860 | NSS: 1.4844\n",
      "==================================================\n",
      "\n",
      "[54] Processing: catch - frisbee\n",
      "Selected CLIP input : edges\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output frisbee_000598.jpg:\n",
      " all_output Current - KLD: 0.7159 | SIM: 0.5052 | NSS: 0.0485\n",
      "\n",
      "Cumulative all_output  Averages over 55 samples:\n",
      "Average - KLD: 0.9524 | SIM: 0.4864 | NSS: 1.4583\n",
      "==================================================\n",
      "\n",
      "[55] Processing: hold - frisbee\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input :  a\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output frisbee_001130.jpg:\n",
      " all_output Current - KLD: 0.9350 | SIM: 0.4188 | NSS: -0.2984\n",
      "\n",
      "Cumulative all_output  Averages over 56 samples:\n",
      "Average - KLD: 0.9521 | SIM: 0.4851 | NSS: 1.4270\n",
      "==================================================\n",
      "\n",
      "[56] Processing: throw - frisbee\n",
      "Selected CLIP input : frisbee\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output frisbee_003249.jpg:\n",
      " all_output Current - KLD: 0.6222 | SIM: 0.5485 | NSS: 0.4913\n",
      "\n",
      "Cumulative all_output  Averages over 57 samples:\n",
      "Average - KLD: 0.9463 | SIM: 0.4863 | NSS: 1.4105\n",
      "==================================================\n",
      "\n",
      "[57] Processing: hold - golf_clubs\n",
      "Selected CLIP input :  black\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output golf_clubs_000045.jpg:\n",
      " all_output Current - KLD: 0.8900 | SIM: 0.4729 | NSS: 1.6259\n",
      "\n",
      "Cumulative all_output  Averages over 58 samples:\n",
      "Average - KLD: 0.9454 | SIM: 0.4860 | NSS: 1.4143\n",
      "==================================================\n",
      "\n",
      "[58] Processing: swing - golf_clubs\n",
      "Selected CLIP input : golf_clubs\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output golf_clubs_001992.jpg:\n",
      " all_output Current - KLD: 2.3558 | SIM: 0.1373 | NSS: 0.4142\n",
      "\n",
      "Cumulative all_output  Averages over 59 samples:\n",
      "Average - KLD: 0.9693 | SIM: 0.4801 | NSS: 1.3973\n",
      "==================================================\n",
      "\n",
      "[59] Processing: hit - hammer\n",
      "Selected CLIP input : hammer\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output hammer_001006.jpg:\n",
      " all_output Current - KLD: 1.7769 | SIM: 0.2057 | NSS: 0.3249\n",
      "\n",
      "Cumulative all_output  Averages over 60 samples:\n",
      "Average - KLD: 0.9827 | SIM: 0.4755 | NSS: 1.3794\n",
      "==================================================\n",
      "\n",
      "[60] Processing: hold - hammer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input :  handle\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output hammer_000215.jpg:\n",
      " all_output Current - KLD: 1.0827 | SIM: 0.3544 | NSS: 2.3231\n",
      "\n",
      "Cumulative all_output  Averages over 61 samples:\n",
      "Average - KLD: 0.9844 | SIM: 0.4736 | NSS: 1.3949\n",
      "==================================================\n",
      "\n",
      "[61] Processing: eat - hot_dog\n",
      "Selected CLIP input : hot_dog\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output hot_dog_002166.jpg:\n",
      " all_output Current - KLD: 0.2865 | SIM: 0.7037 | NSS: 1.1316\n",
      "\n",
      "Cumulative all_output  Averages over 62 samples:\n",
      "Average - KLD: 0.9731 | SIM: 0.4773 | NSS: 1.3907\n",
      "==================================================\n",
      "\n",
      "[62] Processing: throw - javelin\n",
      "Selected CLIP input :  yellow\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output javelin_001474.jpg:\n",
      " all_output Current - KLD: 0.3226 | SIM: 0.7294 | NSS: 3.6087\n",
      "\n",
      "Cumulative all_output  Averages over 63 samples:\n",
      "Average - KLD: 0.9628 | SIM: 0.4813 | NSS: 1.4259\n",
      "==================================================\n",
      "\n",
      "[63] Processing: type_on - keyboard\n",
      "Selected CLIP input : keyboard\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output keyboard_000439.jpg:\n",
      " all_output Current - KLD: 0.2138 | SIM: 0.7666 | NSS: 1.4523\n",
      "\n",
      "Cumulative all_output  Averages over 64 samples:\n",
      "Average - KLD: 0.9511 | SIM: 0.4857 | NSS: 1.4263\n",
      "==================================================\n",
      "\n",
      "[64] Processing: cut_with - knife\n",
      "Selected CLIP input :  the\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output knife_001749.jpg:\n",
      " all_output Current - KLD: 0.6000 | SIM: 0.5534 | NSS: 2.1543\n",
      "\n",
      "Cumulative all_output  Averages over 65 samples:\n",
      "Average - KLD: 0.9457 | SIM: 0.4868 | NSS: 1.4375\n",
      "==================================================\n",
      "\n",
      "[65] Processing: hold - knife\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input : knife\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output knife_002682.jpg:\n",
      " all_output Current - KLD: 1.0232 | SIM: 0.3902 | NSS: 1.8405\n",
      "\n",
      "Cumulative all_output  Averages over 66 samples:\n",
      "Average - KLD: 0.9469 | SIM: 0.4853 | NSS: 1.4436\n",
      "==================================================\n",
      "\n",
      "[66] Processing: stick - knife\n",
      "Selected CLIP input : knife\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output knife_001072.jpg:\n",
      " all_output Current - KLD: 1.5174 | SIM: 0.2483 | NSS: 1.9480\n",
      "\n",
      "Cumulative all_output  Averages over 67 samples:\n",
      "Average - KLD: 0.9554 | SIM: 0.4818 | NSS: 1.4511\n",
      "==================================================\n",
      "\n",
      "[67] Processing: wash - knife\n",
      "Selected CLIP input : knife\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output knife_002720.jpg:\n",
      " all_output Current - KLD: 0.9273 | SIM: 0.4421 | NSS: 2.6447\n",
      "\n",
      "Cumulative all_output  Averages over 68 samples:\n",
      "Average - KLD: 0.9550 | SIM: 0.4812 | NSS: 1.4687\n",
      "==================================================\n",
      "\n",
      "[68] Processing: type_on - laptop\n",
      "Selected CLIP input :  keyboard\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output laptop_000585.jpg:\n",
      " all_output Current - KLD: 0.5253 | SIM: 0.5943 | NSS: 1.9482\n",
      "\n",
      "Cumulative all_output  Averages over 69 samples:\n",
      "Average - KLD: 0.9487 | SIM: 0.4828 | NSS: 1.4756\n",
      "==================================================\n",
      "\n",
      "[69] Processing: open - microwave\n",
      "Selected CLIP input :  the\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output microwave_001049.jpg:\n",
      " all_output Current - KLD: 1.1101 | SIM: 0.3776 | NSS: 1.0478\n",
      "\n",
      "Cumulative all_output  Averages over 70 samples:\n",
      "Average - KLD: 0.9510 | SIM: 0.4813 | NSS: 1.4695\n",
      "==================================================\n",
      "\n",
      "[70] Processing: push - motorcycle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input :  a\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output motorcycle_003541.jpg:\n",
      " all_output Current - KLD: 1.3411 | SIM: 0.3314 | NSS: 1.2066\n",
      "\n",
      "Cumulative all_output  Averages over 71 samples:\n",
      "Average - KLD: 0.9565 | SIM: 0.4792 | NSS: 1.4658\n",
      "==================================================\n",
      "\n",
      "[71] Processing: ride - motorcycle\n",
      "Selected CLIP input :  seat\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output motorcycle_002198.jpg:\n",
      " all_output Current - KLD: 1.1581 | SIM: 0.3682 | NSS: 1.4468\n",
      "\n",
      "Cumulative all_output  Averages over 72 samples:\n",
      "Average - KLD: 0.9593 | SIM: 0.4777 | NSS: 1.4655\n",
      "==================================================\n",
      "\n",
      "[72] Processing: sit_on - motorcycle\n",
      "Selected CLIP input :  the\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output motorcycle_000837.jpg:\n",
      " all_output Current - KLD: 1.3107 | SIM: 0.2949 | NSS: 2.7045\n",
      "\n",
      "Cumulative all_output  Averages over 73 samples:\n",
      "Average - KLD: 0.9641 | SIM: 0.4752 | NSS: 1.4825\n",
      "==================================================\n",
      "\n",
      "[73] Processing: cut - orange\n",
      "Selected CLIP input :  an\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output orange_001193.jpg:\n",
      " all_output Current - KLD: 0.9225 | SIM: 0.5922 | NSS: 1.2981\n",
      "\n",
      "Cumulative all_output  Averages over 74 samples:\n",
      "Average - KLD: 0.9636 | SIM: 0.4767 | NSS: 1.4800\n",
      "==================================================\n",
      "\n",
      "[74] Processing: eat - orange\n",
      "Selected CLIP input :  an\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output orange_001193.jpg:\n",
      " all_output Current - KLD: 0.8999 | SIM: 0.5980 | NSS: 1.3294\n",
      "\n",
      "Cumulative all_output  Averages over 75 samples:\n",
      "Average - KLD: 0.9627 | SIM: 0.4784 | NSS: 1.4780\n",
      "==================================================\n",
      "\n",
      "[75] Processing: peel - orange\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input : orange\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output orange_001193.jpg:\n",
      " all_output Current - KLD: 0.7340 | SIM: 0.6127 | NSS: 1.2876\n",
      "\n",
      "Cumulative all_output  Averages over 76 samples:\n",
      "Average - KLD: 0.9597 | SIM: 0.4801 | NSS: 1.4755\n",
      "==================================================\n",
      "\n",
      "[76] Processing: wash - orange\n",
      "Selected CLIP input : orange\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output orange_001193.jpg:\n",
      " all_output Current - KLD: 0.6870 | SIM: 0.6413 | NSS: 1.2487\n",
      "\n",
      "Cumulative all_output  Averages over 77 samples:\n",
      "Average - KLD: 0.9562 | SIM: 0.4822 | NSS: 1.4726\n",
      "==================================================\n",
      "\n",
      "[77] Processing: open - oven\n",
      "Selected CLIP input : oven\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output oven_001370.jpg:\n",
      " all_output Current - KLD: 1.1927 | SIM: 0.3395 | NSS: 1.1986\n",
      "\n",
      "Cumulative all_output  Averages over 78 samples:\n",
      "Average - KLD: 0.9592 | SIM: 0.4804 | NSS: 1.4690\n",
      "==================================================\n",
      "\n",
      "[78] Processing: write - pen\n",
      "Selected CLIP input : pen\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output pen_003590.jpg:\n",
      " all_output Current - KLD: 1.3988 | SIM: 0.2838 | NSS: 1.3488\n",
      "\n",
      "Cumulative all_output  Averages over 79 samples:\n",
      "Average - KLD: 0.9648 | SIM: 0.4779 | NSS: 1.4675\n",
      "==================================================\n",
      "\n",
      "[79] Processing: boxing - punching_bag\n",
      "Selected CLIP input :  red\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output punching_bag_001845.jpg:\n",
      " all_output Current - KLD: 0.4239 | SIM: 0.6336 | NSS: 0.6560\n",
      "\n",
      "Cumulative all_output  Averages over 80 samples:\n",
      "Average - KLD: 0.9580 | SIM: 0.4799 | NSS: 1.4574\n",
      "==================================================\n",
      "\n",
      "[80] Processing: kick - punching_bag\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input :  the\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output punching_bag_001639.jpg:\n",
      " all_output Current - KLD: 0.8855 | SIM: 0.4345 | NSS: 0.5756\n",
      "\n",
      "Cumulative all_output  Averages over 81 samples:\n",
      "Average - KLD: 0.9571 | SIM: 0.4793 | NSS: 1.4465\n",
      "==================================================\n",
      "\n",
      "[81] Processing: open - refrigerator\n",
      "Selected CLIP input :  the\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output refrigerator_002162.jpg:\n",
      " all_output Current - KLD: 1.0834 | SIM: 0.3736 | NSS: 1.1050\n",
      "\n",
      "Cumulative all_output  Averages over 82 samples:\n",
      "Average - KLD: 0.9587 | SIM: 0.4780 | NSS: 1.4423\n",
      "==================================================\n",
      "\n",
      "[82] Processing: catch - rugby_ball\n",
      "Selected CLIP input :  brown\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output rugby_ball_003522.jpg:\n",
      " all_output Current - KLD: 0.3486 | SIM: 0.6960 | NSS: 0.6167\n",
      "\n",
      "Cumulative all_output  Averages over 83 samples:\n",
      "Average - KLD: 0.9513 | SIM: 0.4806 | NSS: 1.4324\n",
      "==================================================\n",
      "\n",
      "[83] Processing: kick - rugby_ball\n",
      "Selected CLIP input :  a\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output rugby_ball_002080.jpg:\n",
      " all_output Current - KLD: 0.1966 | SIM: 0.7709 | NSS: 0.9354\n",
      "\n",
      "Cumulative all_output  Averages over 84 samples:\n",
      "Average - KLD: 0.9423 | SIM: 0.4841 | NSS: 1.4265\n",
      "==================================================\n",
      "\n",
      "[84] Processing: throw - rugby_ball\n",
      "Selected CLIP input : rugby_ball\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output rugby_ball_000001.jpg:\n",
      " all_output Current - KLD: 0.2823 | SIM: 0.7205 | NSS: 0.8934\n",
      "\n",
      "Cumulative all_output  Averages over 85 samples:\n",
      "Average - KLD: 0.9346 | SIM: 0.4869 | NSS: 1.4202\n",
      "==================================================\n",
      "\n",
      "[85] Processing: cut_with - scissors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input :  blades\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output scissors_002479.jpg:\n",
      " all_output Current - KLD: 1.4852 | SIM: 0.2570 | NSS: 1.2752\n",
      "\n",
      "Cumulative all_output  Averages over 86 samples:\n",
      "Average - KLD: 0.9410 | SIM: 0.4842 | NSS: 1.4185\n",
      "==================================================\n",
      "\n",
      "[86] Processing: hold - scissors\n",
      "Selected CLIP input :  finger\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output scissors_002479.jpg:\n",
      " all_output Current - KLD: 0.3897 | SIM: 0.6806 | NSS: 1.8663\n",
      "\n",
      "Cumulative all_output  Averages over 87 samples:\n",
      "Average - KLD: 0.9346 | SIM: 0.4865 | NSS: 1.4237\n",
      "==================================================\n",
      "\n",
      "[87] Processing: carry - skateboard\n",
      "Selected CLIP input : skateboard\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output skateboard_002668.jpg:\n",
      " all_output Current - KLD: 0.1699 | SIM: 0.7947 | NSS: 0.8651\n",
      "\n",
      "Cumulative all_output  Averages over 88 samples:\n",
      "Average - KLD: 0.9259 | SIM: 0.4900 | NSS: 1.4173\n",
      "==================================================\n",
      "\n",
      "[88] Processing: hold - skateboard\n",
      "Selected CLIP input : skateboard\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output skateboard_002387.jpg:\n",
      " all_output Current - KLD: 0.6562 | SIM: 0.5612 | NSS: 0.9405\n",
      "\n",
      "Cumulative all_output  Averages over 89 samples:\n",
      "Average - KLD: 0.9229 | SIM: 0.4908 | NSS: 1.4120\n",
      "==================================================\n",
      "\n",
      "[89] Processing: jump - skateboard\n",
      "Selected CLIP input : skateboard\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output skateboard_002387.jpg:\n",
      " all_output Current - KLD: 1.1076 | SIM: 0.3781 | NSS: 1.1192\n",
      "\n",
      "Cumulative all_output  Averages over 90 samples:\n",
      "Average - KLD: 0.9250 | SIM: 0.4895 | NSS: 1.4087\n",
      "==================================================\n",
      "\n",
      "[90] Processing: sit_on - skateboard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input :  the\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output skateboard_001460.jpg:\n",
      " all_output Current - KLD: 0.1988 | SIM: 0.7835 | NSS: 1.1397\n",
      "\n",
      "Cumulative all_output  Averages over 91 samples:\n",
      "Average - KLD: 0.9170 | SIM: 0.4927 | NSS: 1.4057\n",
      "==================================================\n",
      "\n",
      "[91] Processing: carry - skis\n",
      "Selected CLIP input :  sk\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output skis_002829.jpg:\n",
      " all_output Current - KLD: 2.3707 | SIM: 0.1269 | NSS: -0.2314\n",
      "\n",
      "Cumulative all_output  Averages over 92 samples:\n",
      "Average - KLD: 0.9328 | SIM: 0.4888 | NSS: 1.3879\n",
      "==================================================\n",
      "\n",
      "[92] Processing: hold - skis\n",
      "Selected CLIP input :  tips\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output skis_001357.jpg:\n",
      " all_output Current - KLD: 2.3867 | SIM: 0.1243 | NSS: 0.3840\n",
      "\n",
      "Cumulative all_output  Averages over 93 samples:\n",
      "Average - KLD: 0.9484 | SIM: 0.4848 | NSS: 1.3772\n",
      "==================================================\n",
      "\n",
      "[93] Processing: jump - skis\n",
      "Selected CLIP input :  ski\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output skis_002829.jpg:\n",
      " all_output Current - KLD: 2.2497 | SIM: 0.1398 | NSS: -0.1149\n",
      "\n",
      "Cumulative all_output  Averages over 94 samples:\n",
      "Average - KLD: 0.9623 | SIM: 0.4812 | NSS: 1.3613\n",
      "==================================================\n",
      "\n",
      "[94] Processing: pick_up - skis\n",
      "Selected CLIP input :  the\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output skis_001547.jpg:\n",
      " all_output Current - KLD: 2.5069 | SIM: 0.1189 | NSS: 0.2635\n",
      "\n",
      "Cumulative all_output  Averages over 95 samples:\n",
      "Average - KLD: 0.9785 | SIM: 0.4774 | NSS: 1.3497\n",
      "==================================================\n",
      "\n",
      "[95] Processing: carry - snowboard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input : snowboard\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output snowboard_001325.jpg:\n",
      " all_output Current - KLD: 1.5072 | SIM: 0.2706 | NSS: 2.0162\n",
      "\n",
      "Cumulative all_output  Averages over 96 samples:\n",
      "Average - KLD: 0.9840 | SIM: 0.4752 | NSS: 1.3567\n",
      "==================================================\n",
      "\n",
      "[96] Processing: hold - snowboard\n",
      "Selected CLIP input :  a\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output snowboard_001704.jpg:\n",
      " all_output Current - KLD: 1.8541 | SIM: 0.1968 | NSS: -0.1414\n",
      "\n",
      "Cumulative all_output  Averages over 97 samples:\n",
      "Average - KLD: 0.9930 | SIM: 0.4723 | NSS: 1.3412\n",
      "==================================================\n",
      "\n",
      "[97] Processing: jump - snowboard\n",
      "Selected CLIP input :  a\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output snowboard_001704.jpg:\n",
      " all_output Current - KLD: 1.2079 | SIM: 0.3606 | NSS: 0.0402\n",
      "\n",
      "Cumulative all_output  Averages over 98 samples:\n",
      "Average - KLD: 0.9952 | SIM: 0.4712 | NSS: 1.3279\n",
      "==================================================\n",
      "\n",
      "[98] Processing: catch - soccer_ball\n",
      "Selected CLIP input : soccer_ball\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output soccer_ball_003333.jpg:\n",
      " all_output Current - KLD: 0.1230 | SIM: 0.8398 | NSS: 1.3770\n",
      "\n",
      "Cumulative all_output  Averages over 99 samples:\n",
      "Average - KLD: 0.9864 | SIM: 0.4749 | NSS: 1.3284\n",
      "==================================================\n",
      "\n",
      "[99] Processing: kick - soccer_ball\n",
      "Selected CLIP input : soccer_ball\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output soccer_ball_001588.jpg:\n",
      " all_output Current - KLD: 0.0770 | SIM: 0.8899 | NSS: 2.3016\n",
      "\n",
      "Cumulative all_output  Averages over 100 samples:\n",
      "Average - KLD: 0.9773 | SIM: 0.4791 | NSS: 1.3382\n",
      "==================================================\n",
      "\n",
      "[100] Processing: drag - suitcase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input :  wheels\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output suitcase_002998.jpg:\n",
      " all_output Current - KLD: 3.9420 | SIM: 0.0292 | NSS: -0.1524\n",
      "\n",
      "Cumulative all_output  Averages over 101 samples:\n",
      "Average - KLD: 1.0066 | SIM: 0.4746 | NSS: 1.3234\n",
      "==================================================\n",
      "\n",
      "[101] Processing: hold - suitcase\n",
      "Selected CLIP input : opic\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output suitcase_003687.jpg:\n",
      " all_output Current - KLD: 1.1052 | SIM: 0.3780 | NSS: 1.7749\n",
      "\n",
      "Cumulative all_output  Averages over 102 samples:\n",
      "Average - KLD: 1.0076 | SIM: 0.4737 | NSS: 1.3278\n",
      "==================================================\n",
      "\n",
      "[102] Processing: open - suitcase\n",
      "Selected CLIP input :  zipper\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output suitcase_000520.jpg:\n",
      " all_output Current - KLD: 2.2725 | SIM: 0.1536 | NSS: -0.1863\n",
      "\n",
      "Cumulative all_output  Averages over 103 samples:\n",
      "Average - KLD: 1.0199 | SIM: 0.4706 | NSS: 1.3131\n",
      "==================================================\n",
      "\n",
      "[103] Processing: pack - suitcase\n",
      "Selected CLIP input :  leopard\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output suitcase_002212.jpg:\n",
      " all_output Current - KLD: 1.1077 | SIM: 0.3634 | NSS: 0.3752\n",
      "\n",
      "Cumulative all_output  Averages over 104 samples:\n",
      "Average - KLD: 1.0207 | SIM: 0.4695 | NSS: 1.3041\n",
      "==================================================\n",
      "\n",
      "[104] Processing: pick_up - suitcase\n",
      "Selected CLIP input :  top\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output suitcase_002493.jpg:\n",
      " all_output Current - KLD: 0.6786 | SIM: 0.5451 | NSS: 3.1760\n",
      "\n",
      "Cumulative all_output  Averages over 105 samples:\n",
      "Average - KLD: 1.0175 | SIM: 0.4702 | NSS: 1.3220\n",
      "==================================================\n",
      "\n",
      "[105] Processing: carry - surfboard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input :  black\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output surfboard_002422.jpg:\n",
      " all_output Current - KLD: 2.9562 | SIM: 0.0820 | NSS: -0.3632\n",
      "\n",
      "Cumulative all_output  Averages over 106 samples:\n",
      "Average - KLD: 1.0358 | SIM: 0.4666 | NSS: 1.3061\n",
      "==================================================\n",
      "\n",
      "[106] Processing: hold - surfboard\n",
      "Selected CLIP input : surfboard\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output surfboard_002631.jpg:\n",
      " all_output Current - KLD: 0.7178 | SIM: 0.4974 | NSS: 2.6803\n",
      "\n",
      "Cumulative all_output  Averages over 107 samples:\n",
      "Average - KLD: 1.0328 | SIM: 0.4669 | NSS: 1.3189\n",
      "==================================================\n",
      "\n",
      "[107] Processing: jump - surfboard\n",
      "Selected CLIP input : surfboard\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output surfboard_000658.jpg:\n",
      " all_output Current - KLD: 0.8878 | SIM: 0.4480 | NSS: 0.3956\n",
      "\n",
      "Cumulative all_output  Averages over 108 samples:\n",
      "Average - KLD: 1.0314 | SIM: 0.4667 | NSS: 1.3103\n",
      "==================================================\n",
      "\n",
      "[108] Processing: lie_on - surfboard\n",
      "Selected CLIP input : surfboard\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output surfboard_000221.jpg:\n",
      " all_output Current - KLD: 0.1053 | SIM: 0.8404 | NSS: 2.2709\n",
      "\n",
      "Cumulative all_output  Averages over 109 samples:\n",
      "Average - KLD: 1.0229 | SIM: 0.4701 | NSS: 1.3192\n",
      "==================================================\n",
      "\n",
      "[109] Processing: sit_on - surfboard\n",
      "Selected CLIP input : surfboard\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output surfboard_000010.jpg:\n",
      " all_output Current - KLD: 0.1517 | SIM: 0.7822 | NSS: 0.2937\n",
      "\n",
      "Cumulative all_output  Averages over 110 samples:\n",
      "Average - KLD: 1.0150 | SIM: 0.4730 | NSS: 1.3098\n",
      "==================================================\n",
      "\n",
      "[110] Processing: hit - tennis_racket\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input : tennis_racket\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output tennis_racket_002268.jpg:\n",
      " all_output Current - KLD: 3.4202 | SIM: 0.0595 | NSS: -0.4407\n",
      "\n",
      "Cumulative all_output  Averages over 111 samples:\n",
      "Average - KLD: 1.0367 | SIM: 0.4692 | NSS: 1.2941\n",
      "==================================================\n",
      "\n",
      "[111] Processing: hold - tennis_racket\n",
      "Selected CLIP input :  handle\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output tennis_racket_001785.jpg:\n",
      " all_output Current - KLD: 0.4499 | SIM: 0.6185 | NSS: 3.3179\n",
      "\n",
      "Cumulative all_output  Averages over 112 samples:\n",
      "Average - KLD: 1.0315 | SIM: 0.4706 | NSS: 1.3121\n",
      "==================================================\n",
      "\n",
      "[112] Processing: swing - tennis_racket\n",
      "Selected CLIP input :  handle\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output tennis_racket_003066.jpg:\n",
      " all_output Current - KLD: 0.8117 | SIM: 0.4755 | NSS: 2.0633\n",
      "\n",
      "Cumulative all_output  Averages over 113 samples:\n",
      "Average - KLD: 1.0295 | SIM: 0.4706 | NSS: 1.3188\n",
      "==================================================\n",
      "\n",
      "[113] Processing: brush_with - toothbrush\n",
      "Selected CLIP input :  br\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output toothbrush_001764.jpg:\n",
      " all_output Current - KLD: 1.5506 | SIM: 0.2412 | NSS: 2.6618\n",
      "\n",
      "Cumulative all_output  Averages over 114 samples:\n",
      "Average - KLD: 1.0341 | SIM: 0.4686 | NSS: 1.3306\n",
      "==================================================\n",
      "\n",
      "[114] Processing: hold - toothbrush\n",
      "Selected CLIP input : toothbrush\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output toothbrush_003341.jpg:\n",
      " all_output Current - KLD: 1.4237 | SIM: 0.2752 | NSS: 1.5176\n",
      "\n",
      "Cumulative all_output  Averages over 115 samples:\n",
      "Average - KLD: 1.0375 | SIM: 0.4669 | NSS: 1.3322\n",
      "==================================================\n",
      "\n",
      "[115] Processing: wash - toothbrush\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input : toothbrush\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output toothbrush_001991.jpg:\n",
      " all_output Current - KLD: 1.1178 | SIM: 0.3577 | NSS: 2.1331\n",
      "\n",
      "Cumulative all_output  Averages over 116 samples:\n",
      "Average - KLD: 1.0382 | SIM: 0.4660 | NSS: 1.3391\n",
      "==================================================\n",
      "\n",
      "[116] Processing: drink_with - wine_glass\n",
      "Selected CLIP input :  bowl\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output wine_glass_003343.jpg:\n",
      " all_output Current - KLD: 1.4712 | SIM: 0.2582 | NSS: 1.0559\n",
      "\n",
      "Cumulative all_output  Averages over 117 samples:\n",
      "Average - KLD: 1.0419 | SIM: 0.4642 | NSS: 1.3367\n",
      "==================================================\n",
      "\n",
      "[117] Processing: hold - wine_glass\n",
      "Selected CLIP input : wine_glass\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output wine_glass_002374.jpg:\n",
      " all_output Current - KLD: 0.9713 | SIM: 0.4086 | NSS: 1.2607\n",
      "\n",
      "Cumulative all_output  Averages over 118 samples:\n",
      "Average - KLD: 1.0413 | SIM: 0.4637 | NSS: 1.3360\n",
      "==================================================\n",
      "\n",
      "[118] Processing: pour - wine_glass\n",
      "Selected CLIP input : wine_glass\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output wine_glass_000186.jpg:\n",
      " all_output Current - KLD: 1.2017 | SIM: 0.3336 | NSS: 1.0309\n",
      "\n",
      "Cumulative all_output  Averages over 119 samples:\n",
      "Average - KLD: 1.0426 | SIM: 0.4626 | NSS: 1.3335\n",
      "==================================================\n",
      "\n",
      "[119] Processing: sip - wine_glass\n",
      "Selected CLIP input :  wine\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output wine_glass_003343.jpg:\n",
      " all_output Current - KLD: 1.6136 | SIM: 0.2341 | NSS: 0.8328\n",
      "\n",
      "Cumulative all_output  Averages over 120 samples:\n",
      "Average - KLD: 1.0474 | SIM: 0.4607 | NSS: 1.3293\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics_tracker_alloutput = MetricsTracker(name=\"all_output\")\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 저장할 디렉토리 생성\n",
    "Layername = \"top1_exp75\"\n",
    "output_dir = f\"./output_{Layername}\"  # 디렉토리 이름 변경 (구분 위해)s\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Contrastive Subtraction 강도 설정 (0.5 ~ 1.0 추천)\n",
    "\n",
    "POS_ALPHA = 0\n",
    "results_list = []\n",
    "pos_map = np.zeros((31, 31), dtype=np.float32)\n",
    "for i in range(24):\n",
    "    i += 1\n",
    "    pkl_path = f\"output_results/attention_result_full_output_32B_{i}.pkl\"\n",
    "    if not os.path.exists(pkl_path):\n",
    "        continue\n",
    "        \n",
    "    df_output = pd.read_pickle(pkl_path)\n",
    "\n",
    "    for idx, row in df_output.iterrows():\n",
    "        object_name = row['object']\n",
    "        action = row['action']\n",
    "        filename = row['filename']\n",
    "        output_description = row['output_sentence']\n",
    "        output_attentions = row['output_attentions']\n",
    "        PLSP_name = prompt_dict_obj[action][object_name]\n",
    "        \n",
    "        file_name_real = f\"{AGD20K_PATH}/Seen/testset/egocentric/{action}/{object_name}/{filename}\"\n",
    "        gt_path = f\"{AGD20K_PATH}/Seen/testset/GT/{action}/{object_name}/{filename.split('.')[0]}.png\"\n",
    "            \n",
    "        # 이미지 로드\n",
    "        if not os.path.exists(file_name_real):\n",
    "            print(f\"Image not found: {file_name_real}\")\n",
    "            continue\n",
    "\n",
    "        orig_img = cv2.imread(file_name_real)\n",
    "        orig_img = cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB)\n",
    "        h, w, _ = orig_img.shape\n",
    "\n",
    "        print(f\"[{idx}] Processing: {action} - {object_name}\")\n",
    "\n",
    "        # --- 1. CLIPSeg Mask 생성 ---\n",
    "\n",
    "        # clip_heatmap = get_clipseg_heatmap(\n",
    "        #     file_name_real,\n",
    "        #     clip_model,\n",
    "        #     clip_processor,\n",
    "        #     object_name,\n",
    "        #     # PLSP_name,\n",
    "        # )\n",
    "\n",
    "        # # CLIPSeg 결과를 31x31로 리사이즈\n",
    "        # clip_heatmap_resized = cv2.resize(clip_heatmap, (31, 31), interpolation=cv2.INTER_LINEAR)\n",
    "        # clip_binary_mask = (clip_heatmap_resized > 0.15).astype(np.float32) # 필요시 사용\n",
    "\n",
    "        # --- 2. [변경] Contrastive Attention Map 계산 ---\n",
    "        token_scores = []\n",
    "        token_idx = 0\n",
    "        for token in output_attentions:\n",
    "            # 토큰별 히트맵 초기화\n",
    "            token_heatmap = np.zeros((31, 31), dtype=np.float32)\n",
    "            token_head_count = 0\n",
    "            \n",
    "            attention_value = token['attentions']\n",
    "            decoded_str = token['token_str'] # 디버깅용\n",
    "\n",
    "            for each_attention in attention_value:\n",
    "                layer = each_attention['layer']\n",
    "                head = each_attention['head']\n",
    "                \n",
    "                # # 사용자가 설정한 특정 레이어 필터링 (여기선 Layer 0 유지)\n",
    "                # if each_attention['layer'] != 0:\n",
    "                if 1==1: # (layer <=45) and (layer >= 20): #1==1: # (layer == 26) : #and( head ==20)) : #or ((layer == 24) and( head ==31)):\n",
    "                    \n",
    "                    token_heatmap += each_attention['heatmap']\n",
    "                    token_head_count += 1\n",
    "\n",
    "                    # ## 부터 : 매 레이어헤드의 맥스값을 죽이기\n",
    "                    # all_token_heatmap = each_attention['heatmap'].copy()\n",
    "\n",
    "                    # # 2. 현재 히트맵에서 최대값을 찾습니다.\n",
    "                    # max_value = np.max(current_heatmap)\n",
    "\n",
    "                    # # 3. 불리언 인덱싱을 사용하여 최대값과 같은 모든 위치를 0으로 설정합니다.\n",
    "                    # # (최대값이 여러 개일 경우 모두 0으로 바뀝니다.)\n",
    "                    # all_token_heatmap[all_token_heatmap == max_value] = 0\n",
    "                    # token_heatmap += current_heatmap\n",
    "                    # ## 까지\n",
    "                    # # minmax_each = min_max_normalize(each_attention['heatmap'])\n",
    "                    # # sum_heatmap += minmax_each\n",
    "                    # token_head_count += 1\n",
    "\n",
    "\n",
    "            \n",
    "            # 해당 레이어의 헤드가 하나도 없으면 스킵\n",
    "            if token_head_count == 0:\n",
    "                continue\n",
    "\n",
    "            # Visual Dependency Score (S_img) 계산: 맵의 총합\n",
    "            s_img = token_heatmap.sum()\n",
    "            ## clipseg랑 얼마냐 비슷하나로 점수 뽑기\n",
    "            # flat_token = token_heatmap.flatten()\n",
    "            # flat_clip = clip_heatmap_resized.flatten()\n",
    "\n",
    "            # norm_token = np.linalg.norm(flat_token)\n",
    "            # norm_clip = np.linalg.norm(flat_clip)\n",
    "    \n",
    "            # s_img = np.dot(flat_token, flat_clip) / (norm_token * norm_clip)\n",
    "            \n",
    "            # 리스트에 저장\n",
    "            token_scores.append({\n",
    "                \"token\": decoded_str,\n",
    "                \"token_idx\" : token_idx,\n",
    "                \"score\": s_img,\n",
    "                \"heatmap\": token_heatmap, \n",
    "                \"count\": token_head_count\n",
    "            })\n",
    "            token_idx +=1\n",
    "        # 예외 처리: 토큰이 없을 경우\n",
    "        if len(token_scores) == 0:\n",
    "            print(\"No valid tokens found.\")\n",
    "            continue\n",
    "\n",
    "        # 정렬 (Score 기준 오름차순)\n",
    "        sorted_tokens = sorted(token_scores, key=lambda x: x['score'])\n",
    "        \n",
    "        # Top 5 (Signal) & Bottom 5 (Noise) 선정\n",
    "        # 토큰 개수가 10개 미만일 경우 처리\n",
    "        num_select = min(1, len(sorted_tokens) // 2)\n",
    "        if num_select < 1: num_select = 1 # 최소 1개\n",
    "\n",
    "        bottom_tokens = sorted_tokens[:num_select]       # Noise (기능어, 배경 등)\n",
    "        top_tokens = sorted_tokens[-num_select:][::-1]   # Signal (명사, 핵심어)\n",
    "\n",
    "        top_token_idx  = top_tokens[-1]['token_idx']\n",
    "        top_token_text  = top_tokens[-1]['token']\n",
    "\n",
    "        following_token_idx = top_token_idx + 1\n",
    "        following_token = None\n",
    "        for item in token_scores:\n",
    "            if item['token_idx'] == following_token_idx:\n",
    "                following_token = item\n",
    "                break\n",
    "        following_text = following_token['token']\n",
    "\n",
    "        ## 꺼꾸로 last 뽑기\n",
    "        # top_tokens = sorted_tokens[:num_select]       # Noise (기능어, 배경 등)\n",
    "        # bottom_tokens = sorted_tokens[-num_select:][::-1]   # Signal (명사, 핵심어)\n",
    "        # clipseg_input_text = object_name #top_token_text #+ ' ' + following_text\n",
    "        clip_object_heatmap = get_clipseg_heatmap(\n",
    "            file_name_real,\n",
    "            clip_model,\n",
    "            clip_processor,\n",
    "            object_name,\n",
    "        )\n",
    "\n",
    "        clip_top_heatmap = get_clipseg_heatmap(\n",
    "            file_name_real,\n",
    "            clip_model,\n",
    "            clip_processor,\n",
    "            top_token_text + ' ' + following_text,\n",
    "        )\n",
    "        pos_map = np.sum([t['heatmap'] for t in top_tokens], axis=0)\n",
    "        pos_map /= len(top_tokens)\n",
    "        # --- [수정] 특정 Layer(26) / Head(20)만 사용하여 pos_map 생성 ---\n",
    "\n",
    "        # pos_map = np.zeros((31, 31), dtype=np.float32)\n",
    "        # found_count = 0\n",
    "\n",
    "        # # 선별된 Top Token(Signal)들에 대해서만 루프\n",
    "        # for t_info in top_tokens:\n",
    "        #     t_idx = t_info['token_idx']\n",
    "            \n",
    "        #     # 해당 토큰의 원본 어텐션 리스트 가져오기\n",
    "        #     raw_attentions = output_attentions[t_idx]['attentions']\n",
    "\n",
    "        #     for attn_item in raw_attentions:\n",
    "        #         # 조건: Layer 26, Head 20 인 경우만 추출\n",
    "        #         if attn_item['layer'] == 26 and attn_item['head'] == 20:\n",
    "        #             pos_map += attn_item['heatmap']\n",
    "        #             found_count += 1\n",
    "        \n",
    "        # # 평균 계산 (발견된 개수로 나누기)\n",
    "        # if found_count > 0:\n",
    "        #     pos_map /= found_count\n",
    "        # else:\n",
    "        #     print(\"Warning: Layer 26, Head 20 was not found in the selected tokens.\")\n",
    "\n",
    "        # if following_token is not None:            \n",
    "        #     # 직전 토큰의 히트맵을 pos_map에 더하기 (가중치 0.5~1.0 추천, 필요시 튜닝)\n",
    "        #     weight_prev = 1  # 조절 가능 (0.5~1.0 사이 추천)\n",
    "        #     pos_map =(pos_map + weight_prev * following_token['heatmap'])/2\n",
    "            \n",
    "        #     # 정규화 (덧셈 후 다시 normalize - 중요!)\n",
    "        #     pos_map = pos_map / pos_map.max() if pos_map.max() > 0 else pos_map\n",
    "        # else:\n",
    "        #     raise ValueError(\"No following token found\")\n",
    "\n",
    "\n",
    "\n",
    "        # Noise Map (Negative) 평균\n",
    "        neg_map = np.sum([t['heatmap'] for t in bottom_tokens], axis=0)\n",
    "        neg_map /= len(bottom_tokens)\n",
    "\n",
    "\n",
    "        # # --- 🔥 추가: neg_map에서 상위 95%만 남기는 sink-like filtering ---\n",
    "        # # 1) 95 percentile threshold 계산\n",
    "        # threshold_95 = np.percentile(neg_map, 95)\n",
    "\n",
    "        # # 2) threshold 미만은 0으로 제거\n",
    "        # neg_map_filtered = np.where(neg_map >= threshold_95, neg_map, 0)\n",
    "\n",
    "        # # 3) 정규화 (0~1로)\n",
    "        # if neg_map_filtered.max() > 0:\n",
    "        #     neg_map_filtered = neg_map_filtered / neg_map_filtered.max()\n",
    "\n",
    "        # # 기존 contrastive 계산에 filtered map 사용\n",
    "        # neg_map = neg_map_filtered\n",
    "\n",
    "\n",
    "        # 정규화 (스케일 맞추기 위해 0~1로 변환 후 뺄셈 진행)\n",
    "        if pos_map.max() > 0: pos_map /= pos_map.max()\n",
    "        if neg_map.max() > 0: neg_map /= neg_map.max()\n",
    "\n",
    "        # ✨ Contrastive Subtraction (Signal - alpha * Noise)\n",
    "        CONTRASTIVE_ALPHA = 0\n",
    "        contrastive_heatmap = (pos_map) - (CONTRASTIVE_ALPHA * neg_map)\n",
    "        # contrastive_heatmap_threshold_5 = np.percentile(contrastive_heatmap, 5)\n",
    "        # contrastive_heatmap = np.where(contrastive_heatmap <= contrastive_heatmap_threshold_5, contrastive_heatmap_threshold_5, contrastive_heatmap)\n",
    "        # contrastive_heatmap = np.maximum(contrastive_heatmap, 0) # ReLU (음수 제거)\n",
    "\n",
    "        # --- 3. 정규화 및 후처리 (기존 코드 흐름 연결) ---\n",
    "        # Contrastive Map을 avg_norm 변수로 사용 (0~1 정규화)\n",
    "        h_min, h_max = contrastive_heatmap.min(), contrastive_heatmap.max()\n",
    "        \n",
    "        # upper_threshold = np.percentile(contrastive_heatmap, 80)\n",
    "        # contrastive_heatmap[contrastive_heatmap > upper_threshold] = upper_threshold\n",
    "\n",
    "        # lower_threshold = np.percentile(contrastive_heatmap, 50)\n",
    "        # contrastive_heatmap[contrastive_heatmap < lower_threshold] = lower_threshold\n",
    "\n",
    "        \n",
    "        avg_norm = (contrastive_heatmap - h_min) / (h_max - h_min + 1e-8)\n",
    "\n",
    "        if check_heatmap_containment(clip_top_heatmap,clip_object_heatmap):\n",
    "            clip_heatmap = clip_top_heatmap\n",
    "            clipseg_input_text = top_token_text+ ' ' + following_text\n",
    "            print(f\"Selected CLIP input : {top_token_text}\")\n",
    "            # Signal Map (Positive) 평균\n",
    "\n",
    "\n",
    "\n",
    "        else:\n",
    "            clip_heatmap = clip_object_heatmap\n",
    "            clipseg_input_text = object_name\n",
    "            # h_min, h_max = token_heatmap.min(), token_heatmap.max()\n",
    "            # avg_norm = (token_heatmap - h_min) / (h_max - h_min + 1e-8)\n",
    "\n",
    "            print(f\"Selected CLIP input : {object_name}\")\n",
    "\n",
    "        # clip_heatmap = get_clipseg_heatmap(\n",
    "        #     file_name_real,\n",
    "        #     clip_model,\n",
    "        #     clip_processor,\n",
    "        #     PLSP_name,\n",
    "        # )\n",
    "        # CLIPSeg 결과를 31x31로 리사이즈\n",
    "        clip_heatmap_resized = cv2.resize(clip_heatmap, (31, 31), interpolation=cv2.INTER_LINEAR)\n",
    "        clip_binary_mask = (clip_heatmap_resized > 0.15).astype(np.float32) # 필요시 사용\n",
    "\n",
    "        \n",
    "        # clip_heatmap = get_clipseg_heatmap(\n",
    "        #     file_name_real,\n",
    "        #     clip_model,\n",
    "        #     clip_processor,\n",
    "        #     clipseg_input_text,\n",
    "            \n",
    "        # )\n",
    "\n",
    "        # # CLIPSeg 결과를 31x31로 리사이즈\n",
    "        # clip_heatmap_resized = cv2.resize(clip_heatmap, (31, 31), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "\n",
    "        # CLIPSeg와 Hadamard Product\n",
    "        avg_norm_cliped = avg_norm * clip_heatmap_resized\n",
    "        gamma =  0.75  # 0\n",
    "        avg_norm_cliped = np.power(avg_norm_cliped, gamma)\n",
    "        # 리사이즈 및 블러링\n",
    "        avg_norm_cliped_rescaled = cv2.resize(avg_norm_cliped, (w, h), interpolation=cv2.INTER_LINEAR)\n",
    "        \n",
    "        sig = min(w, h) * 0.05\n",
    "        k_val = int(sig * 3) * 2 + 1 \n",
    "        kernel_size = (k_val, k_val)\n",
    "\n",
    "        # 블러 적용\n",
    "        blur_map = cv2.GaussianBlur(avg_norm_cliped_rescaled, kernel_size, sig)\n",
    "\n",
    "        # 블러 후 다시 정규화\n",
    "        blur_map = min_max_normalize(blur_map) # 함수가 정의되어 있다고 가정\n",
    "        avg_norm_cliped_blur = blur_map\n",
    "        \n",
    "        # 시각화를 위해 31x31 맵도 원본 크기로 리사이즈\n",
    "        avg_norm_resized_vis = cv2.resize(avg_norm, (w, h), interpolation=cv2.INTER_LINEAR)\n",
    "        clip_vis = cv2.resize(clip_heatmap_resized, (w, h), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        # --- 4. GT 평가 및 메트릭 계산 ---\n",
    "        gt_map = load_ground_truth(gt_path) # 함수 정의 가정\n",
    "        if gt_map is not None:\n",
    "            metrics_dino = calculate_metrics(avg_norm_cliped_blur, gt_map) # 함수 정의 가정\n",
    "            metrics_tracker_alloutput.update(metrics_dino) # 객체 정의 가정\n",
    "            \n",
    "            # 메트릭 텍스트\n",
    "            metrics_text = f\"[{object_name} {action}] KLD: {metrics_dino['KLD']:.4f} | SIM: {metrics_dino['SIM']:.4f} | NSS: {metrics_dino['NSS']:.4f}\"\n",
    "            metrics_tracker_alloutput.print_metrics(metrics_dino, filename)\n",
    "        else:\n",
    "            print(\"NO GT!!!\")\n",
    "            metrics_text = \"No GT Available\"\n",
    "            continue\n",
    "        \n",
    "        results_list.append({\n",
    "            'object': object_name,\n",
    "            'action': action,\n",
    "            'filename': filename,\n",
    "            'output_sentence': output_description,\n",
    "            'top_token_text': top_token_text,\n",
    "            'following_text': following_text,\n",
    "            'clip_input': clipseg_input_text,\n",
    "            'KLD': metrics_dino['KLD'],\n",
    "            'SIM': metrics_dino['SIM'],\n",
    "            'NSS': metrics_dino['NSS']\n",
    "        })\n",
    "\n",
    "        # --- 5. 시각화 ---\n",
    "        fig, axes = plt.subplots(1, 6, figsize=(24, 5)) # 사이즈 살짝 조정\n",
    "        \n",
    "        # Signal 단어와 Noise 단어 표시 (제목용)\n",
    "        top_words = \",\".join([f\"'{t['token'].strip()}'\" for t in top_tokens[:5]])\n",
    "        \n",
    "        main_title = f\"Obj: {object_name} | Act: {action} |{metrics_text}\\nTop Tokens: [{top_words}({top_token_idx } ), clipseg input : {top_token_text} {following_text}] \\n Whole answer : {output_description}\"\n",
    "        fig.suptitle(main_title, fontsize=14, fontweight='bold', y=0.98)\n",
    "\n",
    "        # (1) 원본 이미지\n",
    "        axes[0].imshow(orig_img)\n",
    "        axes[0].set_title(f\"Original\\n({object_name})\")\n",
    "        axes[0].axis('off')\n",
    "\n",
    "        # (2) Contrastive Attention (Pos - Neg)\n",
    "        im1 = axes[1].imshow(avg_norm_resized_vis, cmap='jet', interpolation='bilinear')\n",
    "        axes[1].set_title(f\"Attention Map {Layername}\")\n",
    "        axes[1].axis('off')\n",
    "        plt.colorbar(im1, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "\n",
    "        # (3) CLIPSeg Result\n",
    "        axes[2].imshow(clip_vis, cmap='gray')\n",
    "        axes[2].set_title(f\"CLIPSeg {clipseg_input_text}\")\n",
    "        axes[2].axis('off')\n",
    "\n",
    "        # (4) Hadamard (Contrastive x CLIPSeg)\n",
    "        # 리사이즈하여 시각화\n",
    "        hadamard_vis = cv2.resize(avg_norm_cliped, (w, h), interpolation=cv2.INTER_LINEAR)\n",
    "        im3 = axes[3].imshow(hadamard_vis, cmap='jet', interpolation='bilinear')\n",
    "        axes[3].set_title(\"Hadamard\\n(Contrastive x CLIP)\")\n",
    "        axes[3].axis('off')\n",
    "        plt.colorbar(im3, ax=axes[3], fraction=0.046, pad=0.04)\n",
    "\n",
    "        # (5) Final Blurred Result\n",
    "        im4 = axes[4].imshow(avg_norm_cliped_blur, cmap='jet', interpolation='bilinear')\n",
    "        axes[4].set_title(\"Final Blurred\")\n",
    "        axes[4].axis('off')\n",
    "        plt.colorbar(im4, ax=axes[4], fraction=0.046, pad=0.04)\n",
    "\n",
    "        # (6) Ground Truth\n",
    "        axes[5].imshow(gt_map, cmap='gray') # GT는 보통 binary 혹은 gray\n",
    "        axes[5].set_title(\"Ground Truth\")\n",
    "        axes[5].axis('off')\n",
    "\n",
    "        # 파일 저장\n",
    "        save_path = os.path.join(output_dir, f\"{object_name}_{action}_{filename.split('.')[0]}.png\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path, bbox_inches='tight', dpi=150)\n",
    "        plt.close(fig)\n",
    "\n",
    "df_analy = pd.DataFrame(results_list)\n",
    "df_analy.to_pickle(\"output_attention_analysis_filtered_clip_exp075_namable.pkl\")\n",
    "        # print(f\"clipseg_input_text : {clipseg_input_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a3ebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP 90 : Average - KLD: 1.1244 | SIM: 0.4453 | NSS: 1.2122\n",
    "TOP 95 : Average - KLD: 1.1112 | SIM: 0.4485 | NSS: 1.2430\n",
    "TOP 99 : KLD: 1.0911 | SIM: 0.4547 | NSS: 1.2855\n",
    "TOP 99 Bottom 50 : KLD: 1.0911 | SIM: 0.4547 | NSS: 1.2855\n",
    "TOP 80 Bottom 50 :KLD: 1.1480 | SIM: 0.4391 | NSS: 1.1538\n",
    "ALL_token_exp075 :KLD: 1.2934 | SIM: 0.3905 | NSS: 0.9825\n",
    "TOP1 : 1.0901 | SIM: 0.4564 | NSS: 1.2929\n",
    "TOP1_exp0.75 : KLD: 1.0885 | SIM: 0.4532 | NSS: 1.2754\n",
    "TOP1_real_exp0.5 : KLD: 1.1299 | SIM: 0.4168 | NSS: 1.3019\n",
    "CLIP_fillter top1 :  KLD: 1.0788 | SIM: 0.4702 | NSS: 1.2851\n",
    "CLIP_fillter top1+following :  KLD: 1.0782 | SIM: 0.4732 | NSS: 1.2873\n",
    "CLIP_fillter top1+following_exp0.3 : KLD: 1.0730 | SIM: 0.4661 | NSS: 1.2646\n",
    "CLIP_fillter top1+following_exp0.75 :  KLD: 1.0625 | SIM: 0.4734 | NSS: 1.2900\n",
    "CLIP_fillter top1+following_exp0.75_real :  KLD: 1.0474 | SIM: 0.4607 | NSS: 1.3293\n",
    "CLIP_fillter top1+following_exp0.75_real_namable :  KLD: 1.1120 | SIM: 0.4399 | NSS: 1.2498\n",
    "CLIP_fillter top1+following_ININ_exp0.75_real :  KLD: 1.0567 | SIM: 0.4571 | NSS: 1.3125\n",
    "CLIP_fillter top1+following_exp0.5_real :  KLD: 1.0970 | SIM: 0.4276 | NSS: 1.3465\n",
    "CLIP_fillter top1+following_exp2 :  Average - KLD: 1.5235 | SIM: 0.4005 | NSS: 0.9573\n",
    "\n",
    "CLIP_fillter PLSP_exp0.75_real :  KLD: 1.0015 | SIM: 0.4608 | NSS: 1.4040"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec9eb2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analy.to_csv(\"results_top1_following_gamma.csv\",sep=\"$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db9b6ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['object', 'action', 'filename', 'output_sentence', 'top_token_text',\n",
       "       'following_text', 'clip_input', 'KLD', 'SIM', 'NSS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9879dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object</th>\n",
       "      <th>action</th>\n",
       "      <th>filename</th>\n",
       "      <th>output_sentence</th>\n",
       "      <th>top_token_text</th>\n",
       "      <th>following_text</th>\n",
       "      <th>clip_input</th>\n",
       "      <th>KLD</th>\n",
       "      <th>SIM</th>\n",
       "      <th>NSS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple</td>\n",
       "      <td>cut</td>\n",
       "      <td>apple_000054.jpg</td>\n",
       "      <td>When people cut an apple, they typically use t...</td>\n",
       "      <td>an</td>\n",
       "      <td>apple</td>\n",
       "      <td>apple</td>\n",
       "      <td>0.953323</td>\n",
       "      <td>0.604613</td>\n",
       "      <td>0.680869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>banana</td>\n",
       "      <td>cut</td>\n",
       "      <td>banana_002623.jpg</td>\n",
       "      <td>The peel of the banana is typically removed be...</td>\n",
       "      <td>peel</td>\n",
       "      <td>of</td>\n",
       "      <td>banana</td>\n",
       "      <td>0.152788</td>\n",
       "      <td>0.782200</td>\n",
       "      <td>1.407556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>banana</td>\n",
       "      <td>eat</td>\n",
       "      <td>banana_002458.jpg</td>\n",
       "      <td>The inner flesh of the banana, which is the so...</td>\n",
       "      <td>inner</td>\n",
       "      <td>flesh</td>\n",
       "      <td>banana</td>\n",
       "      <td>0.093214</td>\n",
       "      <td>0.834037</td>\n",
       "      <td>1.719909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>baseball</td>\n",
       "      <td>throw</td>\n",
       "      <td>baseball_002670.jpg</td>\n",
       "      <td>The entire baseball is used for throwing, but ...</td>\n",
       "      <td>raised</td>\n",
       "      <td>stitching</td>\n",
       "      <td>baseball</td>\n",
       "      <td>0.137434</td>\n",
       "      <td>0.815854</td>\n",
       "      <td>3.191665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>baseball_bat</td>\n",
       "      <td>hit</td>\n",
       "      <td>baseball_bat_001882.jpg</td>\n",
       "      <td>The barrel, which is the thick, rounded end of...</td>\n",
       "      <td>barrel</td>\n",
       "      <td>,</td>\n",
       "      <td>baseball_bat</td>\n",
       "      <td>2.214648</td>\n",
       "      <td>0.137202</td>\n",
       "      <td>0.184698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>baseball_bat</td>\n",
       "      <td>hold</td>\n",
       "      <td>baseball_bat_002547.jpg</td>\n",
       "      <td>The handle of the baseball bat is used for hol...</td>\n",
       "      <td>handle</td>\n",
       "      <td>of</td>\n",
       "      <td>baseball_bat</td>\n",
       "      <td>2.026475</td>\n",
       "      <td>0.163947</td>\n",
       "      <td>1.701513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>baseball_bat</td>\n",
       "      <td>swing</td>\n",
       "      <td>baseball_bat_001882.jpg</td>\n",
       "      <td>The barrel of the baseball_bat is used for swi...</td>\n",
       "      <td>barrel</td>\n",
       "      <td>of</td>\n",
       "      <td>baseball_bat</td>\n",
       "      <td>2.146138</td>\n",
       "      <td>0.146076</td>\n",
       "      <td>0.247262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>basketball</td>\n",
       "      <td>throw</td>\n",
       "      <td>basketball_003534.jpg</td>\n",
       "      <td>When people throw a basketball, they use their...</td>\n",
       "      <td>a</td>\n",
       "      <td>basketball</td>\n",
       "      <td>basketball</td>\n",
       "      <td>0.268886</td>\n",
       "      <td>0.740719</td>\n",
       "      <td>3.487939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bench</td>\n",
       "      <td>lie_on</td>\n",
       "      <td>bench_003727.jpg</td>\n",
       "      <td>The seat of the bench is used for lying on.</td>\n",
       "      <td>seat</td>\n",
       "      <td>of</td>\n",
       "      <td>bench</td>\n",
       "      <td>0.716610</td>\n",
       "      <td>0.514579</td>\n",
       "      <td>1.208419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bench</td>\n",
       "      <td>sit_on</td>\n",
       "      <td>bench_001877.jpg</td>\n",
       "      <td>The flat, horizontal slats on the top surface ...</td>\n",
       "      <td>flat</td>\n",
       "      <td>,</td>\n",
       "      <td>bench</td>\n",
       "      <td>0.057316</td>\n",
       "      <td>0.881795</td>\n",
       "      <td>1.778349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>binoculars</td>\n",
       "      <td>look_out</td>\n",
       "      <td>binoculars_003630.jpg</td>\n",
       "      <td>The eyepieces (the smaller lenses at the front...</td>\n",
       "      <td>ey</td>\n",
       "      <td>ep</td>\n",
       "      <td>binoculars</td>\n",
       "      <td>1.109505</td>\n",
       "      <td>0.376979</td>\n",
       "      <td>0.456978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>book</td>\n",
       "      <td>hold</td>\n",
       "      <td>book_001195.jpg</td>\n",
       "      <td>People typically use the **cover and spine** o...</td>\n",
       "      <td>the</td>\n",
       "      <td>**</td>\n",
       "      <td>book</td>\n",
       "      <td>0.696297</td>\n",
       "      <td>0.534425</td>\n",
       "      <td>1.226442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>book</td>\n",
       "      <td>open</td>\n",
       "      <td>book_003044.jpg</td>\n",
       "      <td>The spine of the book is used for 'open' when ...</td>\n",
       "      <td>spine</td>\n",
       "      <td>of</td>\n",
       "      <td>book</td>\n",
       "      <td>0.594520</td>\n",
       "      <td>0.540672</td>\n",
       "      <td>2.472611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>bottle</td>\n",
       "      <td>hold</td>\n",
       "      <td>bottle_001227.jpg</td>\n",
       "      <td>People typically hold a bottle by its neck or ...</td>\n",
       "      <td>a</td>\n",
       "      <td>bottle</td>\n",
       "      <td>bottle</td>\n",
       "      <td>0.365511</td>\n",
       "      <td>0.676896</td>\n",
       "      <td>1.801573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>bottle</td>\n",
       "      <td>pour</td>\n",
       "      <td>bottle_002780.jpg</td>\n",
       "      <td>The narrow spout or tip of the bottle is used ...</td>\n",
       "      <td>sp</td>\n",
       "      <td>out</td>\n",
       "      <td>bottle</td>\n",
       "      <td>2.560700</td>\n",
       "      <td>0.136236</td>\n",
       "      <td>-0.123696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>bowl</td>\n",
       "      <td>hold</td>\n",
       "      <td>bowl_000546.jpg</td>\n",
       "      <td>The rim or edge of the bowl is typically used ...</td>\n",
       "      <td>rim</td>\n",
       "      <td>or</td>\n",
       "      <td>bowl</td>\n",
       "      <td>0.181379</td>\n",
       "      <td>0.755979</td>\n",
       "      <td>0.826717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>bowl</td>\n",
       "      <td>stir</td>\n",
       "      <td>bowl_000134.jpg</td>\n",
       "      <td>The interior surface of the bowl, specifically...</td>\n",
       "      <td>interior</td>\n",
       "      <td>surface</td>\n",
       "      <td>bowl</td>\n",
       "      <td>1.396722</td>\n",
       "      <td>0.369197</td>\n",
       "      <td>0.452302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>bowl</td>\n",
       "      <td>wash</td>\n",
       "      <td>bowl_002825.jpg</td>\n",
       "      <td>The interior surface of the bowl is used for w...</td>\n",
       "      <td>interior</td>\n",
       "      <td>surface</td>\n",
       "      <td>bowl</td>\n",
       "      <td>0.843469</td>\n",
       "      <td>0.497629</td>\n",
       "      <td>0.441300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>broccoli</td>\n",
       "      <td>eat</td>\n",
       "      <td>broccoli_002796.jpg</td>\n",
       "      <td>People typically eat the florets and stalks of...</td>\n",
       "      <td>the</td>\n",
       "      <td>flo</td>\n",
       "      <td>broccoli</td>\n",
       "      <td>0.187420</td>\n",
       "      <td>0.749665</td>\n",
       "      <td>1.507471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>carrot</td>\n",
       "      <td>cut</td>\n",
       "      <td>carrot_001443.jpg</td>\n",
       "      <td>The part of the carrot used for 'cut' is the s...</td>\n",
       "      <td>a</td>\n",
       "      <td>knife</td>\n",
       "      <td>carrot</td>\n",
       "      <td>0.868247</td>\n",
       "      <td>0.471963</td>\n",
       "      <td>2.850394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>carrot</td>\n",
       "      <td>eat</td>\n",
       "      <td>carrot_001443.jpg</td>\n",
       "      <td>The edible part of the carrot used for eating ...</td>\n",
       "      <td>the</td>\n",
       "      <td>cutting</td>\n",
       "      <td>carrot</td>\n",
       "      <td>0.952182</td>\n",
       "      <td>0.433952</td>\n",
       "      <td>2.679701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>carrot</td>\n",
       "      <td>peel</td>\n",
       "      <td>carrot_003707.jpg</td>\n",
       "      <td>The outer skin or rind of the carrot is peeled...</td>\n",
       "      <td>a</td>\n",
       "      <td>knife</td>\n",
       "      <td>carrot</td>\n",
       "      <td>0.303778</td>\n",
       "      <td>0.702846</td>\n",
       "      <td>2.085634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>cell_phone</td>\n",
       "      <td>talk_on</td>\n",
       "      <td>cell_phone_000601.jpg</td>\n",
       "      <td>The microphone and speaker of the cell phone a...</td>\n",
       "      <td>microphone</td>\n",
       "      <td>and</td>\n",
       "      <td>cell_phone</td>\n",
       "      <td>0.750690</td>\n",
       "      <td>0.484189</td>\n",
       "      <td>1.164626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>cup</td>\n",
       "      <td>drink_with</td>\n",
       "      <td>cup_000508.jpg</td>\n",
       "      <td>The rim of the cup is used for drinking, as it...</td>\n",
       "      <td>rim</td>\n",
       "      <td>of</td>\n",
       "      <td>cup</td>\n",
       "      <td>0.468414</td>\n",
       "      <td>0.604631</td>\n",
       "      <td>2.819588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>cup</td>\n",
       "      <td>pour</td>\n",
       "      <td>cup_001535.jpg</td>\n",
       "      <td>The spout or rim of the cup is typically used ...</td>\n",
       "      <td>sp</td>\n",
       "      <td>out</td>\n",
       "      <td>cup</td>\n",
       "      <td>1.244894</td>\n",
       "      <td>0.384339</td>\n",
       "      <td>2.079993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>cup</td>\n",
       "      <td>sip</td>\n",
       "      <td>cup_001864.jpg</td>\n",
       "      <td>The rim of the cup is used for sipping.</td>\n",
       "      <td>rim</td>\n",
       "      <td>of</td>\n",
       "      <td>cup</td>\n",
       "      <td>0.547422</td>\n",
       "      <td>0.594170</td>\n",
       "      <td>0.895887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>cup</td>\n",
       "      <td>wash</td>\n",
       "      <td>cup_003621.jpg</td>\n",
       "      <td>The interior surface of the cup is used for wa...</td>\n",
       "      <td>interior</td>\n",
       "      <td>surface</td>\n",
       "      <td>cup</td>\n",
       "      <td>0.778997</td>\n",
       "      <td>0.472265</td>\n",
       "      <td>2.127257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>drum</td>\n",
       "      <td>beat</td>\n",
       "      <td>drum_002586.jpg</td>\n",
       "      <td>The drumhead is the part of the drum used for ...</td>\n",
       "      <td>drum</td>\n",
       "      <td>head</td>\n",
       "      <td>drum</td>\n",
       "      <td>1.054528</td>\n",
       "      <td>0.403515</td>\n",
       "      <td>0.108292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>fork</td>\n",
       "      <td>lift</td>\n",
       "      <td>fork_001691.jpg</td>\n",
       "      <td>The tines (the prongs) of the fork are used fo...</td>\n",
       "      <td>t</td>\n",
       "      <td>ines</td>\n",
       "      <td>fork</td>\n",
       "      <td>1.796315</td>\n",
       "      <td>0.212984</td>\n",
       "      <td>0.107341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>fork</td>\n",
       "      <td>stick</td>\n",
       "      <td>fork_000095.jpg</td>\n",
       "      <td>The tines (the prongs) of the fork are used fo...</td>\n",
       "      <td>t</td>\n",
       "      <td>ines</td>\n",
       "      <td>fork</td>\n",
       "      <td>0.707276</td>\n",
       "      <td>0.523349</td>\n",
       "      <td>1.942757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>fork</td>\n",
       "      <td>wash</td>\n",
       "      <td>fork_001691.jpg</td>\n",
       "      <td>Forks are not typically used for washing; they...</td>\n",
       "      <td>orks</td>\n",
       "      <td>are</td>\n",
       "      <td>fork</td>\n",
       "      <td>0.767783</td>\n",
       "      <td>0.493578</td>\n",
       "      <td>2.007411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>frisbee</td>\n",
       "      <td>throw</td>\n",
       "      <td>frisbee_003249.jpg</td>\n",
       "      <td>The edge or rim of the frisbee is typically us...</td>\n",
       "      <td>edge</td>\n",
       "      <td>or</td>\n",
       "      <td>frisbee</td>\n",
       "      <td>0.707149</td>\n",
       "      <td>0.526501</td>\n",
       "      <td>0.430291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>golf_clubs</td>\n",
       "      <td>swing</td>\n",
       "      <td>golf_clubs_001992.jpg</td>\n",
       "      <td>The shaft and grip of the golf club are used f...</td>\n",
       "      <td>shaft</td>\n",
       "      <td>and</td>\n",
       "      <td>golf_clubs</td>\n",
       "      <td>2.379632</td>\n",
       "      <td>0.136689</td>\n",
       "      <td>0.354270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>hammer</td>\n",
       "      <td>hit</td>\n",
       "      <td>hammer_001006.jpg</td>\n",
       "      <td>The flat, heavy end of the hammer, known as th...</td>\n",
       "      <td>flat</td>\n",
       "      <td>,</td>\n",
       "      <td>hammer</td>\n",
       "      <td>2.184591</td>\n",
       "      <td>0.147652</td>\n",
       "      <td>0.074342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>hot_dog</td>\n",
       "      <td>eat</td>\n",
       "      <td>hot_dog_002166.jpg</td>\n",
       "      <td>People eat the entire cooked sausage portion o...</td>\n",
       "      <td>cooked</td>\n",
       "      <td>sausage</td>\n",
       "      <td>hot_dog</td>\n",
       "      <td>0.283595</td>\n",
       "      <td>0.700773</td>\n",
       "      <td>1.058734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>keyboard</td>\n",
       "      <td>type_on</td>\n",
       "      <td>keyboard_000439.jpg</td>\n",
       "      <td>The keys on the keyboard are used for 'type_on...</td>\n",
       "      <td>keyboard</td>\n",
       "      <td>are</td>\n",
       "      <td>keyboard</td>\n",
       "      <td>0.209769</td>\n",
       "      <td>0.760820</td>\n",
       "      <td>1.397651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>knife</td>\n",
       "      <td>hold</td>\n",
       "      <td>knife_002682.jpg</td>\n",
       "      <td>When people perform a hold with a knife, the h...</td>\n",
       "      <td>a</td>\n",
       "      <td>knife</td>\n",
       "      <td>knife</td>\n",
       "      <td>1.143759</td>\n",
       "      <td>0.360469</td>\n",
       "      <td>1.515368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>knife</td>\n",
       "      <td>stick</td>\n",
       "      <td>knife_001072.jpg</td>\n",
       "      <td>In a \"stick with knife\" technique, typically t...</td>\n",
       "      <td>tip</td>\n",
       "      <td>**</td>\n",
       "      <td>knife</td>\n",
       "      <td>1.304519</td>\n",
       "      <td>0.296400</td>\n",
       "      <td>2.064045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>knife</td>\n",
       "      <td>wash</td>\n",
       "      <td>knife_002720.jpg</td>\n",
       "      <td>The term \"wash\" is not a standard knife techni...</td>\n",
       "      <td>ing</td>\n",
       "      <td>stone</td>\n",
       "      <td>knife</td>\n",
       "      <td>0.793842</td>\n",
       "      <td>0.508148</td>\n",
       "      <td>2.605911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>orange</td>\n",
       "      <td>peel</td>\n",
       "      <td>orange_001193.jpg</td>\n",
       "      <td>The outer skin, or rind, of the orange is used...</td>\n",
       "      <td>pe</td>\n",
       "      <td>el</td>\n",
       "      <td>orange</td>\n",
       "      <td>1.004670</td>\n",
       "      <td>0.586998</td>\n",
       "      <td>1.224180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>orange</td>\n",
       "      <td>wash</td>\n",
       "      <td>orange_001193.jpg</td>\n",
       "      <td>The peel of the orange is used for \"wash,\" as ...</td>\n",
       "      <td>peel</td>\n",
       "      <td>of</td>\n",
       "      <td>orange</td>\n",
       "      <td>0.995860</td>\n",
       "      <td>0.607565</td>\n",
       "      <td>1.185696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>oven</td>\n",
       "      <td>open</td>\n",
       "      <td>oven_001370.jpg</td>\n",
       "      <td>The handle on the front of the oven door is us...</td>\n",
       "      <td>the</td>\n",
       "      <td>front</td>\n",
       "      <td>oven</td>\n",
       "      <td>1.131583</td>\n",
       "      <td>0.363523</td>\n",
       "      <td>1.139504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>pen</td>\n",
       "      <td>write</td>\n",
       "      <td>pen_003590.jpg</td>\n",
       "      <td>The tip of the pen, specifically the nib or ba...</td>\n",
       "      <td>tip</td>\n",
       "      <td>of</td>\n",
       "      <td>pen</td>\n",
       "      <td>1.373276</td>\n",
       "      <td>0.291705</td>\n",
       "      <td>1.240978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>rugby_ball</td>\n",
       "      <td>throw</td>\n",
       "      <td>rugby_ball_000001.jpg</td>\n",
       "      <td>When people throw a rugby ball, they typically...</td>\n",
       "      <td>l</td>\n",
       "      <td>aces</td>\n",
       "      <td>rugby_ball</td>\n",
       "      <td>0.355544</td>\n",
       "      <td>0.685050</td>\n",
       "      <td>0.818302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>skateboard</td>\n",
       "      <td>carry</td>\n",
       "      <td>skateboard_002668.jpg</td>\n",
       "      <td>People typically carry a skateboard by holding...</td>\n",
       "      <td>with</td>\n",
       "      <td>grip</td>\n",
       "      <td>skateboard</td>\n",
       "      <td>0.227472</td>\n",
       "      <td>0.752252</td>\n",
       "      <td>0.779079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>skateboard</td>\n",
       "      <td>hold</td>\n",
       "      <td>skateboard_002387.jpg</td>\n",
       "      <td>When people perform a \"hold\" on a skateboard, ...</td>\n",
       "      <td>a</td>\n",
       "      <td>skateboard</td>\n",
       "      <td>skateboard</td>\n",
       "      <td>0.686816</td>\n",
       "      <td>0.552761</td>\n",
       "      <td>0.897731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>skateboard</td>\n",
       "      <td>jump</td>\n",
       "      <td>skateboard_002387.jpg</td>\n",
       "      <td>When people perform a jump with a skateboard, ...</td>\n",
       "      <td>a</td>\n",
       "      <td>skateboard</td>\n",
       "      <td>skateboard</td>\n",
       "      <td>1.064476</td>\n",
       "      <td>0.391961</td>\n",
       "      <td>1.106408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>snowboard</td>\n",
       "      <td>carry</td>\n",
       "      <td>snowboard_001325.jpg</td>\n",
       "      <td>People typically carry a snowboard by gripping...</td>\n",
       "      <td>the</td>\n",
       "      <td>bindings</td>\n",
       "      <td>snowboard</td>\n",
       "      <td>1.434903</td>\n",
       "      <td>0.286415</td>\n",
       "      <td>2.060194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>soccer_ball</td>\n",
       "      <td>catch</td>\n",
       "      <td>soccer_ball_003333.jpg</td>\n",
       "      <td>When people perform a catch with a soccer ball...</td>\n",
       "      <td>a</td>\n",
       "      <td>soccer</td>\n",
       "      <td>soccer_ball</td>\n",
       "      <td>0.106172</td>\n",
       "      <td>0.831204</td>\n",
       "      <td>1.314543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>soccer_ball</td>\n",
       "      <td>kick</td>\n",
       "      <td>soccer_ball_001588.jpg</td>\n",
       "      <td>When people kick a soccer ball, they typically...</td>\n",
       "      <td>front</td>\n",
       "      <td>or</td>\n",
       "      <td>soccer_ball</td>\n",
       "      <td>0.047915</td>\n",
       "      <td>0.900816</td>\n",
       "      <td>2.226715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>surfboard</td>\n",
       "      <td>hold</td>\n",
       "      <td>surfboard_002631.jpg</td>\n",
       "      <td>The part of the surfboard used for \"hold\" is t...</td>\n",
       "      <td>the</td>\n",
       "      <td>surf</td>\n",
       "      <td>surfboard</td>\n",
       "      <td>0.632143</td>\n",
       "      <td>0.532037</td>\n",
       "      <td>2.730133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>surfboard</td>\n",
       "      <td>jump</td>\n",
       "      <td>surfboard_000658.jpg</td>\n",
       "      <td>When performing a jump with a surfboard, the t...</td>\n",
       "      <td>a</td>\n",
       "      <td>surf</td>\n",
       "      <td>surfboard</td>\n",
       "      <td>0.924637</td>\n",
       "      <td>0.442090</td>\n",
       "      <td>0.304387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>surfboard</td>\n",
       "      <td>lie_on</td>\n",
       "      <td>surfboard_000221.jpg</td>\n",
       "      <td>When people perform \"lie_on\" with a surfboard,...</td>\n",
       "      <td>a</td>\n",
       "      <td>surf</td>\n",
       "      <td>surfboard</td>\n",
       "      <td>0.087334</td>\n",
       "      <td>0.826782</td>\n",
       "      <td>2.138487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>surfboard</td>\n",
       "      <td>sit_on</td>\n",
       "      <td>surfboard_000010.jpg</td>\n",
       "      <td>The central, textured deck area of the surfboa...</td>\n",
       "      <td>textured</td>\n",
       "      <td>deck</td>\n",
       "      <td>surfboard</td>\n",
       "      <td>0.202874</td>\n",
       "      <td>0.745118</td>\n",
       "      <td>0.250377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>tennis_racket</td>\n",
       "      <td>hit</td>\n",
       "      <td>tennis_racket_002268.jpg</td>\n",
       "      <td>The strings of the tennis racket are used to h...</td>\n",
       "      <td>strings</td>\n",
       "      <td>of</td>\n",
       "      <td>tennis_racket</td>\n",
       "      <td>4.088600</td>\n",
       "      <td>0.035627</td>\n",
       "      <td>-0.474043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>toothbrush</td>\n",
       "      <td>hold</td>\n",
       "      <td>toothbrush_003341.jpg</td>\n",
       "      <td>The handle of the toothbrush is used for holding.</td>\n",
       "      <td>handle</td>\n",
       "      <td>of</td>\n",
       "      <td>toothbrush</td>\n",
       "      <td>1.324531</td>\n",
       "      <td>0.296131</td>\n",
       "      <td>1.408021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>toothbrush</td>\n",
       "      <td>wash</td>\n",
       "      <td>toothbrush_001991.jpg</td>\n",
       "      <td>The bristles at the head of the toothbrush are...</td>\n",
       "      <td>br</td>\n",
       "      <td>istles</td>\n",
       "      <td>toothbrush</td>\n",
       "      <td>0.996455</td>\n",
       "      <td>0.406010</td>\n",
       "      <td>2.137414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>wine_glass</td>\n",
       "      <td>hold</td>\n",
       "      <td>wine_glass_002374.jpg</td>\n",
       "      <td>People typically hold the wine glass by its st...</td>\n",
       "      <td>wine</td>\n",
       "      <td>glass</td>\n",
       "      <td>wine_glass</td>\n",
       "      <td>0.917508</td>\n",
       "      <td>0.427392</td>\n",
       "      <td>1.224567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>wine_glass</td>\n",
       "      <td>pour</td>\n",
       "      <td>wine_glass_000186.jpg</td>\n",
       "      <td>The rim of the wine glass is used for pouring,...</td>\n",
       "      <td>rim</td>\n",
       "      <td>of</td>\n",
       "      <td>wine_glass</td>\n",
       "      <td>1.282375</td>\n",
       "      <td>0.314259</td>\n",
       "      <td>0.854406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            object      action                  filename  \\\n",
       "0            apple         cut          apple_000054.jpg   \n",
       "7           banana         cut         banana_002623.jpg   \n",
       "8           banana         eat         banana_002458.jpg   \n",
       "10        baseball       throw       baseball_002670.jpg   \n",
       "11    baseball_bat         hit   baseball_bat_001882.jpg   \n",
       "12    baseball_bat        hold   baseball_bat_002547.jpg   \n",
       "13    baseball_bat       swing   baseball_bat_001882.jpg   \n",
       "14      basketball       throw     basketball_003534.jpg   \n",
       "17           bench      lie_on          bench_003727.jpg   \n",
       "18           bench      sit_on          bench_001877.jpg   \n",
       "22      binoculars    look_out     binoculars_003630.jpg   \n",
       "23            book        hold           book_001195.jpg   \n",
       "24            book        open           book_003044.jpg   \n",
       "26          bottle        hold         bottle_001227.jpg   \n",
       "28          bottle        pour         bottle_002780.jpg   \n",
       "29            bowl        hold           bowl_000546.jpg   \n",
       "30            bowl        stir           bowl_000134.jpg   \n",
       "31            bowl        wash           bowl_002825.jpg   \n",
       "32        broccoli         eat       broccoli_002796.jpg   \n",
       "34          carrot         cut         carrot_001443.jpg   \n",
       "35          carrot         eat         carrot_001443.jpg   \n",
       "36          carrot        peel         carrot_003707.jpg   \n",
       "38      cell_phone     talk_on     cell_phone_000601.jpg   \n",
       "43             cup  drink_with            cup_000508.jpg   \n",
       "45             cup        pour            cup_001535.jpg   \n",
       "46             cup         sip            cup_001864.jpg   \n",
       "47             cup        wash            cup_003621.jpg   \n",
       "49            drum        beat           drum_002586.jpg   \n",
       "51            fork        lift           fork_001691.jpg   \n",
       "52            fork       stick           fork_000095.jpg   \n",
       "53            fork        wash           fork_001691.jpg   \n",
       "56         frisbee       throw        frisbee_003249.jpg   \n",
       "58      golf_clubs       swing     golf_clubs_001992.jpg   \n",
       "59          hammer         hit         hammer_001006.jpg   \n",
       "61         hot_dog         eat        hot_dog_002166.jpg   \n",
       "63        keyboard     type_on       keyboard_000439.jpg   \n",
       "65           knife        hold          knife_002682.jpg   \n",
       "66           knife       stick          knife_001072.jpg   \n",
       "67           knife        wash          knife_002720.jpg   \n",
       "75          orange        peel         orange_001193.jpg   \n",
       "76          orange        wash         orange_001193.jpg   \n",
       "77            oven        open           oven_001370.jpg   \n",
       "78             pen       write            pen_003590.jpg   \n",
       "84      rugby_ball       throw     rugby_ball_000001.jpg   \n",
       "87      skateboard       carry     skateboard_002668.jpg   \n",
       "88      skateboard        hold     skateboard_002387.jpg   \n",
       "89      skateboard        jump     skateboard_002387.jpg   \n",
       "95       snowboard       carry      snowboard_001325.jpg   \n",
       "98     soccer_ball       catch    soccer_ball_003333.jpg   \n",
       "99     soccer_ball        kick    soccer_ball_001588.jpg   \n",
       "106      surfboard        hold      surfboard_002631.jpg   \n",
       "107      surfboard        jump      surfboard_000658.jpg   \n",
       "108      surfboard      lie_on      surfboard_000221.jpg   \n",
       "109      surfboard      sit_on      surfboard_000010.jpg   \n",
       "110  tennis_racket         hit  tennis_racket_002268.jpg   \n",
       "114     toothbrush        hold     toothbrush_003341.jpg   \n",
       "115     toothbrush        wash     toothbrush_001991.jpg   \n",
       "117     wine_glass        hold     wine_glass_002374.jpg   \n",
       "118     wine_glass        pour     wine_glass_000186.jpg   \n",
       "\n",
       "                                       output_sentence top_token_text  \\\n",
       "0    When people cut an apple, they typically use t...             an   \n",
       "7    The peel of the banana is typically removed be...           peel   \n",
       "8    The inner flesh of the banana, which is the so...          inner   \n",
       "10   The entire baseball is used for throwing, but ...         raised   \n",
       "11   The barrel, which is the thick, rounded end of...         barrel   \n",
       "12   The handle of the baseball bat is used for hol...         handle   \n",
       "13   The barrel of the baseball_bat is used for swi...         barrel   \n",
       "14   When people throw a basketball, they use their...              a   \n",
       "17         The seat of the bench is used for lying on.           seat   \n",
       "18   The flat, horizontal slats on the top surface ...           flat   \n",
       "22   The eyepieces (the smaller lenses at the front...             ey   \n",
       "23   People typically use the **cover and spine** o...            the   \n",
       "24   The spine of the book is used for 'open' when ...          spine   \n",
       "26   People typically hold a bottle by its neck or ...              a   \n",
       "28   The narrow spout or tip of the bottle is used ...             sp   \n",
       "29   The rim or edge of the bowl is typically used ...            rim   \n",
       "30   The interior surface of the bowl, specifically...       interior   \n",
       "31   The interior surface of the bowl is used for w...       interior   \n",
       "32   People typically eat the florets and stalks of...            the   \n",
       "34   The part of the carrot used for 'cut' is the s...              a   \n",
       "35   The edible part of the carrot used for eating ...            the   \n",
       "36   The outer skin or rind of the carrot is peeled...              a   \n",
       "38   The microphone and speaker of the cell phone a...     microphone   \n",
       "43   The rim of the cup is used for drinking, as it...            rim   \n",
       "45   The spout or rim of the cup is typically used ...             sp   \n",
       "46             The rim of the cup is used for sipping.            rim   \n",
       "47   The interior surface of the cup is used for wa...       interior   \n",
       "49   The drumhead is the part of the drum used for ...           drum   \n",
       "51   The tines (the prongs) of the fork are used fo...              t   \n",
       "52   The tines (the prongs) of the fork are used fo...              t   \n",
       "53   Forks are not typically used for washing; they...           orks   \n",
       "56   The edge or rim of the frisbee is typically us...           edge   \n",
       "58   The shaft and grip of the golf club are used f...          shaft   \n",
       "59   The flat, heavy end of the hammer, known as th...           flat   \n",
       "61   People eat the entire cooked sausage portion o...         cooked   \n",
       "63   The keys on the keyboard are used for 'type_on...       keyboard   \n",
       "65   When people perform a hold with a knife, the h...              a   \n",
       "66   In a \"stick with knife\" technique, typically t...            tip   \n",
       "67   The term \"wash\" is not a standard knife techni...            ing   \n",
       "75   The outer skin, or rind, of the orange is used...             pe   \n",
       "76   The peel of the orange is used for \"wash,\" as ...           peel   \n",
       "77   The handle on the front of the oven door is us...            the   \n",
       "78   The tip of the pen, specifically the nib or ba...            tip   \n",
       "84   When people throw a rugby ball, they typically...              l   \n",
       "87   People typically carry a skateboard by holding...           with   \n",
       "88   When people perform a \"hold\" on a skateboard, ...              a   \n",
       "89   When people perform a jump with a skateboard, ...              a   \n",
       "95   People typically carry a snowboard by gripping...            the   \n",
       "98   When people perform a catch with a soccer ball...              a   \n",
       "99   When people kick a soccer ball, they typically...          front   \n",
       "106  The part of the surfboard used for \"hold\" is t...            the   \n",
       "107  When performing a jump with a surfboard, the t...              a   \n",
       "108  When people perform \"lie_on\" with a surfboard,...              a   \n",
       "109  The central, textured deck area of the surfboa...       textured   \n",
       "110  The strings of the tennis racket are used to h...        strings   \n",
       "114  The handle of the toothbrush is used for holding.         handle   \n",
       "115  The bristles at the head of the toothbrush are...             br   \n",
       "117  People typically hold the wine glass by its st...           wine   \n",
       "118  The rim of the wine glass is used for pouring,...            rim   \n",
       "\n",
       "    following_text     clip_input       KLD       SIM       NSS  \n",
       "0            apple          apple  0.953323  0.604613  0.680869  \n",
       "7               of         banana  0.152788  0.782200  1.407556  \n",
       "8            flesh         banana  0.093214  0.834037  1.719909  \n",
       "10       stitching       baseball  0.137434  0.815854  3.191665  \n",
       "11               ,   baseball_bat  2.214648  0.137202  0.184698  \n",
       "12              of   baseball_bat  2.026475  0.163947  1.701513  \n",
       "13              of   baseball_bat  2.146138  0.146076  0.247262  \n",
       "14      basketball     basketball  0.268886  0.740719  3.487939  \n",
       "17              of          bench  0.716610  0.514579  1.208419  \n",
       "18               ,          bench  0.057316  0.881795  1.778349  \n",
       "22              ep     binoculars  1.109505  0.376979  0.456978  \n",
       "23              **           book  0.696297  0.534425  1.226442  \n",
       "24              of           book  0.594520  0.540672  2.472611  \n",
       "26          bottle         bottle  0.365511  0.676896  1.801573  \n",
       "28             out         bottle  2.560700  0.136236 -0.123696  \n",
       "29              or           bowl  0.181379  0.755979  0.826717  \n",
       "30         surface           bowl  1.396722  0.369197  0.452302  \n",
       "31         surface           bowl  0.843469  0.497629  0.441300  \n",
       "32             flo       broccoli  0.187420  0.749665  1.507471  \n",
       "34           knife         carrot  0.868247  0.471963  2.850394  \n",
       "35         cutting         carrot  0.952182  0.433952  2.679701  \n",
       "36           knife         carrot  0.303778  0.702846  2.085634  \n",
       "38             and     cell_phone  0.750690  0.484189  1.164626  \n",
       "43              of            cup  0.468414  0.604631  2.819588  \n",
       "45             out            cup  1.244894  0.384339  2.079993  \n",
       "46              of            cup  0.547422  0.594170  0.895887  \n",
       "47         surface            cup  0.778997  0.472265  2.127257  \n",
       "49            head           drum  1.054528  0.403515  0.108292  \n",
       "51            ines           fork  1.796315  0.212984  0.107341  \n",
       "52            ines           fork  0.707276  0.523349  1.942757  \n",
       "53             are           fork  0.767783  0.493578  2.007411  \n",
       "56              or        frisbee  0.707149  0.526501  0.430291  \n",
       "58             and     golf_clubs  2.379632  0.136689  0.354270  \n",
       "59               ,         hammer  2.184591  0.147652  0.074342  \n",
       "61         sausage        hot_dog  0.283595  0.700773  1.058734  \n",
       "63             are       keyboard  0.209769  0.760820  1.397651  \n",
       "65           knife          knife  1.143759  0.360469  1.515368  \n",
       "66              **          knife  1.304519  0.296400  2.064045  \n",
       "67           stone          knife  0.793842  0.508148  2.605911  \n",
       "75              el         orange  1.004670  0.586998  1.224180  \n",
       "76              of         orange  0.995860  0.607565  1.185696  \n",
       "77           front           oven  1.131583  0.363523  1.139504  \n",
       "78              of            pen  1.373276  0.291705  1.240978  \n",
       "84            aces     rugby_ball  0.355544  0.685050  0.818302  \n",
       "87            grip     skateboard  0.227472  0.752252  0.779079  \n",
       "88      skateboard     skateboard  0.686816  0.552761  0.897731  \n",
       "89      skateboard     skateboard  1.064476  0.391961  1.106408  \n",
       "95        bindings      snowboard  1.434903  0.286415  2.060194  \n",
       "98          soccer    soccer_ball  0.106172  0.831204  1.314543  \n",
       "99              or    soccer_ball  0.047915  0.900816  2.226715  \n",
       "106           surf      surfboard  0.632143  0.532037  2.730133  \n",
       "107           surf      surfboard  0.924637  0.442090  0.304387  \n",
       "108           surf      surfboard  0.087334  0.826782  2.138487  \n",
       "109           deck      surfboard  0.202874  0.745118  0.250377  \n",
       "110             of  tennis_racket  4.088600  0.035627 -0.474043  \n",
       "114             of     toothbrush  1.324531  0.296131  1.408021  \n",
       "115         istles     toothbrush  0.996455  0.406010  2.137414  \n",
       "117          glass     wine_glass  0.917508  0.427392  1.224567  \n",
       "118             of     wine_glass  1.282375  0.314259  0.854406  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analy[df_analy['clip_input'] == df_analy['object']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a9db57e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KLD    0.929405\n",
       "SIM    0.504299\n",
       "NSS    1.349262\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analy[df_analy['clip_input'] == df_analy['object']][['KLD','SIM','NSS']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a977e2fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KLD    1.222106\n",
       "SIM    0.443117\n",
       "NSS    1.227378\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analy[df_analy['clip_input'] != df_analy['object']][['KLD','SIM','NSS']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fc4a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_analy[df_analy['clip_input'] != df_analy['object']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1f5a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa1fb49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7b5666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Processing: eat - apple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Layer-wise attention maps for token: 'flesh' (Idx: 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving Layers for 'flesh': 100%|██████████| 64/64 [01:59<00:00,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved all layer maps and DataFrame to: ./output_layerhead_deep/viz_token_1_flesh\n",
      "DataFrame Head 미리보기:\n",
      "   Layer  Head  Attention_Sum  Layer_Total_Sum\n",
      "0      0     0       0.019457         2.554762\n",
      "1      0     1       0.070488         2.554762\n",
      "2      0     2       0.000568         2.554762\n",
      "3      0     3       0.040754         2.554762\n",
      "4      0     4       0.035283         2.554762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "metrics_tracker_alloutput = MetricsTracker(name=\"all_output\")\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 저장할 디렉토리 생성\n",
    "Layername = \"layerhead_deep\"\n",
    "output_dir = f\"./output_{Layername}\"  # 디렉토리 이름 변경 (구분 위해)s\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Contrastive Subtraction 강도 설정 (0.5 ~ 1.0 추천)\n",
    "\n",
    "POS_ALPHA = 0\n",
    "\n",
    "for i in range(1):\n",
    "    i += 1\n",
    "    pkl_path = f\"output_results/attention_result_full_output_32B_{i}.pkl\"\n",
    "    if not os.path.exists(pkl_path):\n",
    "        continue\n",
    "        \n",
    "    df_output = pd.read_pickle(pkl_path)\n",
    "\n",
    "    row = df_output.iloc[1]\n",
    "\n",
    "\n",
    "    object_name = row['object']\n",
    "    action = row['action']\n",
    "    filename = row['filename']\n",
    "    output_description = row['output_sentence']\n",
    "    output_attentions = row['output_attentions']\n",
    "    \n",
    "    file_name_real = f\"{AGD20K_PATH}/Seen/testset/egocentric/{action}/{object_name}/{filename}\"\n",
    "    gt_path = f\"{AGD20K_PATH}/Seen/testset/GT/{action}/{object_name}/{filename.split('.')[0]}.png\"\n",
    "        \n",
    "    # 이미지 로드\n",
    "    if not os.path.exists(file_name_real):\n",
    "        print(f\"Image not found: {file_name_real}\")\n",
    "        continue\n",
    "\n",
    "    orig_img = cv2.imread(file_name_real)\n",
    "    orig_img = cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB)\n",
    "    h, w, _ = orig_img.shape\n",
    "\n",
    "    print(f\"[Processing: {action} - {object_name}\")\n",
    "\n",
    "    # --- 1. CLIPSeg Mask 생성 ---\n",
    "\n",
    "    clip_heatmap = get_clipseg_heatmap(\n",
    "        file_name_real,\n",
    "        clip_model,\n",
    "        clip_processor,\n",
    "        object_name,\n",
    "    )\n",
    "\n",
    "    # CLIPSeg 결과를 31x31로 리사이즈\n",
    "    clip_heatmap_resized = cv2.resize(clip_heatmap, (31, 31), interpolation=cv2.INTER_LINEAR)\n",
    "    clip_binary_mask = (clip_heatmap_resized > 0.15).astype(np.float32) # 필요시 사용\n",
    "\n",
    "    # --- 2. [변경] Contrastive Attention Map 계산 ---\n",
    "    token_scores = []\n",
    "    token_idx = 0\n",
    "    for token in output_attentions:\n",
    "        # 토큰별 히트맵 초기화\n",
    "        token_heatmap = np.zeros((31, 31), dtype=np.float32)\n",
    "        token_head_count = 0\n",
    "        \n",
    "        attention_value = token['attentions']\n",
    "        decoded_str = token['token_str'] # 디버깅용\n",
    "\n",
    "        for each_attention in attention_value:\n",
    "            layer = each_attention['layer']\n",
    "            head = each_attention['head']\n",
    "            \n",
    "            # # 사용자가 설정한 특정 레이어 필터링 (여기선 Layer 0 유지)\n",
    "            # if each_attention['layer'] != 0:\n",
    "            if 1==1: # (layer <=45) and (layer >= 20): #1==1: # (layer == 26) : #and( head ==20)) : #or ((layer == 24) and( head ==31)):\n",
    "                \n",
    "                token_heatmap += each_attention['heatmap']\n",
    "                token_head_count += 1\n",
    "\n",
    "        \n",
    "        # 해당 레이어의 헤드가 하나도 없으면 스킵\n",
    "        if token_head_count == 0:\n",
    "            continue\n",
    "\n",
    "        # Visual Dependency Score (S_img) 계산: 맵의 총합\n",
    "        s_img = token_heatmap.sum()\n",
    "\n",
    "        # 리스트에 저장\n",
    "        token_scores.append({\n",
    "            \"token\": decoded_str,\n",
    "            \"token_idx\" : token_idx,\n",
    "            \"score\": s_img,\n",
    "            \"heatmap\": token_heatmap, \n",
    "            \"count\": token_head_count\n",
    "        })\n",
    "        token_idx +=1\n",
    "    # 예외 처리: 토큰이 없을 경우\n",
    "    if len(token_scores) == 0:\n",
    "        print(\"No valid tokens found.\")\n",
    "        continue\n",
    "\n",
    "    # 정렬 (Score 기준 오름차순)\n",
    "    sorted_tokens = sorted(token_scores, key=lambda x: x['score'])\n",
    "    \n",
    "    # Top 5 (Signal) & Bottom 5 (Noise) 선정\n",
    "    # 토큰 개수가 10개 미만일 경우 처리\n",
    "    num_select = min(1, len(sorted_tokens) // 2)\n",
    "    if num_select < 1: num_select = 1 # 최소 1개\n",
    "\n",
    "    bottom_tokens = sorted_tokens[:num_select]       # Noise (기능어, 배경 등)\n",
    "    top_tokens = sorted_tokens[-num_select:][::-1]   # Signal (명사, 핵심어)\n",
    "    ## 꺼꾸로 last 뽑기\n",
    "\n",
    "\n",
    "    # Signal Map (Positive) 평균\n",
    "    pos_map = np.sum([t['heatmap'] for t in top_tokens], axis=0)\n",
    "    pos_map /= len(top_tokens)\n",
    "    top_token_idx  = top_tokens[-1]['token_idx']\n",
    "    top_token_text  = top_tokens[-1]['token']\n",
    "\n",
    "    # --- 모든 레이어/헤드 어텐션 저장 로직 ---\n",
    "\n",
    "    # 1. 대상 토큰 데이터 추출 (Top 1 토큰)\n",
    "    target_token_info = top_tokens[-1] \n",
    "    target_token_str = target_token_info['token'].strip()\n",
    "    target_token_idx = target_token_info['token_idx']\n",
    "\n",
    "\n",
    "    # ... (위쪽 코드: target_token_idx, target_token_str 추출 부분) ...\n",
    "    \n",
    "    print(f\"Generating Layer-wise attention maps for token: '{target_token_str}' (Idx: {target_token_idx})\")\n",
    "\n",
    "    # --- [추가] 모든 Layer/Head Attention 시각화 저장 로직 ---\n",
    "\n",
    "    # 1. 저장할 서브 디렉토리 생성\n",
    "    # 파일명에 겹치지 않게 토큰 인덱스와 텍스트를 포함\n",
    "    safe_token_str = \"\".join([c if c.isalnum() else \"_\" for c in target_token_str])\n",
    "    vis_save_dir = os.path.join(output_dir, f\"viz_token_{target_token_idx}_{safe_token_str}\")\n",
    "    os.makedirs(vis_save_dir, exist_ok=True)\n",
    "\n",
    "    # 2. 해당 토큰의 모든 어텐션 데이터 수집 및 레이어별 분류\n",
    "    # output_attentions[target_token_idx]는 해당 토큰 위치의 정보라고 가정\n",
    "    # 만약 output_attentions가 토큰들의 리스트라면 아래와 같이 접근\n",
    "    target_token_data = output_attentions[target_token_idx]\n",
    "    \n",
    "    # 레이어별로 Head 정보를 모음: { layer_idx: [ {head: h, heatmap: map}, ... ] }\n",
    "    layer_wise_attentions = {}\n",
    "    \n",
    "    for attn_item in target_token_data['attentions']:\n",
    "        ly = attn_item['layer']\n",
    "        hd = attn_item['head']\n",
    "        hm = attn_item['heatmap']\n",
    "        \n",
    "        if ly not in layer_wise_attentions:\n",
    "            layer_wise_attentions[ly] = []\n",
    "        layer_wise_attentions[ly].append({'head': hd, 'heatmap': hm})\n",
    "\n",
    " # ... (이전 데이터 수집 단계 코드는 동일) ...\n",
    "\n",
    "# ... (이전 코드: target_token_str 추출, 디렉토리 생성 등) ...\n",
    "\n",
    "    # [추가 1] 데이터를 모을 리스트 초기화\n",
    "    att_data_list = []\n",
    "\n",
    "    # 3. 레이어별 루프를 돌며 이미지 생성 및 데이터 수집\n",
    "    sorted_layers = sorted(layer_wise_attentions.keys())\n",
    "    \n",
    "    for ly in tqdm(sorted_layers, desc=f\"Saving Layers for '{target_token_str}'\"):\n",
    "        heads_data = layer_wise_attentions[ly]\n",
    "        \n",
    "        # Head 번호 순서대로 정렬\n",
    "        heads_data.sort(key=lambda x: x['head'])\n",
    "        \n",
    "        num_heads = len(heads_data)\n",
    "        if num_heads == 0: continue\n",
    "\n",
    "        # 해당 레이어의 전체 Attention Score 합계 계산\n",
    "        layer_total_score = sum([h['heatmap'].sum() for h in heads_data])\n",
    "\n",
    "        # 격자 크기 계산\n",
    "        grid_size = int(np.ceil(np.sqrt(num_heads)))\n",
    "        \n",
    "        # 캔버스 생성\n",
    "        fig, axes = plt.subplots(grid_size, grid_size, figsize=(20, 20))\n",
    "        fig.suptitle(\n",
    "            f\"Token: '{target_token_str}' (Idx: {target_token_idx}) - Layer {ly}\\n\"\n",
    "            f\"Layer Total Attention Sum: {layer_total_score:.4f}\", \n",
    "            fontsize=24\n",
    "        )\n",
    "        \n",
    "        if isinstance(axes, np.ndarray):\n",
    "            axes_flat = axes.flatten()\n",
    "        else:\n",
    "            axes_flat = [axes]\n",
    "            \n",
    "        # 각 Head별 처리\n",
    "        for i, ax in enumerate(axes_flat):\n",
    "            if i < num_heads:\n",
    "                head_info = heads_data[i]\n",
    "                h_idx = head_info['head']\n",
    "                h_map = head_info['heatmap']\n",
    "                \n",
    "                # 개별 Head Score 계산\n",
    "                head_score = h_map.sum()\n",
    "                \n",
    "                # [추가 2] 리스트에 데이터 추가 (Layer, Head, Attention Sum)\n",
    "                att_data_list.append({\n",
    "                    'Layer': ly,\n",
    "                    'Head': h_idx,\n",
    "                    'Attention_Sum': head_score,\n",
    "                    'Layer_Total_Sum': layer_total_score  # 필요 시 레이어 총합도 함께 저장\n",
    "                })\n",
    "\n",
    "                # 시각화\n",
    "                im = ax.imshow(h_map, cmap='viridis', interpolation='nearest')\n",
    "                ax.set_title(f\"Head {h_idx}\\nSum: {head_score:.2f}\", fontsize=10)\n",
    "                ax.axis('off')\n",
    "            else:\n",
    "                ax.axis('off')\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.93])\n",
    "        save_path = os.path.join(vis_save_dir, f\"layer_{ly:03d}.png\")\n",
    "        plt.savefig(save_path)\n",
    "        plt.close(fig) \n",
    "\n",
    "    # [추가 3] DataFrame 생성 및 저장\n",
    "    df_att = pd.DataFrame(att_data_list)\n",
    "    \n",
    "    # 보기 좋게 컬럼 순서 정렬 (Layer -> Head -> Sum)\n",
    "    df_att = df_att[['Layer', 'Head', 'Attention_Sum', 'Layer_Total_Sum']]\n",
    "    \n",
    "    # CSV 파일로 저장\n",
    "    csv_path = os.path.join(vis_save_dir, \"attention_sums.csv\")\n",
    "    df_att.to_csv(csv_path, index=False)\n",
    "\n",
    "    print(f\"Saved all layer maps and DataFrame to: {vis_save_dir}\")\n",
    "    print(\"DataFrame Head 미리보기:\")\n",
    "    print(df_att.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c37288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Layer\n",
       "20    0.376303\n",
       "23    0.566991\n",
       "1     0.760726\n",
       "10    0.854804\n",
       "9     0.889243\n",
       "        ...   \n",
       "50    8.005047\n",
       "45    8.019423\n",
       "17    8.284877\n",
       "46    8.924697\n",
       "41    9.288528\n",
       "Name: Attention_Sum, Length: 64, dtype: float32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_att.groupby(['Layer'])['Attention_Sum'].sum().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767dc381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer</th>\n",
       "      <th>Head</th>\n",
       "      <th>Attention_Sum</th>\n",
       "      <th>Layer_Total_Sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>1.028297e-08</td>\n",
       "      <td>0.376303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>20</td>\n",
       "      <td>58</td>\n",
       "      <td>1.797992e-07</td>\n",
       "      <td>0.376303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>2.148592e-07</td>\n",
       "      <td>0.376303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>20</td>\n",
       "      <td>27</td>\n",
       "      <td>2.576361e-07</td>\n",
       "      <td>0.376303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>3.766697e-07</td>\n",
       "      <td>0.376303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>20</td>\n",
       "      <td>53</td>\n",
       "      <td>2.764578e-02</td>\n",
       "      <td>0.376303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>20</td>\n",
       "      <td>31</td>\n",
       "      <td>3.363384e-02</td>\n",
       "      <td>0.376303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>20</td>\n",
       "      <td>62</td>\n",
       "      <td>3.683291e-02</td>\n",
       "      <td>0.376303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1325</th>\n",
       "      <td>20</td>\n",
       "      <td>45</td>\n",
       "      <td>4.368176e-02</td>\n",
       "      <td>0.376303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322</th>\n",
       "      <td>20</td>\n",
       "      <td>42</td>\n",
       "      <td>5.164818e-02</td>\n",
       "      <td>0.376303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Layer  Head  Attention_Sum  Layer_Total_Sum\n",
       "1302     20    22   1.028297e-08         0.376303\n",
       "1338     20    58   1.797992e-07         0.376303\n",
       "1304     20    24   2.148592e-07         0.376303\n",
       "1307     20    27   2.576361e-07         0.376303\n",
       "1291     20    11   3.766697e-07         0.376303\n",
       "...     ...   ...            ...              ...\n",
       "1333     20    53   2.764578e-02         0.376303\n",
       "1311     20    31   3.363384e-02         0.376303\n",
       "1342     20    62   3.683291e-02         0.376303\n",
       "1325     20    45   4.368176e-02         0.376303\n",
       "1322     20    42   5.164818e-02         0.376303\n",
       "\n",
       "[64 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_att[df_att['Layer']==20].sort_values(\"Attention_Sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bace41e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer</th>\n",
       "      <th>Head</th>\n",
       "      <th>Attention_Sum</th>\n",
       "      <th>Layer_Total_Sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019457</td>\n",
       "      <td>2.554762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.070488</td>\n",
       "      <td>2.554762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>2.554762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.040754</td>\n",
       "      <td>2.554762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.035283</td>\n",
       "      <td>2.554762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4091</th>\n",
       "      <td>63</td>\n",
       "      <td>59</td>\n",
       "      <td>0.052509</td>\n",
       "      <td>2.854838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4092</th>\n",
       "      <td>63</td>\n",
       "      <td>60</td>\n",
       "      <td>0.032250</td>\n",
       "      <td>2.854838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4093</th>\n",
       "      <td>63</td>\n",
       "      <td>61</td>\n",
       "      <td>0.033217</td>\n",
       "      <td>2.854838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4094</th>\n",
       "      <td>63</td>\n",
       "      <td>62</td>\n",
       "      <td>0.092705</td>\n",
       "      <td>2.854838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4095</th>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>0.363023</td>\n",
       "      <td>2.854838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4096 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Layer  Head  Attention_Sum  Layer_Total_Sum\n",
       "0         0     0       0.019457         2.554762\n",
       "1         0     1       0.070488         2.554762\n",
       "2         0     2       0.000568         2.554762\n",
       "3         0     3       0.040754         2.554762\n",
       "4         0     4       0.035283         2.554762\n",
       "...     ...   ...            ...              ...\n",
       "4091     63    59       0.052509         2.854838\n",
       "4092     63    60       0.032250         2.854838\n",
       "4093     63    61       0.033217         2.854838\n",
       "4094     63    62       0.092705         2.854838\n",
       "4095     63    63       0.363023         2.854838\n",
       "\n",
       "[4096 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_att"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
