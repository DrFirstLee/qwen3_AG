{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b351283e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/DATA/AGD20K'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from transformers import CLIPSegProcessor, CLIPSegForImageSegmentation\n",
    "\n",
    "clip_processor = CLIPSegProcessor.from_pretrained(\"CIDAS/clipseg-rd64-refined\")\n",
    "clip_model = CLIPSegForImageSegmentation.from_pretrained(\"CIDAS/clipseg-rd64-refined\")\n",
    "\n",
    "import os\n",
    "import sys\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(parent_dir)\n",
    "from config import AGD20K_PATH, model_name\n",
    "\n",
    "from VLM_model_dot_relative import MetricsTracker\n",
    "from file_managing import (\n",
    "    load_selected_samples,\n",
    "    get_actual_path,\n",
    "    get_gt_path,\n",
    "    load_ground_truth,\n",
    "    prompt_dict_obj,\n",
    "    get_clipseg_heatmap,\n",
    "    calculate_metrics\n",
    ")\n",
    "\n",
    "def min_max_normalize(arr):\n",
    "    denom = arr.max() - arr.min()\n",
    "    if denom == 0:\n",
    "        return np.zeros_like(arr)\n",
    "    return (arr - arr.min()) / (denom + 1e-8)\n",
    "\n",
    "\n",
    "\n",
    "from transformers import Qwen3VLForConditionalGeneration, AutoProcessor\n",
    "model_name= f\"Qwen/Qwen3-VL-32B-Instruct\"\n",
    "processor = AutoProcessor.from_pretrained(model_name)\n",
    "tok = processor.tokenizer\n",
    "\n",
    "AGD20K_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28613512",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output = pd.read_pickle(\"output_results/attention_result_full_output_32B_1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2859e01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output = df_output.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be5cc17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['action', 'object', 'filename', 'description', 'output_sentence',\n",
       "       'output_attentions'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f380b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'When people cut an apple, they typically use the entire fruit, including the flesh, skin, and sometimes the core, depending on the purpose of the cut.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output.iloc[0,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ab1cad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Processing: cut - apple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Metrics for all_output apple_000054.jpg:\n",
      " all_output Current - KLD: 0.9182 | SIM: 0.6091 | NSS: 0.6864\n",
      "\n",
      "Cumulative all_output  Averages over 1 samples:\n",
      "Average - KLD: 0.9182 | SIM: 0.6091 | NSS: 0.6864\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : apple\n",
      "[1] Processing: eat - apple\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output apple_001541.jpg:\n",
      " all_output Current - KLD: 0.0325 | SIM: 0.9073 | NSS: 1.2867\n",
      "\n",
      "Cumulative all_output  Averages over 2 samples:\n",
      "Average - KLD: 0.4753 | SIM: 0.7582 | NSS: 0.9866\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : apple\n",
      "[2] Processing: peel - apple\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output apple_001541.jpg:\n",
      " all_output Current - KLD: 0.0470 | SIM: 0.8876 | NSS: 1.2933\n",
      "\n",
      "Cumulative all_output  Averages over 3 samples:\n",
      "Average - KLD: 0.3325 | SIM: 0.8013 | NSS: 1.0888\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : apple\n",
      "[3] Processing: hit - axe\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output axe_000961.jpg:\n",
      " all_output Current - KLD: 1.4914 | SIM: 0.2716 | NSS: 0.2730\n",
      "\n",
      "Cumulative all_output  Averages over 4 samples:\n",
      "Average - KLD: 0.6223 | SIM: 0.6689 | NSS: 0.8849\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : axe\n",
      "[4] Processing: hold - axe\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output axe_001552.jpg:\n",
      " all_output Current - KLD: 0.7554 | SIM: 0.4886 | NSS: 2.3974\n",
      "\n",
      "Cumulative all_output  Averages over 5 samples:\n",
      "Average - KLD: 0.6489 | SIM: 0.6328 | NSS: 1.1874\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : axe\n",
      "[5] Processing: hold - badminton_racket\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Metrics for all_output badminton_racket_002255.jpg:\n",
      " all_output Current - KLD: 1.9222 | SIM: 0.1708 | NSS: 0.1734\n",
      "\n",
      "Cumulative all_output  Averages over 6 samples:\n",
      "Average - KLD: 0.8611 | SIM: 0.5558 | NSS: 1.0184\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : badminton_racket\n",
      "[6] Processing: swing - badminton_racket\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output badminton_racket_003649.jpg:\n",
      " all_output Current - KLD: 5.8610 | SIM: 0.0049 | NSS: -0.3990\n",
      "\n",
      "Cumulative all_output  Averages over 7 samples:\n",
      "Average - KLD: 1.5754 | SIM: 0.4771 | NSS: 0.8159\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : badminton_racket\n",
      "[7] Processing: cut - banana\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output banana_002623.jpg:\n",
      " all_output Current - KLD: 0.1495 | SIM: 0.7857 | NSS: 1.4138\n",
      "\n",
      "Cumulative all_output  Averages over 8 samples:\n",
      "Average - KLD: 1.3971 | SIM: 0.5157 | NSS: 0.8906\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : banana\n",
      "[8] Processing: eat - banana\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output banana_002458.jpg:\n",
      " all_output Current - KLD: 0.1023 | SIM: 0.8314 | NSS: 1.7577\n",
      "\n",
      "Cumulative all_output  Averages over 9 samples:\n",
      "Average - KLD: 1.2533 | SIM: 0.5508 | NSS: 0.9870\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : banana\n",
      "[9] Processing: peel - banana\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output banana_000480.jpg:\n",
      " all_output Current - KLD: 1.1579 | SIM: 0.3530 | NSS: 1.1185\n",
      "\n",
      "Cumulative all_output  Averages over 10 samples:\n",
      "Average - KLD: 1.2437 | SIM: 0.5310 | NSS: 1.0001\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : banana\n",
      "[10] Processing: throw - baseball\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Metrics for all_output baseball_002670.jpg:\n",
      " all_output Current - KLD: 0.0693 | SIM: 0.9040 | NSS: 3.3185\n",
      "\n",
      "Cumulative all_output  Averages over 11 samples:\n",
      "Average - KLD: 1.1370 | SIM: 0.5649 | NSS: 1.2109\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : baseball\n",
      "[11] Processing: hit - baseball_bat\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output baseball_bat_001882.jpg:\n",
      " all_output Current - KLD: 2.2654 | SIM: 0.1320 | NSS: 0.1438\n",
      "\n",
      "Cumulative all_output  Averages over 12 samples:\n",
      "Average - KLD: 1.2310 | SIM: 0.5288 | NSS: 1.1219\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : baseball_bat\n",
      "[12] Processing: hold - baseball_bat\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output baseball_bat_002547.jpg:\n",
      " all_output Current - KLD: 2.0787 | SIM: 0.1563 | NSS: 1.5873\n",
      "\n",
      "Cumulative all_output  Averages over 13 samples:\n",
      "Average - KLD: 1.2962 | SIM: 0.5002 | NSS: 1.1577\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : baseball_bat\n",
      "[13] Processing: swing - baseball_bat\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output baseball_bat_001882.jpg:\n",
      " all_output Current - KLD: 2.2550 | SIM: 0.1331 | NSS: 0.1504\n",
      "\n",
      "Cumulative all_output  Averages over 14 samples:\n",
      "Average - KLD: 1.3647 | SIM: 0.4740 | NSS: 1.0858\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : baseball_bat\n",
      "[14] Processing: throw - basketball\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output basketball_003534.jpg:\n",
      " all_output Current - KLD: 0.3462 | SIM: 0.7007 | NSS: 3.4466\n",
      "\n",
      "Cumulative all_output  Averages over 15 samples:\n",
      "Average - KLD: 1.2968 | SIM: 0.4891 | NSS: 1.2432\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : basketball\n",
      "[15] Processing: lie_on - bed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Metrics for all_output bed_002880.jpg:\n",
      " all_output Current - KLD: 0.5021 | SIM: 0.6060 | NSS: 2.7479\n",
      "\n",
      "Cumulative all_output  Averages over 16 samples:\n",
      "Average - KLD: 1.2471 | SIM: 0.4964 | NSS: 1.3372\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : bed\n",
      "[16] Processing: sit_on - bed\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output bed_003622.jpg:\n",
      " all_output Current - KLD: 0.4224 | SIM: 0.6230 | NSS: 1.7113\n",
      "\n",
      "Cumulative all_output  Averages over 17 samples:\n",
      "Average - KLD: 1.1986 | SIM: 0.5038 | NSS: 1.3592\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : bed\n",
      "[17] Processing: lie_on - bench\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output bench_003727.jpg:\n",
      " all_output Current - KLD: 0.7546 | SIM: 0.4976 | NSS: 1.1714\n",
      "\n",
      "Cumulative all_output  Averages over 18 samples:\n",
      "Average - KLD: 1.1739 | SIM: 0.5035 | NSS: 1.3488\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : bench\n",
      "[18] Processing: sit_on - bench\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output bench_001877.jpg:\n",
      " all_output Current - KLD: 0.0607 | SIM: 0.8782 | NSS: 1.8452\n",
      "\n",
      "Cumulative all_output  Averages over 19 samples:\n",
      "Average - KLD: 1.1154 | SIM: 0.5232 | NSS: 1.3749\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : bench\n",
      "[19] Processing: push - bicycle\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output bicycle_002432.jpg:\n",
      " all_output Current - KLD: 2.6223 | SIM: 0.1158 | NSS: 0.1047\n",
      "\n",
      "Cumulative all_output  Averages over 20 samples:\n",
      "Average - KLD: 1.1907 | SIM: 0.5028 | NSS: 1.3114\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : bicycle\n",
      "[20] Processing: ride - bicycle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Metrics for all_output bicycle_003046.jpg:\n",
      " all_output Current - KLD: 1.3539 | SIM: 0.3026 | NSS: 1.0559\n",
      "\n",
      "Cumulative all_output  Averages over 21 samples:\n",
      "Average - KLD: 1.1985 | SIM: 0.4933 | NSS: 1.2992\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : bicycle\n",
      "[21] Processing: sit_on - bicycle\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output bicycle_002100.jpg:\n",
      " all_output Current - KLD: 1.6764 | SIM: 0.2416 | NSS: 1.7908\n",
      "\n",
      "Cumulative all_output  Averages over 22 samples:\n",
      "Average - KLD: 1.2202 | SIM: 0.4819 | NSS: 1.3216\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : bicycle\n",
      "[22] Processing: look_out - binoculars\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output binoculars_003630.jpg:\n",
      " all_output Current - KLD: 1.0348 | SIM: 0.3976 | NSS: 0.5503\n",
      "\n",
      "Cumulative all_output  Averages over 23 samples:\n",
      "Average - KLD: 1.2121 | SIM: 0.4782 | NSS: 1.2881\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : binoculars\n",
      "[23] Processing: hold - book\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output book_001195.jpg:\n",
      " all_output Current - KLD: 0.9866 | SIM: 0.4035 | NSS: 0.8308\n",
      "\n",
      "Cumulative all_output  Averages over 24 samples:\n",
      "Average - KLD: 1.2027 | SIM: 0.4751 | NSS: 1.2690\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : book\n",
      "[24] Processing: open - book\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output book_003044.jpg:\n",
      " all_output Current - KLD: 0.6575 | SIM: 0.5128 | NSS: 2.2905\n",
      "\n",
      "Cumulative all_output  Averages over 25 samples:\n",
      "Average - KLD: 1.1809 | SIM: 0.4766 | NSS: 1.3099\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : book\n",
      "[25] Processing: drink_with - bottle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Metrics for all_output bottle_003259.jpg:\n",
      " all_output Current - KLD: 1.8125 | SIM: 0.1869 | NSS: 1.3958\n",
      "\n",
      "Cumulative all_output  Averages over 26 samples:\n",
      "Average - KLD: 1.2052 | SIM: 0.4654 | NSS: 1.3132\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : bottle\n",
      "[26] Processing: hold - bottle\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output bottle_001227.jpg:\n",
      " all_output Current - KLD: 0.2786 | SIM: 0.7230 | NSS: 1.9674\n",
      "\n",
      "Cumulative all_output  Averages over 27 samples:\n",
      "Average - KLD: 1.1709 | SIM: 0.4750 | NSS: 1.3374\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : bottle\n",
      "[27] Processing: open - bottle\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output bottle_001033.jpg:\n",
      " all_output Current - KLD: 1.9126 | SIM: 0.1698 | NSS: 1.4221\n",
      "\n",
      "Cumulative all_output  Averages over 28 samples:\n",
      "Average - KLD: 1.1974 | SIM: 0.4641 | NSS: 1.3404\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : bottle\n",
      "[28] Processing: pour - bottle\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output bottle_002780.jpg:\n",
      " all_output Current - KLD: 2.0278 | SIM: 0.2060 | NSS: 0.0882\n",
      "\n",
      "Cumulative all_output  Averages over 29 samples:\n",
      "Average - KLD: 1.2260 | SIM: 0.4552 | NSS: 1.2972\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : bottle\n",
      "[29] Processing: hold - bowl\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output bowl_000546.jpg:\n",
      " all_output Current - KLD: 0.1973 | SIM: 0.7463 | NSS: 0.8309\n",
      "\n",
      "Cumulative all_output  Averages over 30 samples:\n",
      "Average - KLD: 1.1917 | SIM: 0.4649 | NSS: 1.2817\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : bowl\n",
      "[30] Processing: stir - bowl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Metrics for all_output bowl_000134.jpg:\n",
      " all_output Current - KLD: 1.2063 | SIM: 0.4014 | NSS: 0.5095\n",
      "\n",
      "Cumulative all_output  Averages over 31 samples:\n",
      "Average - KLD: 1.1922 | SIM: 0.4628 | NSS: 1.2568\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : bowl\n",
      "[31] Processing: wash - bowl\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output bowl_002825.jpg:\n",
      " all_output Current - KLD: 0.8534 | SIM: 0.4758 | NSS: 0.3122\n",
      "\n",
      "Cumulative all_output  Averages over 32 samples:\n",
      "Average - KLD: 1.1816 | SIM: 0.4632 | NSS: 1.2273\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : bowl\n",
      "[32] Processing: eat - broccoli\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output broccoli_002796.jpg:\n",
      " all_output Current - KLD: 0.1327 | SIM: 0.7996 | NSS: 1.6228\n",
      "\n",
      "Cumulative all_output  Averages over 33 samples:\n",
      "Average - KLD: 1.1498 | SIM: 0.4734 | NSS: 1.2392\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : broccoli\n",
      "[33] Processing: take_photo - camera\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output camera_002534.jpg:\n",
      " all_output Current - KLD: 0.7035 | SIM: 0.5183 | NSS: 0.3941\n",
      "\n",
      "Cumulative all_output  Averages over 34 samples:\n",
      "Average - KLD: 1.1367 | SIM: 0.4748 | NSS: 1.2144\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : camera\n",
      "[34] Processing: cut - carrot\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output carrot_001443.jpg:\n",
      " all_output Current - KLD: 0.8265 | SIM: 0.4823 | NSS: 3.0084\n",
      "\n",
      "Cumulative all_output  Averages over 35 samples:\n",
      "Average - KLD: 1.1278 | SIM: 0.4750 | NSS: 1.2656\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : carrot\n",
      "[35] Processing: eat - carrot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Metrics for all_output carrot_001443.jpg:\n",
      " all_output Current - KLD: 0.8767 | SIM: 0.4561 | NSS: 2.8304\n",
      "\n",
      "Cumulative all_output  Averages over 36 samples:\n",
      "Average - KLD: 1.1209 | SIM: 0.4744 | NSS: 1.3091\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : carrot\n",
      "[36] Processing: peel - carrot\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output carrot_003707.jpg:\n",
      " all_output Current - KLD: 0.2681 | SIM: 0.7277 | NSS: 2.0469\n",
      "\n",
      "Cumulative all_output  Averages over 37 samples:\n",
      "Average - KLD: 1.0978 | SIM: 0.4813 | NSS: 1.3291\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : carrot\n",
      "[37] Processing: take_photo - cell_phone\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output cell_phone_000601.jpg:\n",
      " all_output Current - KLD: 0.2837 | SIM: 0.7036 | NSS: 1.6209\n",
      "\n",
      "Cumulative all_output  Averages over 38 samples:\n",
      "Average - KLD: 1.0764 | SIM: 0.4871 | NSS: 1.3367\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : cell_phone\n",
      "[38] Processing: talk_on - cell_phone\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output cell_phone_000601.jpg:\n",
      " all_output Current - KLD: 0.7154 | SIM: 0.5013 | NSS: 1.2887\n",
      "\n",
      "Cumulative all_output  Averages over 39 samples:\n",
      "Average - KLD: 1.0671 | SIM: 0.4875 | NSS: 1.3355\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : cell_phone\n",
      "[39] Processing: text_on - cell_phone\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output cell_phone_003361.jpg:\n",
      " all_output Current - KLD: 0.8541 | SIM: 0.4561 | NSS: 1.5644\n",
      "\n",
      "Cumulative all_output  Averages over 40 samples:\n",
      "Average - KLD: 1.0618 | SIM: 0.4867 | NSS: 1.3412\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : cell_phone\n",
      "[40] Processing: sit_on - chair\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Metrics for all_output chair_002839.jpg:\n",
      " all_output Current - KLD: 0.9419 | SIM: 0.4231 | NSS: 1.1573\n",
      "\n",
      "Cumulative all_output  Averages over 41 samples:\n",
      "Average - KLD: 1.0589 | SIM: 0.4852 | NSS: 1.3367\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : chair\n",
      "[41] Processing: lie_on - couch\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output couch_003293.jpg:\n",
      " all_output Current - KLD: 0.6768 | SIM: 0.5116 | NSS: 1.5696\n",
      "\n",
      "Cumulative all_output  Averages over 42 samples:\n",
      "Average - KLD: 1.0498 | SIM: 0.4858 | NSS: 1.3423\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : couch\n",
      "[42] Processing: sit_on - couch\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output couch_000779.jpg:\n",
      " all_output Current - KLD: 0.7204 | SIM: 0.4992 | NSS: 2.0532\n",
      "\n",
      "Cumulative all_output  Averages over 43 samples:\n",
      "Average - KLD: 1.0421 | SIM: 0.4861 | NSS: 1.3588\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : couch\n",
      "[43] Processing: drink_with - cup\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output cup_000508.jpg:\n",
      " all_output Current - KLD: 0.5345 | SIM: 0.5716 | NSS: 2.6962\n",
      "\n",
      "Cumulative all_output  Averages over 44 samples:\n",
      "Average - KLD: 1.0306 | SIM: 0.4880 | NSS: 1.3892\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : cup\n",
      "[44] Processing: hold - cup\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output cup_002518.jpg:\n",
      " all_output Current - KLD: 1.4085 | SIM: 0.3039 | NSS: 1.5432\n",
      "\n",
      "Cumulative all_output  Averages over 45 samples:\n",
      "Average - KLD: 1.0390 | SIM: 0.4840 | NSS: 1.3926\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : cup\n",
      "[45] Processing: pour - cup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Metrics for all_output cup_001535.jpg:\n",
      " all_output Current - KLD: 1.3322 | SIM: 0.3381 | NSS: 1.7592\n",
      "\n",
      "Cumulative all_output  Averages over 46 samples:\n",
      "Average - KLD: 1.0454 | SIM: 0.4808 | NSS: 1.4006\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : cup\n",
      "[46] Processing: sip - cup\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output cup_001864.jpg:\n",
      " all_output Current - KLD: 0.5266 | SIM: 0.5988 | NSS: 0.9441\n",
      "\n",
      "Cumulative all_output  Averages over 47 samples:\n",
      "Average - KLD: 1.0343 | SIM: 0.4833 | NSS: 1.3909\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : cup\n",
      "[47] Processing: wash - cup\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output cup_003621.jpg:\n",
      " all_output Current - KLD: 1.1582 | SIM: 0.3400 | NSS: 1.6589\n",
      "\n",
      "Cumulative all_output  Averages over 48 samples:\n",
      "Average - KLD: 1.0369 | SIM: 0.4803 | NSS: 1.3965\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : cup\n",
      "[48] Processing: throw - discus\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output discus_003558.jpg:\n",
      " all_output Current - KLD: 0.5420 | SIM: 0.5842 | NSS: 0.6682\n",
      "\n",
      "Cumulative all_output  Averages over 49 samples:\n",
      "Average - KLD: 1.0268 | SIM: 0.4824 | NSS: 1.3816\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : discus\n",
      "[49] Processing: beat - drum\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output drum_002586.jpg:\n",
      " all_output Current - KLD: 1.0698 | SIM: 0.4058 | NSS: 0.1348\n",
      "\n",
      "Cumulative all_output  Averages over 50 samples:\n",
      "Average - KLD: 1.0277 | SIM: 0.4809 | NSS: 1.3567\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : drum\n",
      "[50] Processing: hold - fork\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Metrics for all_output fork_000804.jpg:\n",
      " all_output Current - KLD: 0.7383 | SIM: 0.4992 | NSS: 1.6246\n",
      "\n",
      "Cumulative all_output  Averages over 51 samples:\n",
      "Average - KLD: 1.0220 | SIM: 0.4813 | NSS: 1.3619\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : fork\n",
      "[51] Processing: lift - fork\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output fork_001691.jpg:\n",
      " all_output Current - KLD: 1.5182 | SIM: 0.2828 | NSS: 0.3793\n",
      "\n",
      "Cumulative all_output  Averages over 52 samples:\n",
      "Average - KLD: 1.0315 | SIM: 0.4774 | NSS: 1.3430\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : fork\n",
      "[52] Processing: stick - fork\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output fork_000095.jpg:\n",
      " all_output Current - KLD: 0.9237 | SIM: 0.4264 | NSS: 1.6346\n",
      "\n",
      "Cumulative all_output  Averages over 53 samples:\n",
      "Average - KLD: 1.0295 | SIM: 0.4765 | NSS: 1.3485\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : fork\n",
      "[53] Processing: wash - fork\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output fork_001691.jpg:\n",
      " all_output Current - KLD: 0.7085 | SIM: 0.5180 | NSS: 2.0433\n",
      "\n",
      "Cumulative all_output  Averages over 54 samples:\n",
      "Average - KLD: 1.0236 | SIM: 0.4772 | NSS: 1.3614\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : fork\n",
      "[54] Processing: catch - frisbee\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output frisbee_000598.jpg:\n",
      " all_output Current - KLD: 0.6128 | SIM: 0.5481 | NSS: 0.2225\n",
      "\n",
      "Cumulative all_output  Averages over 55 samples:\n",
      "Average - KLD: 1.0161 | SIM: 0.4785 | NSS: 1.3407\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : frisbee\n",
      "[55] Processing: hold - frisbee\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Metrics for all_output frisbee_001130.jpg:\n",
      " all_output Current - KLD: 0.4608 | SIM: 0.6172 | NSS: 0.4795\n",
      "\n",
      "Cumulative all_output  Averages over 56 samples:\n",
      "Average - KLD: 1.0062 | SIM: 0.4810 | NSS: 1.3253\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : frisbee\n",
      "[56] Processing: throw - frisbee\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output frisbee_003249.jpg:\n",
      " all_output Current - KLD: 0.6833 | SIM: 0.5291 | NSS: 0.4374\n",
      "\n",
      "Cumulative all_output  Averages over 57 samples:\n",
      "Average - KLD: 1.0005 | SIM: 0.4819 | NSS: 1.3097\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : frisbee\n",
      "[57] Processing: hold - golf_clubs\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output golf_clubs_000045.jpg:\n",
      " all_output Current - KLD: 1.7560 | SIM: 0.2384 | NSS: 0.6473\n",
      "\n",
      "Cumulative all_output  Averages over 58 samples:\n",
      "Average - KLD: 1.0135 | SIM: 0.4777 | NSS: 1.2983\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : golf_clubs\n",
      "[58] Processing: swing - golf_clubs\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output golf_clubs_001992.jpg:\n",
      " all_output Current - KLD: 2.2764 | SIM: 0.1429 | NSS: 0.4423\n",
      "\n",
      "Cumulative all_output  Averages over 59 samples:\n",
      "Average - KLD: 1.0349 | SIM: 0.4720 | NSS: 1.2838\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : golf_clubs\n",
      "[59] Processing: hit - hammer\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output hammer_001006.jpg:\n",
      " all_output Current - KLD: 1.7008 | SIM: 0.2164 | NSS: 0.3573\n",
      "\n",
      "Cumulative all_output  Averages over 60 samples:\n",
      "Average - KLD: 1.0460 | SIM: 0.4677 | NSS: 1.2684\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : hammer\n",
      "[60] Processing: hold - hammer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Metrics for all_output hammer_000215.jpg:\n",
      " all_output Current - KLD: 1.1199 | SIM: 0.3463 | NSS: 2.2765\n",
      "\n",
      "Cumulative all_output  Averages over 61 samples:\n",
      "Average - KLD: 1.0472 | SIM: 0.4657 | NSS: 1.2849\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : hammer\n",
      "[61] Processing: eat - hot_dog\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output hot_dog_002166.jpg:\n",
      " all_output Current - KLD: 0.2431 | SIM: 0.7255 | NSS: 1.0414\n",
      "\n",
      "Cumulative all_output  Averages over 62 samples:\n",
      "Average - KLD: 1.0343 | SIM: 0.4699 | NSS: 1.2810\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : hot_dog\n",
      "[62] Processing: throw - javelin\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output javelin_001474.jpg:\n",
      " all_output Current - KLD: 0.8591 | SIM: 0.4371 | NSS: 3.5100\n",
      "\n",
      "Cumulative all_output  Averages over 63 samples:\n",
      "Average - KLD: 1.0315 | SIM: 0.4694 | NSS: 1.3163\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : javelin\n",
      "[63] Processing: type_on - keyboard\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output keyboard_000439.jpg:\n",
      " all_output Current - KLD: 0.2139 | SIM: 0.7564 | NSS: 1.3810\n",
      "\n",
      "Cumulative all_output  Averages over 64 samples:\n",
      "Average - KLD: 1.0187 | SIM: 0.4739 | NSS: 1.3174\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : keyboard\n",
      "[64] Processing: cut_with - knife\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output knife_001749.jpg:\n",
      " all_output Current - KLD: 0.6769 | SIM: 0.5221 | NSS: 1.9077\n",
      "\n",
      "Cumulative all_output  Averages over 65 samples:\n",
      "Average - KLD: 1.0135 | SIM: 0.4746 | NSS: 1.3264\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : knife\n",
      "[65] Processing: hold - knife\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Metrics for all_output knife_002682.jpg:\n",
      " all_output Current - KLD: 1.0795 | SIM: 0.3677 | NSS: 1.6216\n",
      "\n",
      "Cumulative all_output  Averages over 66 samples:\n",
      "Average - KLD: 1.0145 | SIM: 0.4730 | NSS: 1.3309\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : knife\n",
      "[66] Processing: stick - knife\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output knife_001072.jpg:\n",
      " all_output Current - KLD: 1.4228 | SIM: 0.2739 | NSS: 1.8817\n",
      "\n",
      "Cumulative all_output  Averages over 67 samples:\n",
      "Average - KLD: 1.0206 | SIM: 0.4700 | NSS: 1.3391\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : knife\n",
      "[67] Processing: wash - knife\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output knife_002720.jpg:\n",
      " all_output Current - KLD: 0.6384 | SIM: 0.5777 | NSS: 2.7673\n",
      "\n",
      "Cumulative all_output  Averages over 68 samples:\n",
      "Average - KLD: 1.0149 | SIM: 0.4716 | NSS: 1.3601\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : knife\n",
      "[68] Processing: type_on - laptop\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output laptop_000585.jpg:\n",
      " all_output Current - KLD: 1.1531 | SIM: 0.3700 | NSS: 1.2968\n",
      "\n",
      "Cumulative all_output  Averages over 69 samples:\n",
      "Average - KLD: 1.0169 | SIM: 0.4701 | NSS: 1.3592\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : laptop\n",
      "[69] Processing: open - microwave\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output microwave_001049.jpg:\n",
      " all_output Current - KLD: 1.4303 | SIM: 0.2918 | NSS: 0.6511\n",
      "\n",
      "Cumulative all_output  Averages over 70 samples:\n",
      "Average - KLD: 1.0228 | SIM: 0.4676 | NSS: 1.3491\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : microwave\n",
      "[70] Processing: push - motorcycle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Metrics for all_output motorcycle_003541.jpg:\n",
      " all_output Current - KLD: 1.2897 | SIM: 0.3478 | NSS: 1.3061\n",
      "\n",
      "Cumulative all_output  Averages over 71 samples:\n",
      "Average - KLD: 1.0266 | SIM: 0.4659 | NSS: 1.3485\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : motorcycle\n",
      "[71] Processing: ride - motorcycle\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output motorcycle_002198.jpg:\n",
      " all_output Current - KLD: 1.0097 | SIM: 0.4103 | NSS: 1.5372\n",
      "\n",
      "Cumulative all_output  Averages over 72 samples:\n",
      "Average - KLD: 1.0264 | SIM: 0.4651 | NSS: 1.3511\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : motorcycle\n",
      "[72] Processing: sit_on - motorcycle\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output motorcycle_000837.jpg:\n",
      " all_output Current - KLD: 1.5893 | SIM: 0.2379 | NSS: 2.0136\n",
      "\n",
      "Cumulative all_output  Averages over 73 samples:\n",
      "Average - KLD: 1.0341 | SIM: 0.4620 | NSS: 1.3602\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : motorcycle\n",
      "[73] Processing: cut - orange\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output orange_001193.jpg:\n",
      " all_output Current - KLD: 1.0870 | SIM: 0.5825 | NSS: 1.2510\n",
      "\n",
      "Cumulative all_output  Averages over 74 samples:\n",
      "Average - KLD: 1.0348 | SIM: 0.4637 | NSS: 1.3587\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : orange\n",
      "[74] Processing: eat - orange\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output orange_001193.jpg:\n",
      " all_output Current - KLD: 1.0406 | SIM: 0.5892 | NSS: 1.2873\n",
      "\n",
      "Cumulative all_output  Averages over 75 samples:\n",
      "Average - KLD: 1.0349 | SIM: 0.4653 | NSS: 1.3578\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : orange\n",
      "[75] Processing: peel - orange\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Metrics for all_output orange_001193.jpg:\n",
      " all_output Current - KLD: 0.9991 | SIM: 0.5870 | NSS: 1.2169\n",
      "\n",
      "Cumulative all_output  Averages over 76 samples:\n",
      "Average - KLD: 1.0344 | SIM: 0.4669 | NSS: 1.3559\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : orange\n",
      "[76] Processing: wash - orange\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output orange_001193.jpg:\n",
      " all_output Current - KLD: 0.9517 | SIM: 0.6144 | NSS: 1.1906\n",
      "\n",
      "Cumulative all_output  Averages over 77 samples:\n",
      "Average - KLD: 1.0333 | SIM: 0.4688 | NSS: 1.3538\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : orange\n",
      "[77] Processing: open - oven\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output oven_001370.jpg:\n",
      " all_output Current - KLD: 1.1425 | SIM: 0.3526 | NSS: 1.2514\n",
      "\n",
      "Cumulative all_output  Averages over 78 samples:\n",
      "Average - KLD: 1.0347 | SIM: 0.4674 | NSS: 1.3524\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : oven\n",
      "[78] Processing: write - pen\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output pen_003590.jpg:\n",
      " all_output Current - KLD: 1.3521 | SIM: 0.2911 | NSS: 1.2223\n",
      "\n",
      "Cumulative all_output  Averages over 79 samples:\n",
      "Average - KLD: 1.0387 | SIM: 0.4651 | NSS: 1.3508\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : pen\n",
      "[79] Processing: boxing - punching_bag\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output punching_bag_001845.jpg:\n",
      " all_output Current - KLD: 0.6545 | SIM: 0.5412 | NSS: 0.3783\n",
      "\n",
      "Cumulative all_output  Averages over 80 samples:\n",
      "Average - KLD: 1.0339 | SIM: 0.4661 | NSS: 1.3386\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : punching_bag\n",
      "[80] Processing: kick - punching_bag\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Metrics for all_output punching_bag_001639.jpg:\n",
      " all_output Current - KLD: 0.7717 | SIM: 0.4818 | NSS: 0.7393\n",
      "\n",
      "Cumulative all_output  Averages over 81 samples:\n",
      "Average - KLD: 1.0307 | SIM: 0.4663 | NSS: 1.3312\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : punching_bag\n",
      "[81] Processing: open - refrigerator\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output refrigerator_002162.jpg:\n",
      " all_output Current - KLD: 1.3063 | SIM: 0.3079 | NSS: 0.5896\n",
      "\n",
      "Cumulative all_output  Averages over 82 samples:\n",
      "Average - KLD: 1.0341 | SIM: 0.4643 | NSS: 1.3222\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : refrigerator\n",
      "[82] Processing: catch - rugby_ball\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output rugby_ball_003522.jpg:\n",
      " all_output Current - KLD: 0.3981 | SIM: 0.6598 | NSS: 0.5623\n",
      "\n",
      "Cumulative all_output  Averages over 83 samples:\n",
      "Average - KLD: 1.0264 | SIM: 0.4667 | NSS: 1.3130\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : rugby_ball\n",
      "[83] Processing: kick - rugby_ball\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output rugby_ball_002080.jpg:\n",
      " all_output Current - KLD: 0.2020 | SIM: 0.7617 | NSS: 0.9668\n",
      "\n",
      "Cumulative all_output  Averages over 84 samples:\n",
      "Average - KLD: 1.0166 | SIM: 0.4702 | NSS: 1.3089\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : rugby_ball\n",
      "[84] Processing: throw - rugby_ball\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output rugby_ball_000001.jpg:\n",
      " all_output Current - KLD: 0.3499 | SIM: 0.6830 | NSS: 0.8047\n",
      "\n",
      "Cumulative all_output  Averages over 85 samples:\n",
      "Average - KLD: 1.0087 | SIM: 0.4727 | NSS: 1.3030\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : rugby_ball\n",
      "[85] Processing: cut_with - scissors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Metrics for all_output scissors_002479.jpg:\n",
      " all_output Current - KLD: 1.2020 | SIM: 0.3276 | NSS: 1.7052\n",
      "\n",
      "Cumulative all_output  Averages over 86 samples:\n",
      "Average - KLD: 1.0110 | SIM: 0.4710 | NSS: 1.3077\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : scissors\n",
      "[86] Processing: hold - scissors\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output scissors_002479.jpg:\n",
      " all_output Current - KLD: 0.6258 | SIM: 0.5596 | NSS: 1.5116\n",
      "\n",
      "Cumulative all_output  Averages over 87 samples:\n",
      "Average - KLD: 1.0066 | SIM: 0.4720 | NSS: 1.3100\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : scissors\n",
      "[87] Processing: carry - skateboard\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output skateboard_002668.jpg:\n",
      " all_output Current - KLD: 0.1759 | SIM: 0.7872 | NSS: 0.8557\n",
      "\n",
      "Cumulative all_output  Averages over 88 samples:\n",
      "Average - KLD: 0.9971 | SIM: 0.4756 | NSS: 1.3048\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : skateboard\n",
      "[88] Processing: hold - skateboard\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output skateboard_002387.jpg:\n",
      " all_output Current - KLD: 0.6044 | SIM: 0.5763 | NSS: 0.9375\n",
      "\n",
      "Cumulative all_output  Averages over 89 samples:\n",
      "Average - KLD: 0.9927 | SIM: 0.4767 | NSS: 1.3007\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : skateboard\n",
      "[89] Processing: jump - skateboard\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output skateboard_002387.jpg:\n",
      " all_output Current - KLD: 1.0379 | SIM: 0.3982 | NSS: 1.1573\n",
      "\n",
      "Cumulative all_output  Averages over 90 samples:\n",
      "Average - KLD: 0.9932 | SIM: 0.4759 | NSS: 1.2991\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : skateboard\n",
      "[90] Processing: sit_on - skateboard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Metrics for all_output skateboard_001460.jpg:\n",
      " all_output Current - KLD: 0.2957 | SIM: 0.7147 | NSS: 1.0807\n",
      "\n",
      "Cumulative all_output  Averages over 91 samples:\n",
      "Average - KLD: 0.9855 | SIM: 0.4785 | NSS: 1.2967\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : skateboard\n",
      "[91] Processing: carry - skis\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output skis_002829.jpg:\n",
      " all_output Current - KLD: 2.3580 | SIM: 0.1243 | NSS: -0.1208\n",
      "\n",
      "Cumulative all_output  Averages over 92 samples:\n",
      "Average - KLD: 1.0005 | SIM: 0.4746 | NSS: 1.2813\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : skis\n",
      "[92] Processing: hold - skis\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output skis_001357.jpg:\n",
      " all_output Current - KLD: 2.1194 | SIM: 0.1553 | NSS: 0.6582\n",
      "\n",
      "Cumulative all_output  Averages over 93 samples:\n",
      "Average - KLD: 1.0125 | SIM: 0.4712 | NSS: 1.2746\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : skis\n",
      "[93] Processing: jump - skis\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output skis_002829.jpg:\n",
      " all_output Current - KLD: 2.3550 | SIM: 0.1282 | NSS: -0.1108\n",
      "\n",
      "Cumulative all_output  Averages over 94 samples:\n",
      "Average - KLD: 1.0268 | SIM: 0.4676 | NSS: 1.2599\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : skis\n",
      "[94] Processing: pick_up - skis\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output skis_001547.jpg:\n",
      " all_output Current - KLD: 2.1505 | SIM: 0.1564 | NSS: 0.6243\n",
      "\n",
      "Cumulative all_output  Averages over 95 samples:\n",
      "Average - KLD: 1.0386 | SIM: 0.4643 | NSS: 1.2532\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : skis\n",
      "[95] Processing: carry - snowboard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Metrics for all_output snowboard_001325.jpg:\n",
      " all_output Current - KLD: 1.5219 | SIM: 0.2611 | NSS: 1.6354\n",
      "\n",
      "Cumulative all_output  Averages over 96 samples:\n",
      "Average - KLD: 1.0436 | SIM: 0.4622 | NSS: 1.2572\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : snowboard\n",
      "[96] Processing: hold - snowboard\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output snowboard_001704.jpg:\n",
      " all_output Current - KLD: 1.7223 | SIM: 0.2297 | NSS: 0.1896\n",
      "\n",
      "Cumulative all_output  Averages over 97 samples:\n",
      "Average - KLD: 1.0506 | SIM: 0.4598 | NSS: 1.2462\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : snowboard\n",
      "[97] Processing: jump - snowboard\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output snowboard_001704.jpg:\n",
      " all_output Current - KLD: 1.2776 | SIM: 0.3496 | NSS: -0.0302\n",
      "\n",
      "Cumulative all_output  Averages over 98 samples:\n",
      "Average - KLD: 1.0530 | SIM: 0.4587 | NSS: 1.2331\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : snowboard\n",
      "[98] Processing: catch - soccer_ball\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output soccer_ball_003333.jpg:\n",
      " all_output Current - KLD: 0.1160 | SIM: 0.8150 | NSS: 1.2700\n",
      "\n",
      "Cumulative all_output  Averages over 99 samples:\n",
      "Average - KLD: 1.0435 | SIM: 0.4623 | NSS: 1.2335\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : soccer_ball\n",
      "[99] Processing: kick - soccer_ball\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output soccer_ball_001588.jpg:\n",
      " all_output Current - KLD: 0.0348 | SIM: 0.9182 | NSS: 2.2685\n",
      "\n",
      "Cumulative all_output  Averages over 100 samples:\n",
      "Average - KLD: 1.0334 | SIM: 0.4668 | NSS: 1.2439\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : soccer_ball\n",
      "[100] Processing: drag - suitcase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Metrics for all_output suitcase_002998.jpg:\n",
      " all_output Current - KLD: 3.3540 | SIM: 0.0626 | NSS: 0.3980\n",
      "\n",
      "Cumulative all_output  Averages over 101 samples:\n",
      "Average - KLD: 1.0564 | SIM: 0.4628 | NSS: 1.2355\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : suitcase\n",
      "[101] Processing: hold - suitcase\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output suitcase_003687.jpg:\n",
      " all_output Current - KLD: 1.8059 | SIM: 0.2131 | NSS: 1.4258\n",
      "\n",
      "Cumulative all_output  Averages over 102 samples:\n",
      "Average - KLD: 1.0637 | SIM: 0.4604 | NSS: 1.2374\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : suitcase\n",
      "[102] Processing: open - suitcase\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output suitcase_000520.jpg:\n",
      " all_output Current - KLD: 2.0698 | SIM: 0.1842 | NSS: 0.1724\n",
      "\n",
      "Cumulative all_output  Averages over 103 samples:\n",
      "Average - KLD: 1.0735 | SIM: 0.4577 | NSS: 1.2270\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : suitcase\n",
      "[103] Processing: pack - suitcase\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output suitcase_002212.jpg:\n",
      " all_output Current - KLD: 0.9747 | SIM: 0.4088 | NSS: 0.5940\n",
      "\n",
      "Cumulative all_output  Averages over 104 samples:\n",
      "Average - KLD: 1.0725 | SIM: 0.4572 | NSS: 1.2209\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : suitcase\n",
      "[104] Processing: pick_up - suitcase\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output suitcase_002493.jpg:\n",
      " all_output Current - KLD: 2.2803 | SIM: 0.1443 | NSS: 1.0100\n",
      "\n",
      "Cumulative all_output  Averages over 105 samples:\n",
      "Average - KLD: 1.0840 | SIM: 0.4542 | NSS: 1.2189\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : suitcase\n",
      "[105] Processing: carry - surfboard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Metrics for all_output surfboard_002422.jpg:\n",
      " all_output Current - KLD: 3.1968 | SIM: 0.0767 | NSS: -0.4178\n",
      "\n",
      "Cumulative all_output  Averages over 106 samples:\n",
      "Average - KLD: 1.1040 | SIM: 0.4507 | NSS: 1.2035\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : surfboard\n",
      "[106] Processing: hold - surfboard\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output surfboard_002631.jpg:\n",
      " all_output Current - KLD: 0.6471 | SIM: 0.5264 | NSS: 2.7242\n",
      "\n",
      "Cumulative all_output  Averages over 107 samples:\n",
      "Average - KLD: 1.0997 | SIM: 0.4514 | NSS: 1.2177\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : surfboard\n",
      "[107] Processing: jump - surfboard\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output surfboard_000658.jpg:\n",
      " all_output Current - KLD: 0.8832 | SIM: 0.4537 | NSS: 0.3873\n",
      "\n",
      "Cumulative all_output  Averages over 108 samples:\n",
      "Average - KLD: 1.0977 | SIM: 0.4514 | NSS: 1.2100\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : surfboard\n",
      "[108] Processing: lie_on - surfboard\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output surfboard_000221.jpg:\n",
      " all_output Current - KLD: 0.0728 | SIM: 0.8506 | NSS: 2.2481\n",
      "\n",
      "Cumulative all_output  Averages over 109 samples:\n",
      "Average - KLD: 1.0883 | SIM: 0.4551 | NSS: 1.2195\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : surfboard\n",
      "[109] Processing: sit_on - surfboard\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output surfboard_000010.jpg:\n",
      " all_output Current - KLD: 0.2489 | SIM: 0.7265 | NSS: 0.1871\n",
      "\n",
      "Cumulative all_output  Averages over 110 samples:\n",
      "Average - KLD: 1.0807 | SIM: 0.4575 | NSS: 1.2101\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : surfboard\n",
      "[110] Processing: hit - tennis_racket\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Metrics for all_output tennis_racket_002268.jpg:\n",
      " all_output Current - KLD: 3.5558 | SIM: 0.0570 | NSS: -0.4596\n",
      "\n",
      "Cumulative all_output  Averages over 111 samples:\n",
      "Average - KLD: 1.1030 | SIM: 0.4539 | NSS: 1.1951\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : tennis_racket\n",
      "[111] Processing: hold - tennis_racket\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output tennis_racket_001785.jpg:\n",
      " all_output Current - KLD: 1.3627 | SIM: 0.2897 | NSS: 1.9682\n",
      "\n",
      "Cumulative all_output  Averages over 112 samples:\n",
      "Average - KLD: 1.1053 | SIM: 0.4525 | NSS: 1.2020\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : tennis_racket\n",
      "[112] Processing: swing - tennis_racket\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output tennis_racket_003066.jpg:\n",
      " all_output Current - KLD: 2.3177 | SIM: 0.1149 | NSS: 0.0039\n",
      "\n",
      "Cumulative all_output  Averages over 113 samples:\n",
      "Average - KLD: 1.1160 | SIM: 0.4495 | NSS: 1.1914\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : tennis_racket\n",
      "[113] Processing: brush_with - toothbrush\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output toothbrush_001764.jpg:\n",
      " all_output Current - KLD: 1.4916 | SIM: 0.2485 | NSS: 2.0183\n",
      "\n",
      "Cumulative all_output  Averages over 114 samples:\n",
      "Average - KLD: 1.1193 | SIM: 0.4477 | NSS: 1.1987\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : toothbrush\n",
      "[114] Processing: hold - toothbrush\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output toothbrush_003341.jpg:\n",
      " all_output Current - KLD: 1.6106 | SIM: 0.2409 | NSS: 1.0162\n",
      "\n",
      "Cumulative all_output  Averages over 115 samples:\n",
      "Average - KLD: 1.1236 | SIM: 0.4459 | NSS: 1.1971\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : toothbrush\n",
      "[115] Processing: wash - toothbrush\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Metrics for all_output toothbrush_001991.jpg:\n",
      " all_output Current - KLD: 1.3147 | SIM: 0.2980 | NSS: 1.3923\n",
      "\n",
      "Cumulative all_output  Averages over 116 samples:\n",
      "Average - KLD: 1.1252 | SIM: 0.4446 | NSS: 1.1987\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : toothbrush\n",
      "[116] Processing: drink_with - wine_glass\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output wine_glass_003343.jpg:\n",
      " all_output Current - KLD: 1.6465 | SIM: 0.2253 | NSS: 0.7406\n",
      "\n",
      "Cumulative all_output  Averages over 117 samples:\n",
      "Average - KLD: 1.1297 | SIM: 0.4428 | NSS: 1.1948\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : wine_glass\n",
      "[117] Processing: hold - wine_glass\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output wine_glass_002374.jpg:\n",
      " all_output Current - KLD: 0.8909 | SIM: 0.4494 | NSS: 1.2962\n",
      "\n",
      "Cumulative all_output  Averages over 118 samples:\n",
      "Average - KLD: 1.1277 | SIM: 0.4428 | NSS: 1.1957\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : wine_glass\n",
      "[118] Processing: pour - wine_glass\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output wine_glass_000186.jpg:\n",
      " all_output Current - KLD: 1.1221 | SIM: 0.3573 | NSS: 1.0977\n",
      "\n",
      "Cumulative all_output  Averages over 119 samples:\n",
      "Average - KLD: 1.1276 | SIM: 0.4421 | NSS: 1.1949\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : wine_glass\n",
      "[119] Processing: sip - wine_glass\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output wine_glass_003343.jpg:\n",
      " all_output Current - KLD: 1.7787 | SIM: 0.2054 | NSS: 0.5768\n",
      "\n",
      "Cumulative all_output  Averages over 120 samples:\n",
      "Average - KLD: 1.1330 | SIM: 0.4401 | NSS: 1.1897\n",
      "==================================================\n",
      "\n",
      "clipseg_input_text : wine_glass\n"
     ]
    }
   ],
   "source": [
    "metrics_tracker_alloutput = MetricsTracker(name=\"all_output\")\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "#   \n",
    "Layername = \"Top1_layerminmax_ALL\"\n",
    "output_dir = f\"./output_{Layername}\"  #    ( )s\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Contrastive Subtraction   (0.5 ~ 1.0 )\n",
    "\n",
    "POS_ALPHA = 0\n",
    "\n",
    "for i in range(24):\n",
    "    i += 1\n",
    "    pkl_path = f\"output_results/attention_result_full_output_32B_{i}.pkl\"\n",
    "    if not os.path.exists(pkl_path):\n",
    "        continue\n",
    "        \n",
    "    df_output = pd.read_pickle(pkl_path)\n",
    "\n",
    "    for idx, row in df_output.iterrows():\n",
    "        object_name = row['object']\n",
    "        action = row['action']\n",
    "        filename = row['filename']\n",
    "        output_description = row['output_sentence']\n",
    "        output_attentions = row['output_attentions']\n",
    "        \n",
    "        file_name_real = f\"{AGD20K_PATH}/Seen/testset/egocentric/{action}/{object_name}/{filename}\"\n",
    "        gt_path = f\"{AGD20K_PATH}/Seen/testset/GT/{action}/{object_name}/{filename.split('.')[0]}.png\"\n",
    "            \n",
    "        #  \n",
    "        if not os.path.exists(file_name_real):\n",
    "            print(f\"Image not found: {file_name_real}\")\n",
    "            continue\n",
    "\n",
    "        orig_img = cv2.imread(file_name_real)\n",
    "        orig_img = cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB)\n",
    "        h, w, _ = orig_img.shape\n",
    "\n",
    "        print(f\"[{idx}] Processing: {action} - {object_name}\")\n",
    "\n",
    "        # --- 1. CLIPSeg Mask  ---\n",
    "\n",
    "        clip_heatmap = get_clipseg_heatmap(\n",
    "            file_name_real,\n",
    "            clip_model,\n",
    "            clip_processor,\n",
    "            object_name,\n",
    "        )\n",
    "\n",
    "        # CLIPSeg  31x31 \n",
    "        clip_heatmap_resized = cv2.resize(clip_heatmap, (31, 31), interpolation=cv2.INTER_LINEAR)\n",
    "        clip_binary_mask = (clip_heatmap_resized > 0.15).astype(np.float32) #  \n",
    "\n",
    "        # --- 2. [] Contrastive Attention Map  ---\n",
    "        token_scores = []\n",
    "        token_idx = 0\n",
    "        for token in output_attentions:\n",
    "            #   \n",
    "            token_heatmap = np.zeros((31, 31), dtype=np.float32)\n",
    "            token_head_count = 0\n",
    "            layer_maps_temp = {}\n",
    "\n",
    "            attention_value = token['attentions']\n",
    "            decoded_str = token['token_str'] # \n",
    "\n",
    "            for each_attention in attention_value:\n",
    "                layer = each_attention['layer']\n",
    "                head = each_attention['head']\n",
    "                heatmap = each_attention['heatmap']\n",
    "                \n",
    "                # #      ( Layer 0 )\n",
    "                # if each_attention['layer'] != 0:\n",
    "                if 1==1: # (layer <=45) and (layer >= 20): #1==1: # (layer == 26) : #and( head ==20)) : #or ((layer == 24) and( head ==31)):\n",
    "                    if layer not in layer_maps_temp:\n",
    "                        layer_maps_temp[layer] = np.zeros((31, 31), dtype=np.float32)\n",
    "                    layer_maps_temp[layer] += heatmap\n",
    "                    token_heatmap += each_attention['heatmap']\n",
    "                    token_head_count += 1\n",
    "\n",
    "                    # ##  :    \n",
    "                    # current_heatmap = each_attention['heatmap'].copy()\n",
    "\n",
    "                    # # 2.    .\n",
    "                    # max_value = np.max(current_heatmap)\n",
    "\n",
    "                    # # 3.        0 .\n",
    "                    # # (     0 .)\n",
    "                    # current_heatmap[current_heatmap == max_value] = 0\n",
    "                    # token_heatmap += current_heatmap\n",
    "                    # ## \n",
    "                    # # minmax_each = min_max_normalize(each_attention['heatmap'])\n",
    "                    # # sum_heatmap += minmax_each\n",
    "                    # token_head_count += 1\n",
    "\n",
    "\n",
    "            # token_minmax_heatmap = np.zeros((31, 31), dtype=np.float32)\n",
    "\n",
    "            # for layer_idx, raw_layer_map in layer_maps_temp.items():\n",
    "            #     # Min-Max Normalization \n",
    "            #     min_val = raw_layer_map.min()\n",
    "            #     max_val = raw_layer_map.max()\n",
    "                \n",
    "            #     # 0   (  ,     0   )\n",
    "            #     if (max_val - min_val) > 1e-9:\n",
    "            #         normalized_layer_map = (raw_layer_map - min_val) / (max_val - min_val)\n",
    "            #     else:\n",
    "            #         normalized_layer_map = np.zeros_like(raw_layer_map) #   0 \n",
    "                \n",
    "            #     #     \n",
    "            #     token_minmax_heatmap += normalized_layer_map\n",
    "\n",
    "\n",
    "            #      \n",
    "            if token_head_count == 0:\n",
    "                continue\n",
    "\n",
    "            # Visual Dependency Score (S_img) :  \n",
    "            s_img = token_heatmap.sum()\n",
    "            ## clipseg    \n",
    "            # flat_token = token_heatmap.flatten()\n",
    "            # flat_clip = clip_heatmap_resized.flatten()\n",
    "\n",
    "            # norm_token = np.linalg.norm(flat_token)\n",
    "            # norm_clip = np.linalg.norm(flat_clip)\n",
    "    \n",
    "            # s_img = np.dot(flat_token, flat_clip) / (norm_token * norm_clip)\n",
    "            \n",
    "            #  \n",
    "            token_scores.append({\n",
    "                \"token\": decoded_str,\n",
    "                \"token_idx\" : token_idx,\n",
    "                \"score\": s_img,\n",
    "                \"heatmap\": token_heatmap, \n",
    "                \"count\": token_head_count\n",
    "            })\n",
    "            token_idx +=1\n",
    "        #  :   \n",
    "        if len(token_scores) == 0:\n",
    "            print(\"No valid tokens found.\")\n",
    "            continue\n",
    "\n",
    "        #  (Score  )\n",
    "        sorted_tokens = sorted(token_scores, key=lambda x: x['score'])\n",
    "        \n",
    "        # Top 5 (Signal) & Bottom 5 (Noise) \n",
    "        #   10   \n",
    "        num_select = min(1, len(sorted_tokens) // 2)\n",
    "        if num_select < 1: num_select = 1 #  1\n",
    "\n",
    "        bottom_tokens = sorted_tokens[:num_select]       # Noise (,  )\n",
    "        top_tokens = sorted_tokens[-num_select:][::-1]   # Signal (, )\n",
    "        ##  last \n",
    "        # top_tokens = sorted_tokens[:num_select]       # Noise (,  )\n",
    "        # bottom_tokens = sorted_tokens[-num_select:][::-1]   # Signal (, )\n",
    "\n",
    "\n",
    "        # Signal Map (Positive) \n",
    "        # pos_map = np.sum([t['heatmap'] for t in top_tokens], axis=0)\n",
    "        # pos_map /= len(top_tokens)\n",
    "\n",
    "        pos_layer_maps = {}\n",
    "\n",
    "        # 2. Top Token   /     \n",
    "        for t_info in top_tokens:\n",
    "            t_idx = t_info['token_idx']\n",
    "            # output_attentions       \n",
    "            raw_attentions = output_attentions[t_idx]['attentions']\n",
    "\n",
    "            for attn_item in raw_attentions:\n",
    "                ly = attn_item['layer']\n",
    "                hm = attn_item['heatmap']\n",
    "                \n",
    "                #   (    )\n",
    "                if 1==1: \n",
    "                    if ly not in pos_layer_maps:\n",
    "                        pos_layer_maps[ly] = np.zeros((31, 31), dtype=np.float32)\n",
    "                    \n",
    "                    #  ,        \n",
    "                    pos_layer_maps[ly] += hm\n",
    "\n",
    "        # 3.     Min-Max    pos_map \n",
    "        pos_map = np.zeros((31, 31), dtype=np.float32)\n",
    "\n",
    "        for ly, raw_map in pos_layer_maps.items():\n",
    "            min_val = raw_map.min()\n",
    "            max_val = raw_map.max()\n",
    "\n",
    "            # 0  \n",
    "            if (max_val - min_val) > 1e-9:\n",
    "                norm_map = (raw_map - min_val) / (max_val - min_val)\n",
    "            else:\n",
    "                norm_map = np.zeros_like(raw_map)\n",
    "            \n",
    "            pos_map += norm_map\n",
    "\n",
    "\n",
    "        top_token_idx  = top_tokens[-1]['token_idx']\n",
    "        top_token_text  = top_tokens[-1]['token']\n",
    "\n",
    "        following_token_idx = top_token_idx + 1\n",
    "        following_token = None\n",
    "        for item in token_scores:\n",
    "            if item['token_idx'] == following_token_idx:\n",
    "                following_token = item\n",
    "                break\n",
    "        following_text = following_token['token']\n",
    "        # if following_token is not None:            \n",
    "        #     #    pos_map  ( 0.5~1.0 ,  )\n",
    "        #     weight_prev = 1  #   (0.5~1.0  )\n",
    "        #     pos_map =(pos_map + weight_prev * following_token['heatmap'])/2\n",
    "            \n",
    "        #     #  (   normalize - !)\n",
    "        #     pos_map = pos_map / pos_map.max() if pos_map.max() > 0 else pos_map\n",
    "        # else:\n",
    "        #     raise ValueError(\"No following token found\")\n",
    "\n",
    "\n",
    "\n",
    "        # Noise Map (Negative) \n",
    "        neg_map = np.sum([t['heatmap'] for t in bottom_tokens], axis=0)\n",
    "        neg_map /= len(bottom_tokens)\n",
    "\n",
    "\n",
    "        # # ---  : neg_map  95%  sink-like filtering ---\n",
    "        # # 1) 95 percentile threshold \n",
    "        # threshold_95 = np.percentile(neg_map, 95)\n",
    "\n",
    "        # # 2) threshold  0 \n",
    "        # neg_map_filtered = np.where(neg_map >= threshold_95, neg_map, 0)\n",
    "\n",
    "        # # 3)  (0~1)\n",
    "        # if neg_map_filtered.max() > 0:\n",
    "        #     neg_map_filtered = neg_map_filtered / neg_map_filtered.max()\n",
    "\n",
    "        # #  contrastive  filtered map \n",
    "        # neg_map = neg_map_filtered\n",
    "\n",
    "\n",
    "        #  (   0~1    )\n",
    "        if pos_map.max() > 0: pos_map /= pos_map.max()\n",
    "        if neg_map.max() > 0: neg_map /= neg_map.max()\n",
    "\n",
    "        #  Contrastive Subtraction (Signal - alpha * Noise)\n",
    "        CONTRASTIVE_ALPHA = 0\n",
    "        contrastive_heatmap = (pos_map) - (CONTRASTIVE_ALPHA * neg_map)\n",
    "        # contrastive_heatmap_threshold_5 = np.percentile(contrastive_heatmap, 5)\n",
    "        # contrastive_heatmap = np.where(contrastive_heatmap <= contrastive_heatmap_threshold_5, contrastive_heatmap_threshold_5, contrastive_heatmap)\n",
    "        # contrastive_heatmap = np.maximum(contrastive_heatmap, 0) # ReLU ( )\n",
    "\n",
    "        # --- 3.    (   ) ---\n",
    "        # Contrastive Map avg_norm   (0~1 )\n",
    "        h_min, h_max = contrastive_heatmap.min(), contrastive_heatmap.max()\n",
    "        avg_norm = (contrastive_heatmap - h_min) / (h_max - h_min + 1e-8)\n",
    "\n",
    "        clipseg_input_text = object_name\n",
    "\n",
    "        # clipseg_input_text = top_token_text + ' ' + following_text\n",
    "        # clip_heatmap = get_clipseg_heatmap(\n",
    "        #     file_name_real,\n",
    "        #     clip_model,\n",
    "        #     clip_processor,\n",
    "        #     clipseg_input_text,\n",
    "            \n",
    "        # )\n",
    "\n",
    "        # # CLIPSeg  31x31 \n",
    "        # clip_heatmap_resized = cv2.resize(clip_heatmap, (31, 31), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "\n",
    "        # CLIPSeg Hadamard Product\n",
    "        avg_norm_cliped = avg_norm * clip_heatmap_resized\n",
    "\n",
    "        #   \n",
    "        avg_norm_cliped_rescaled = cv2.resize(avg_norm_cliped, (w, h), interpolation=cv2.INTER_LINEAR)\n",
    "        \n",
    "        sig = min(w, h) * 0.05\n",
    "        k_val = int(sig * 3) * 2 + 1 \n",
    "        kernel_size = (k_val, k_val)\n",
    "\n",
    "        #  \n",
    "        blur_map = cv2.GaussianBlur(avg_norm_cliped_rescaled, kernel_size, sig)\n",
    "\n",
    "        #    \n",
    "        blur_map = min_max_normalize(blur_map) #    \n",
    "        avg_norm_cliped_blur = blur_map\n",
    "        \n",
    "        #   31x31    \n",
    "        avg_norm_resized_vis = cv2.resize(avg_norm, (w, h), interpolation=cv2.INTER_LINEAR)\n",
    "        clip_vis = cv2.resize(clip_heatmap_resized, (w, h), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        # --- 4. GT     ---\n",
    "        gt_map = load_ground_truth(gt_path) #   \n",
    "        if gt_map is not None:\n",
    "            metrics_dino = calculate_metrics(avg_norm_cliped_blur, gt_map) #   \n",
    "            metrics_tracker_alloutput.update(metrics_dino) #   \n",
    "            \n",
    "            #  \n",
    "            metrics_text = f\"[{object_name} {action}] KLD: {metrics_dino['KLD']:.4f} | SIM: {metrics_dino['SIM']:.4f} | NSS: {metrics_dino['NSS']:.4f}\"\n",
    "            metrics_tracker_alloutput.print_metrics(metrics_dino, filename)\n",
    "        else:\n",
    "            print(\"NO GT!!!\")\n",
    "            metrics_text = \"No GT Available\"\n",
    "            continue\n",
    "\n",
    "        # --- 5.  ---\n",
    "        fig, axes = plt.subplots(1, 6, figsize=(24, 5)) #   \n",
    "        \n",
    "        # Signal  Noise   ()\n",
    "        top_words = \",\".join([f\"'{t['token'].strip()}'\" for t in top_tokens[:5]])\n",
    "        \n",
    "        main_title = f\"Obj: {object_name} | Act: {action} |{metrics_text}\\nTop Tokens: [{top_words}({top_token_idx } ), clipseg input : {top_token_text} {following_text}] \\n Whole answer : {output_description}\"\n",
    "        fig.suptitle(main_title, fontsize=14, fontweight='bold', y=0.98)\n",
    "\n",
    "        # (1)  \n",
    "        axes[0].imshow(orig_img)\n",
    "        axes[0].set_title(f\"Original\\n({object_name})\")\n",
    "        axes[0].axis('off')\n",
    "\n",
    "        # (2) Contrastive Attention (Pos - Neg)\n",
    "        im1 = axes[1].imshow(avg_norm_resized_vis, cmap='jet', interpolation='bilinear')\n",
    "        axes[1].set_title(f\"Attention Map {Layername}\")\n",
    "        axes[1].axis('off')\n",
    "        plt.colorbar(im1, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "\n",
    "        # (3) CLIPSeg Result\n",
    "        axes[2].imshow(clip_vis, cmap='gray')\n",
    "        axes[2].set_title(f\"CLIPSeg {clipseg_input_text}\")\n",
    "        axes[2].axis('off')\n",
    "\n",
    "        # (4) Hadamard (Contrastive x CLIPSeg)\n",
    "        #  \n",
    "        hadamard_vis = cv2.resize(avg_norm_cliped, (w, h), interpolation=cv2.INTER_LINEAR)\n",
    "        im3 = axes[3].imshow(hadamard_vis, cmap='jet', interpolation='bilinear')\n",
    "        axes[3].set_title(\"Hadamard\\n(Contrastive x CLIP)\")\n",
    "        axes[3].axis('off')\n",
    "        plt.colorbar(im3, ax=axes[3], fraction=0.046, pad=0.04)\n",
    "\n",
    "        # (5) Final Blurred Result\n",
    "        im4 = axes[4].imshow(avg_norm_cliped_blur, cmap='jet', interpolation='bilinear')\n",
    "        axes[4].set_title(\"Final Blurred\")\n",
    "        axes[4].axis('off')\n",
    "        plt.colorbar(im4, ax=axes[4], fraction=0.046, pad=0.04)\n",
    "\n",
    "        # (6) Ground Truth\n",
    "        axes[5].imshow(gt_map, cmap='gray') # GT  binary  gray\n",
    "        axes[5].set_title(\"Ground Truth\")\n",
    "        axes[5].axis('off')\n",
    "\n",
    "        #  \n",
    "        save_path = os.path.join(output_dir, f\"{object_name}_{action}_{filename.split('.')[0]}.png\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path, bbox_inches='tight', dpi=150)\n",
    "        plt.close(fig)\n",
    "        print(f\"clipseg_input_text : {clipseg_input_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9eb2cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fc4a36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1f5a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa1fb49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab7b5666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Processing: eat - apple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Layer-wise attention maps for token: 'flesh' (Idx: 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving Layers for 'flesh': 100%|| 64/64 [01:59<00:00,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved all layer maps and DataFrame to: ./output_layerhead_deep/viz_token_1_flesh\n",
      "DataFrame Head :\n",
      "   Layer  Head  Attention_Sum  Layer_Total_Sum\n",
      "0      0     0       0.019457         2.554762\n",
      "1      0     1       0.070488         2.554762\n",
      "2      0     2       0.000568         2.554762\n",
      "3      0     3       0.040754         2.554762\n",
      "4      0     4       0.035283         2.554762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "metrics_tracker_alloutput = MetricsTracker(name=\"all_output\")\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "#   \n",
    "Layername = \"layerhead_deep\"\n",
    "output_dir = f\"./output_{Layername}\"  #    ( )s\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Contrastive Subtraction   (0.5 ~ 1.0 )\n",
    "\n",
    "POS_ALPHA = 0\n",
    "\n",
    "for i in range(1):\n",
    "    i += 1\n",
    "    pkl_path = f\"output_results/attention_result_full_output_32B_{i}.pkl\"\n",
    "    if not os.path.exists(pkl_path):\n",
    "        continue\n",
    "        \n",
    "    df_output = pd.read_pickle(pkl_path)\n",
    "\n",
    "    row = df_output.iloc[1]\n",
    "\n",
    "\n",
    "    object_name = row['object']\n",
    "    action = row['action']\n",
    "    filename = row['filename']\n",
    "    output_description = row['output_sentence']\n",
    "    output_attentions = row['output_attentions']\n",
    "    \n",
    "    file_name_real = f\"{AGD20K_PATH}/Seen/testset/egocentric/{action}/{object_name}/{filename}\"\n",
    "    gt_path = f\"{AGD20K_PATH}/Seen/testset/GT/{action}/{object_name}/{filename.split('.')[0]}.png\"\n",
    "        \n",
    "    #  \n",
    "    if not os.path.exists(file_name_real):\n",
    "        print(f\"Image not found: {file_name_real}\")\n",
    "        continue\n",
    "\n",
    "    orig_img = cv2.imread(file_name_real)\n",
    "    orig_img = cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB)\n",
    "    h, w, _ = orig_img.shape\n",
    "\n",
    "    print(f\"[Processing: {action} - {object_name}\")\n",
    "\n",
    "    # --- 1. CLIPSeg Mask  ---\n",
    "\n",
    "    clip_heatmap = get_clipseg_heatmap(\n",
    "        file_name_real,\n",
    "        clip_model,\n",
    "        clip_processor,\n",
    "        object_name,\n",
    "    )\n",
    "\n",
    "    # CLIPSeg  31x31 \n",
    "    clip_heatmap_resized = cv2.resize(clip_heatmap, (31, 31), interpolation=cv2.INTER_LINEAR)\n",
    "    clip_binary_mask = (clip_heatmap_resized > 0.15).astype(np.float32) #  \n",
    "\n",
    "    # --- 2. [] Contrastive Attention Map  ---\n",
    "    token_scores = []\n",
    "    token_idx = 0\n",
    "    for token in output_attentions:\n",
    "        #   \n",
    "        token_heatmap = np.zeros((31, 31), dtype=np.float32)\n",
    "        token_head_count = 0\n",
    "        \n",
    "        attention_value = token['attentions']\n",
    "        decoded_str = token['token_str'] # \n",
    "\n",
    "        for each_attention in attention_value:\n",
    "            layer = each_attention['layer']\n",
    "            head = each_attention['head']\n",
    "            \n",
    "            # #      ( Layer 0 )\n",
    "            # if each_attention['layer'] != 0:\n",
    "            if 1==1: # (layer <=45) and (layer >= 20): #1==1: # (layer == 26) : #and( head ==20)) : #or ((layer == 24) and( head ==31)):\n",
    "                \n",
    "                token_heatmap += each_attention['heatmap']\n",
    "                token_head_count += 1\n",
    "\n",
    "        \n",
    "        #      \n",
    "        if token_head_count == 0:\n",
    "            continue\n",
    "\n",
    "        # Visual Dependency Score (S_img) :  \n",
    "        s_img = token_heatmap.sum()\n",
    "\n",
    "        #  \n",
    "        token_scores.append({\n",
    "            \"token\": decoded_str,\n",
    "            \"token_idx\" : token_idx,\n",
    "            \"score\": s_img,\n",
    "            \"heatmap\": token_heatmap, \n",
    "            \"count\": token_head_count\n",
    "        })\n",
    "        token_idx +=1\n",
    "    #  :   \n",
    "    if len(token_scores) == 0:\n",
    "        print(\"No valid tokens found.\")\n",
    "        continue\n",
    "\n",
    "    #  (Score  )\n",
    "    sorted_tokens = sorted(token_scores, key=lambda x: x['score'])\n",
    "    \n",
    "    # Top 5 (Signal) & Bottom 5 (Noise) \n",
    "    #   10   \n",
    "    num_select = min(1, len(sorted_tokens) // 2)\n",
    "    if num_select < 1: num_select = 1 #  1\n",
    "\n",
    "    bottom_tokens = sorted_tokens[:num_select]       # Noise (,  )\n",
    "    top_tokens = sorted_tokens[-num_select:][::-1]   # Signal (, )\n",
    "    ##  last \n",
    "\n",
    "\n",
    "    # Signal Map (Positive) \n",
    "    pos_map = np.sum([t['heatmap'] for t in top_tokens], axis=0)\n",
    "    pos_map /= len(top_tokens)\n",
    "    top_token_idx  = top_tokens[-1]['token_idx']\n",
    "    top_token_text  = top_tokens[-1]['token']\n",
    "\n",
    "    # ---  /    ---\n",
    "\n",
    "    # 1.     (Top 1 )\n",
    "    target_token_info = top_tokens[-1] \n",
    "    target_token_str = target_token_info['token'].strip()\n",
    "    target_token_idx = target_token_info['token_idx']\n",
    "\n",
    "\n",
    "    # ... ( : target_token_idx, target_token_str  ) ...\n",
    "    \n",
    "    print(f\"Generating Layer-wise attention maps for token: '{target_token_str}' (Idx: {target_token_idx})\")\n",
    "\n",
    "    # --- []  Layer/Head Attention    ---\n",
    "\n",
    "    # 1.    \n",
    "    #       \n",
    "    safe_token_str = \"\".join([c if c.isalnum() else \"_\" for c in target_token_str])\n",
    "    vis_save_dir = os.path.join(output_dir, f\"viz_token_{target_token_idx}_{safe_token_str}\")\n",
    "    os.makedirs(vis_save_dir, exist_ok=True)\n",
    "\n",
    "    # 2.         \n",
    "    # output_attentions[target_token_idx]     \n",
    "    #  output_attentions     \n",
    "    target_token_data = output_attentions[target_token_idx]\n",
    "    \n",
    "    #  Head  : { layer_idx: [ {head: h, heatmap: map}, ... ] }\n",
    "    layer_wise_attentions = {}\n",
    "    \n",
    "    for attn_item in target_token_data['attentions']:\n",
    "        ly = attn_item['layer']\n",
    "        hd = attn_item['head']\n",
    "        hm = attn_item['heatmap']\n",
    "        \n",
    "        if ly not in layer_wise_attentions:\n",
    "            layer_wise_attentions[ly] = []\n",
    "        layer_wise_attentions[ly].append({'head': hd, 'heatmap': hm})\n",
    "\n",
    " # ... (     ) ...\n",
    "\n",
    "# ... ( : target_token_str ,   ) ...\n",
    "\n",
    "    # [ 1]    \n",
    "    att_data_list = []\n",
    "\n",
    "    # 3.        \n",
    "    sorted_layers = sorted(layer_wise_attentions.keys())\n",
    "    \n",
    "    for ly in tqdm(sorted_layers, desc=f\"Saving Layers for '{target_token_str}'\"):\n",
    "        heads_data = layer_wise_attentions[ly]\n",
    "        \n",
    "        # Head   \n",
    "        heads_data.sort(key=lambda x: x['head'])\n",
    "        \n",
    "        num_heads = len(heads_data)\n",
    "        if num_heads == 0: continue\n",
    "\n",
    "        #    Attention Score  \n",
    "        layer_total_score = sum([h['heatmap'].sum() for h in heads_data])\n",
    "\n",
    "        #   \n",
    "        grid_size = int(np.ceil(np.sqrt(num_heads)))\n",
    "        \n",
    "        #  \n",
    "        fig, axes = plt.subplots(grid_size, grid_size, figsize=(20, 20))\n",
    "        fig.suptitle(\n",
    "            f\"Token: '{target_token_str}' (Idx: {target_token_idx}) - Layer {ly}\\n\"\n",
    "            f\"Layer Total Attention Sum: {layer_total_score:.4f}\", \n",
    "            fontsize=24\n",
    "        )\n",
    "        \n",
    "        if isinstance(axes, np.ndarray):\n",
    "            axes_flat = axes.flatten()\n",
    "        else:\n",
    "            axes_flat = [axes]\n",
    "            \n",
    "        #  Head \n",
    "        for i, ax in enumerate(axes_flat):\n",
    "            if i < num_heads:\n",
    "                head_info = heads_data[i]\n",
    "                h_idx = head_info['head']\n",
    "                h_map = head_info['heatmap']\n",
    "                \n",
    "                #  Head Score \n",
    "                head_score = h_map.sum()\n",
    "                \n",
    "                # [ 2]    (Layer, Head, Attention Sum)\n",
    "                att_data_list.append({\n",
    "                    'Layer': ly,\n",
    "                    'Head': h_idx,\n",
    "                    'Attention_Sum': head_score,\n",
    "                    'Layer_Total_Sum': layer_total_score  #      \n",
    "                })\n",
    "\n",
    "                # \n",
    "                im = ax.imshow(h_map, cmap='viridis', interpolation='nearest')\n",
    "                ax.set_title(f\"Head {h_idx}\\nSum: {head_score:.2f}\", fontsize=10)\n",
    "                ax.axis('off')\n",
    "            else:\n",
    "                ax.axis('off')\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.93])\n",
    "        save_path = os.path.join(vis_save_dir, f\"layer_{ly:03d}.png\")\n",
    "        plt.savefig(save_path)\n",
    "        plt.close(fig) \n",
    "\n",
    "    # [ 3] DataFrame   \n",
    "    df_att = pd.DataFrame(att_data_list)\n",
    "    \n",
    "    #      (Layer -> Head -> Sum)\n",
    "    df_att = df_att[['Layer', 'Head', 'Attention_Sum', 'Layer_Total_Sum']]\n",
    "    \n",
    "    # CSV  \n",
    "    csv_path = os.path.join(vis_save_dir, \"attention_sums.csv\")\n",
    "    df_att.to_csv(csv_path, index=False)\n",
    "\n",
    "    print(f\"Saved all layer maps and DataFrame to: {vis_save_dir}\")\n",
    "    print(\"DataFrame Head :\")\n",
    "    print(df_att.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22c37288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Layer\n",
       "20    0.376303\n",
       "23    0.566991\n",
       "1     0.760726\n",
       "10    0.854804\n",
       "9     0.889243\n",
       "        ...   \n",
       "50    8.005047\n",
       "45    8.019423\n",
       "17    8.284877\n",
       "46    8.924697\n",
       "41    9.288528\n",
       "Name: Attention_Sum, Length: 64, dtype: float32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_att.groupby(['Layer'])['Attention_Sum'].sum().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "767dc381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer</th>\n",
       "      <th>Head</th>\n",
       "      <th>Attention_Sum</th>\n",
       "      <th>Layer_Total_Sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>1.028297e-08</td>\n",
       "      <td>0.376303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>20</td>\n",
       "      <td>58</td>\n",
       "      <td>1.797992e-07</td>\n",
       "      <td>0.376303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>2.148592e-07</td>\n",
       "      <td>0.376303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>20</td>\n",
       "      <td>27</td>\n",
       "      <td>2.576361e-07</td>\n",
       "      <td>0.376303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>3.766697e-07</td>\n",
       "      <td>0.376303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>20</td>\n",
       "      <td>53</td>\n",
       "      <td>2.764578e-02</td>\n",
       "      <td>0.376303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>20</td>\n",
       "      <td>31</td>\n",
       "      <td>3.363384e-02</td>\n",
       "      <td>0.376303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>20</td>\n",
       "      <td>62</td>\n",
       "      <td>3.683291e-02</td>\n",
       "      <td>0.376303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1325</th>\n",
       "      <td>20</td>\n",
       "      <td>45</td>\n",
       "      <td>4.368176e-02</td>\n",
       "      <td>0.376303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322</th>\n",
       "      <td>20</td>\n",
       "      <td>42</td>\n",
       "      <td>5.164818e-02</td>\n",
       "      <td>0.376303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Layer  Head  Attention_Sum  Layer_Total_Sum\n",
       "1302     20    22   1.028297e-08         0.376303\n",
       "1338     20    58   1.797992e-07         0.376303\n",
       "1304     20    24   2.148592e-07         0.376303\n",
       "1307     20    27   2.576361e-07         0.376303\n",
       "1291     20    11   3.766697e-07         0.376303\n",
       "...     ...   ...            ...              ...\n",
       "1333     20    53   2.764578e-02         0.376303\n",
       "1311     20    31   3.363384e-02         0.376303\n",
       "1342     20    62   3.683291e-02         0.376303\n",
       "1325     20    45   4.368176e-02         0.376303\n",
       "1322     20    42   5.164818e-02         0.376303\n",
       "\n",
       "[64 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_att[df_att['Layer']==20].sort_values(\"Attention_Sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bace41e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer</th>\n",
       "      <th>Head</th>\n",
       "      <th>Attention_Sum</th>\n",
       "      <th>Layer_Total_Sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019457</td>\n",
       "      <td>2.554762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.070488</td>\n",
       "      <td>2.554762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>2.554762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.040754</td>\n",
       "      <td>2.554762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.035283</td>\n",
       "      <td>2.554762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4091</th>\n",
       "      <td>63</td>\n",
       "      <td>59</td>\n",
       "      <td>0.052509</td>\n",
       "      <td>2.854838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4092</th>\n",
       "      <td>63</td>\n",
       "      <td>60</td>\n",
       "      <td>0.032250</td>\n",
       "      <td>2.854838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4093</th>\n",
       "      <td>63</td>\n",
       "      <td>61</td>\n",
       "      <td>0.033217</td>\n",
       "      <td>2.854838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4094</th>\n",
       "      <td>63</td>\n",
       "      <td>62</td>\n",
       "      <td>0.092705</td>\n",
       "      <td>2.854838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4095</th>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>0.363023</td>\n",
       "      <td>2.854838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4096 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Layer  Head  Attention_Sum  Layer_Total_Sum\n",
       "0         0     0       0.019457         2.554762\n",
       "1         0     1       0.070488         2.554762\n",
       "2         0     2       0.000568         2.554762\n",
       "3         0     3       0.040754         2.554762\n",
       "4         0     4       0.035283         2.554762\n",
       "...     ...   ...            ...              ...\n",
       "4091     63    59       0.052509         2.854838\n",
       "4092     63    60       0.032250         2.854838\n",
       "4093     63    61       0.033217         2.854838\n",
       "4094     63    62       0.092705         2.854838\n",
       "4095     63    63       0.363023         2.854838\n",
       "\n",
       "[4096 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_att"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
