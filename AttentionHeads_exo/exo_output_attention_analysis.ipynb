{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b351283e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/DATA/AGD20K'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from transformers import CLIPSegProcessor, CLIPSegForImageSegmentation\n",
    "\n",
    "clip_processor = CLIPSegProcessor.from_pretrained(\"CIDAS/clipseg-rd64-refined\")\n",
    "clip_model = CLIPSegForImageSegmentation.from_pretrained(\"CIDAS/clipseg-rd64-refined\")\n",
    "\n",
    "import os\n",
    "import sys\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(parent_dir)\n",
    "from config import AGD20K_PATH, model_name\n",
    "\n",
    "from VLM_model_dot_relative import MetricsTracker\n",
    "from file_managing import (\n",
    "    load_selected_samples,\n",
    "    get_actual_path,\n",
    "    get_gt_path,\n",
    "    load_ground_truth,\n",
    "    prompt_dict_obj,\n",
    "    get_clipseg_heatmap,\n",
    "    calculate_metrics,\n",
    "    prompt_dict_obj\n",
    ")\n",
    "\n",
    "def min_max_normalize(arr):\n",
    "    denom = arr.max() - arr.min()\n",
    "    if denom == 0:\n",
    "        return np.zeros_like(arr)\n",
    "    return (arr - arr.min()) / (denom + 1e-8)\n",
    "\n",
    "\n",
    "\n",
    "from transformers import Qwen3VLForConditionalGeneration, AutoProcessor\n",
    "model_name= f\"Qwen/Qwen3-VL-32B-Instruct\"\n",
    "processor = AutoProcessor.from_pretrained(model_name)\n",
    "tok = processor.tokenizer\n",
    "\n",
    "AGD20K_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75cd8797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def check_heatmap_containment(heatmap_top, heatmap_obj, threshold=0.15, containment_ratio=0.8):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        containment_ratio (float): Top 영역의 몇 % 이상이 Obj와 겹쳐야 포함으로 볼 것인지 (기본 0.9 = 90%)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. 텐서인 경우 numpy 변환\n",
    "    if hasattr(heatmap_top, 'cpu'):\n",
    "        heatmap_top = heatmap_top.detach().cpu().numpy()\n",
    "    if hasattr(heatmap_obj, 'cpu'):\n",
    "        heatmap_obj = heatmap_obj.detach().cpu().numpy()\n",
    "\n",
    "    # 2. 이진 마스크 생성\n",
    "    mask_top = heatmap_top > threshold\n",
    "    mask_obj = heatmap_obj > threshold\n",
    "\n",
    "    # 3. 면적 계산\n",
    "    area_top = np.sum(mask_top)\n",
    "    area_obj = np.sum(mask_obj)\n",
    "\n",
    "    # 예외 처리: Top 히트맵이 아예 활성화되지 않은 경우 (면적 0)\n",
    "    if area_top == 0:\n",
    "        return False\n",
    "\n",
    "    # 조건 1: Top의 면적이 Object 면적보다 작은가?\n",
    "    is_smaller = area_top < area_obj\n",
    "    \n",
    "    # 4. 포함 관계 확인 (수정된 부분)\n",
    "    # 교집합(Intersection) 영역 계산\n",
    "    intersection = np.logical_and(mask_top, mask_obj)\n",
    "    intersection_area = np.sum(intersection)\n",
    "\n",
    "    # [수정됨] 교집합 면적이 Top 전체 면적의 90% 이상인지 확인\n",
    "    # (intersection_area / area_top) >= 0.9 와 동일한 수식입니다.\n",
    "    is_inside = intersection_area >= (area_top * containment_ratio)\n",
    "\n",
    "    # 디버깅용: 실제 겹치는 비율 확인\n",
    "    # print(f\"Overlap Ratio: {intersection_area / area_top:.2f}\")\n",
    "\n",
    "    return is_smaller and is_inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab1cad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Processing: cut - apple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input : apple\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output apple_000054.jpg:\n",
      " all_output Current - KLD: 0.6868 | SIM: 0.6305 | NSS: 0.7139\n",
      "\n",
      "Cumulative all_output  Averages over 1 samples:\n",
      "Average - KLD: 0.6868 | SIM: 0.6305 | NSS: 0.7139\n",
      "==================================================\n",
      "\n",
      "[1] Processing: eat - apple\n",
      "Selected CLIP input :  the\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output apple_001541.jpg:\n",
      " all_output Current - KLD: 0.0485 | SIM: 0.8789 | NSS: 1.2721\n",
      "\n",
      "Cumulative all_output  Averages over 2 samples:\n",
      "Average - KLD: 0.3676 | SIM: 0.7547 | NSS: 0.9930\n",
      "==================================================\n",
      "\n",
      "[2] Processing: peel - apple\n",
      "Selected CLIP input : apple\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output apple_001541.jpg:\n",
      " all_output Current - KLD: 0.1676 | SIM: 0.7868 | NSS: 1.3753\n",
      "\n",
      "Cumulative all_output  Averages over 3 samples:\n",
      "Average - KLD: 0.3010 | SIM: 0.7654 | NSS: 1.1204\n",
      "==================================================\n",
      "\n",
      "[3] Processing: hit - axe\n",
      "Selected CLIP input :  curved\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output axe_000961.jpg:\n",
      " all_output Current - KLD: 2.6712 | SIM: 0.1018 | NSS: -0.2334\n",
      "\n",
      "Cumulative all_output  Averages over 4 samples:\n",
      "Average - KLD: 0.8935 | SIM: 0.5995 | NSS: 0.7820\n",
      "==================================================\n",
      "\n",
      "[4] Processing: hold - axe\n",
      "Selected CLIP input :  red\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output axe_001552.jpg:\n",
      " all_output Current - KLD: 0.2080 | SIM: 0.7505 | NSS: 2.5648\n",
      "\n",
      "Cumulative all_output  Averages over 5 samples:\n",
      "Average - KLD: 0.7564 | SIM: 0.6297 | NSS: 1.1385\n",
      "==================================================\n",
      "\n",
      "[5] Processing: hold - badminton_racket\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input :  handle\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output badminton_racket_002255.jpg:\n",
      " all_output Current - KLD: 0.8326 | SIM: 0.4569 | NSS: 2.2282\n",
      "\n",
      "Cumulative all_output  Averages over 6 samples:\n",
      "Average - KLD: 0.7691 | SIM: 0.6009 | NSS: 1.3202\n",
      "==================================================\n",
      "\n",
      "[6] Processing: swing - badminton_racket\n",
      "Selected CLIP input : badminton_racket\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output badminton_racket_003649.jpg:\n",
      " all_output Current - KLD: 3.4653 | SIM: 0.0437 | NSS: -0.3587\n",
      "\n",
      "Cumulative all_output  Averages over 7 samples:\n",
      "Average - KLD: 1.1543 | SIM: 0.5213 | NSS: 1.0803\n",
      "==================================================\n",
      "\n",
      "[7] Processing: cut - banana\n",
      "Selected CLIP input : banana\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output banana_002623.jpg:\n",
      " all_output Current - KLD: 0.1011 | SIM: 0.8332 | NSS: 1.4134\n",
      "\n",
      "Cumulative all_output  Averages over 8 samples:\n",
      "Average - KLD: 1.0226 | SIM: 0.5603 | NSS: 1.1220\n",
      "==================================================\n",
      "\n",
      "[8] Processing: eat - banana\n",
      "Selected CLIP input : banana\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output banana_002458.jpg:\n",
      " all_output Current - KLD: 0.3266 | SIM: 0.6819 | NSS: 1.6803\n",
      "\n",
      "Cumulative all_output  Averages over 9 samples:\n",
      "Average - KLD: 0.9453 | SIM: 0.5738 | NSS: 1.1840\n",
      "==================================================\n",
      "\n",
      "[9] Processing: peel - banana\n",
      "Selected CLIP input :  yellow\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output banana_000480.jpg:\n",
      " all_output Current - KLD: 1.4166 | SIM: 0.3103 | NSS: 0.9061\n",
      "\n",
      "Cumulative all_output  Averages over 10 samples:\n",
      "Average - KLD: 0.9924 | SIM: 0.5474 | NSS: 1.1562\n",
      "==================================================\n",
      "\n",
      "[10] Processing: throw - baseball\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input : baseball\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output baseball_002670.jpg:\n",
      " all_output Current - KLD: 0.1526 | SIM: 0.8481 | NSS: 3.3807\n",
      "\n",
      "Cumulative all_output  Averages over 11 samples:\n",
      "Average - KLD: 0.9161 | SIM: 0.5748 | NSS: 1.3584\n",
      "==================================================\n",
      "\n",
      "[11] Processing: hit - baseball_bat\n",
      "Selected CLIP input : baseball_bat\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output baseball_bat_001882.jpg:\n",
      " all_output Current - KLD: 2.2722 | SIM: 0.1382 | NSS: 0.1849\n",
      "\n",
      "Cumulative all_output  Averages over 12 samples:\n",
      "Average - KLD: 1.0291 | SIM: 0.5384 | NSS: 1.2606\n",
      "==================================================\n",
      "\n",
      "[12] Processing: hold - baseball_bat\n",
      "Selected CLIP input : baseball_bat\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output baseball_bat_002547.jpg:\n",
      " all_output Current - KLD: 2.4875 | SIM: 0.1159 | NSS: 0.5922\n",
      "\n",
      "Cumulative all_output  Averages over 13 samples:\n",
      "Average - KLD: 1.1413 | SIM: 0.5059 | NSS: 1.2092\n",
      "==================================================\n",
      "\n",
      "[13] Processing: swing - baseball_bat\n",
      "Selected CLIP input : baseball_bat\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output baseball_bat_001882.jpg:\n",
      " all_output Current - KLD: 2.2096 | SIM: 0.1461 | NSS: 0.2499\n",
      "\n",
      "Cumulative all_output  Averages over 14 samples:\n",
      "Average - KLD: 1.2176 | SIM: 0.4802 | NSS: 1.1407\n",
      "==================================================\n",
      "\n",
      "[14] Processing: throw - basketball\n",
      "Selected CLIP input : basketball\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output basketball_003534.jpg:\n",
      " all_output Current - KLD: 1.1168 | SIM: 0.3782 | NSS: 2.4859\n",
      "\n",
      "Cumulative all_output  Averages over 15 samples:\n",
      "Average - KLD: 1.2109 | SIM: 0.4734 | NSS: 1.2304\n",
      "==================================================\n",
      "\n",
      "[15] Processing: lie_on - bed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input :  gray\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output bed_002880.jpg:\n",
      " all_output Current - KLD: 0.2175 | SIM: 0.7502 | NSS: 2.9233\n",
      "\n",
      "Cumulative all_output  Averages over 16 samples:\n",
      "Average - KLD: 1.1488 | SIM: 0.4907 | NSS: 1.3362\n",
      "==================================================\n",
      "\n",
      "[16] Processing: sit_on - bed\n",
      "Selected CLIP input :  blue\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output bed_003622.jpg:\n",
      " all_output Current - KLD: 0.5706 | SIM: 0.5783 | NSS: 1.6768\n",
      "\n",
      "Cumulative all_output  Averages over 17 samples:\n",
      "Average - KLD: 1.1148 | SIM: 0.4958 | NSS: 1.3562\n",
      "==================================================\n",
      "\n",
      "[17] Processing: lie_on - bench\n",
      "Selected CLIP input :  by\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output bench_003727.jpg:\n",
      " all_output Current - KLD: 1.3515 | SIM: 0.3781 | NSS: 0.7633\n",
      "\n",
      "Cumulative all_output  Averages over 18 samples:\n",
      "Average - KLD: 1.1279 | SIM: 0.4893 | NSS: 1.3233\n",
      "==================================================\n",
      "\n",
      "[18] Processing: sit_on - bench\n",
      "Selected CLIP input : bench\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output bench_001877.jpg:\n",
      " all_output Current - KLD: 0.1507 | SIM: 0.7902 | NSS: 1.8560\n",
      "\n",
      "Cumulative all_output  Averages over 19 samples:\n",
      "Average - KLD: 1.0765 | SIM: 0.5051 | NSS: 1.3513\n",
      "==================================================\n",
      "\n",
      "[19] Processing: push - bicycle\n",
      "Selected CLIP input :  a\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output bicycle_002432.jpg:\n",
      " all_output Current - KLD: 2.7850 | SIM: 0.1030 | NSS: -0.0340\n",
      "\n",
      "Cumulative all_output  Averages over 20 samples:\n",
      "Average - KLD: 1.1619 | SIM: 0.4850 | NSS: 1.2820\n",
      "==================================================\n",
      "\n",
      "[20] Processing: ride - bicycle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input :  seat\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output bicycle_003046.jpg:\n",
      " all_output Current - KLD: 0.9201 | SIM: 0.4791 | NSS: 1.5760\n",
      "\n",
      "Cumulative all_output  Averages over 21 samples:\n",
      "Average - KLD: 1.1504 | SIM: 0.4847 | NSS: 1.2960\n",
      "==================================================\n",
      "\n",
      "[21] Processing: sit_on - bicycle\n",
      "Selected CLIP input :  the\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output bicycle_002100.jpg:\n",
      " all_output Current - KLD: 1.4445 | SIM: 0.2989 | NSS: 2.3524\n",
      "\n",
      "Cumulative all_output  Averages over 22 samples:\n",
      "Average - KLD: 1.1638 | SIM: 0.4763 | NSS: 1.3441\n",
      "==================================================\n",
      "\n",
      "[22] Processing: look_out - binoculars\n",
      "Selected CLIP input : binoculars\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output binoculars_003630.jpg:\n",
      " all_output Current - KLD: 1.0479 | SIM: 0.3935 | NSS: 0.5802\n",
      "\n",
      "Cumulative all_output  Averages over 23 samples:\n",
      "Average - KLD: 1.1587 | SIM: 0.4727 | NSS: 1.3108\n",
      "==================================================\n",
      "\n",
      "[23] Processing: hold - book\n",
      "Selected CLIP input : book\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output book_001195.jpg:\n",
      " all_output Current - KLD: 0.7563 | SIM: 0.5065 | NSS: 1.1489\n",
      "\n",
      "Cumulative all_output  Averages over 24 samples:\n",
      "Average - KLD: 1.1420 | SIM: 0.4741 | NSS: 1.3041\n",
      "==================================================\n",
      "\n",
      "[24] Processing: open - book\n",
      "Selected CLIP input : book\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output book_003044.jpg:\n",
      " all_output Current - KLD: 0.7295 | SIM: 0.5037 | NSS: 2.2898\n",
      "\n",
      "Cumulative all_output  Averages over 25 samples:\n",
      "Average - KLD: 1.1255 | SIM: 0.4753 | NSS: 1.3435\n",
      "==================================================\n",
      "\n",
      "[25] Processing: drink_with - bottle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input :  the\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output bottle_003259.jpg:\n",
      " all_output Current - KLD: 1.7136 | SIM: 0.2093 | NSS: 1.6973\n",
      "\n",
      "Cumulative all_output  Averages over 26 samples:\n",
      "Average - KLD: 1.1481 | SIM: 0.4651 | NSS: 1.3571\n",
      "==================================================\n",
      "\n",
      "[26] Processing: hold - bottle\n",
      "Selected CLIP input : bottle\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output bottle_001227.jpg:\n",
      " all_output Current - KLD: 0.6119 | SIM: 0.5410 | NSS: 1.9510\n",
      "\n",
      "Cumulative all_output  Averages over 27 samples:\n",
      "Average - KLD: 1.1282 | SIM: 0.4679 | NSS: 1.3791\n",
      "==================================================\n",
      "\n",
      "[27] Processing: open - bottle\n",
      "Selected CLIP input :  green\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output bottle_001033.jpg:\n",
      " all_output Current - KLD: 0.4656 | SIM: 0.6252 | NSS: 3.7235\n",
      "\n",
      "Cumulative all_output  Averages over 28 samples:\n",
      "Average - KLD: 1.1046 | SIM: 0.4735 | NSS: 1.4629\n",
      "==================================================\n",
      "\n",
      "[28] Processing: pour - bottle\n",
      "Selected CLIP input :  pink\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output bottle_002780.jpg:\n",
      " all_output Current - KLD: 4.2887 | SIM: 0.0571 | NSS: -0.2626\n",
      "\n",
      "Cumulative all_output  Averages over 29 samples:\n",
      "Average - KLD: 1.2144 | SIM: 0.4591 | NSS: 1.4034\n",
      "==================================================\n",
      "\n",
      "[29] Processing: hold - bowl\n",
      "Selected CLIP input :  outer\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output bowl_000546.jpg:\n",
      " all_output Current - KLD: 0.2319 | SIM: 0.7436 | NSS: 0.8918\n",
      "\n",
      "Cumulative all_output  Averages over 30 samples:\n",
      "Average - KLD: 1.1816 | SIM: 0.4686 | NSS: 1.3863\n",
      "==================================================\n",
      "\n",
      "[30] Processing: stir - bowl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input :  creamy\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output bowl_000134.jpg:\n",
      " all_output Current - KLD: 1.0495 | SIM: 0.4813 | NSS: 0.8977\n",
      "\n",
      "Cumulative all_output  Averages over 31 samples:\n",
      "Average - KLD: 1.1773 | SIM: 0.4690 | NSS: 1.3705\n",
      "==================================================\n",
      "\n",
      "[31] Processing: wash - bowl\n",
      "Selected CLIP input : bowl\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output bowl_002825.jpg:\n",
      " all_output Current - KLD: 0.7662 | SIM: 0.5081 | NSS: 0.4828\n",
      "\n",
      "Cumulative all_output  Averages over 32 samples:\n",
      "Average - KLD: 1.1645 | SIM: 0.4702 | NSS: 1.3428\n",
      "==================================================\n",
      "\n",
      "[32] Processing: eat - broccoli\n",
      "Selected CLIP input : broccoli\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output broccoli_002796.jpg:\n",
      " all_output Current - KLD: 0.1378 | SIM: 0.8218 | NSS: 1.6541\n",
      "\n",
      "Cumulative all_output  Averages over 33 samples:\n",
      "Average - KLD: 1.1334 | SIM: 0.4809 | NSS: 1.3522\n",
      "==================================================\n",
      "\n",
      "[33] Processing: take_photo - camera\n",
      "Selected CLIP input :  the\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output camera_002534.jpg:\n",
      " all_output Current - KLD: 0.7341 | SIM: 0.5042 | NSS: 0.3773\n",
      "\n",
      "Cumulative all_output  Averages over 34 samples:\n",
      "Average - KLD: 1.1216 | SIM: 0.4816 | NSS: 1.3236\n",
      "==================================================\n",
      "\n",
      "[34] Processing: cut - carrot\n",
      "Selected CLIP input : carrot\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output carrot_001443.jpg:\n",
      " all_output Current - KLD: 0.9340 | SIM: 0.4485 | NSS: 2.7737\n",
      "\n",
      "Cumulative all_output  Averages over 35 samples:\n",
      "Average - KLD: 1.1163 | SIM: 0.4806 | NSS: 1.3650\n",
      "==================================================\n",
      "\n",
      "[35] Processing: eat - carrot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input : carrot\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output carrot_001443.jpg:\n",
      " all_output Current - KLD: 0.7906 | SIM: 0.4916 | NSS: 2.8625\n",
      "\n",
      "Cumulative all_output  Averages over 36 samples:\n",
      "Average - KLD: 1.1072 | SIM: 0.4809 | NSS: 1.4066\n",
      "==================================================\n",
      "\n",
      "[36] Processing: peel - carrot\n",
      "Selected CLIP input : carrot\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output carrot_003707.jpg:\n",
      " all_output Current - KLD: 0.5758 | SIM: 0.5534 | NSS: 2.0183\n",
      "\n",
      "Cumulative all_output  Averages over 37 samples:\n",
      "Average - KLD: 1.0929 | SIM: 0.4829 | NSS: 1.4231\n",
      "==================================================\n",
      "\n",
      "[37] Processing: take_photo - cell_phone\n",
      "Selected CLIP input :  the\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output cell_phone_000601.jpg:\n",
      " all_output Current - KLD: 0.3870 | SIM: 0.6479 | NSS: 1.5962\n",
      "\n",
      "Cumulative all_output  Averages over 38 samples:\n",
      "Average - KLD: 1.0743 | SIM: 0.4872 | NSS: 1.4277\n",
      "==================================================\n",
      "\n",
      "[38] Processing: talk_on - cell_phone\n",
      "Selected CLIP input : cell_phone\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output cell_phone_000601.jpg:\n",
      " all_output Current - KLD: 0.6337 | SIM: 0.5337 | NSS: 1.5027\n",
      "\n",
      "Cumulative all_output  Averages over 39 samples:\n",
      "Average - KLD: 1.0630 | SIM: 0.4884 | NSS: 1.4296\n",
      "==================================================\n",
      "\n",
      "[39] Processing: text_on - cell_phone\n",
      "Selected CLIP input :  the\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output cell_phone_003361.jpg:\n",
      " all_output Current - KLD: 0.9235 | SIM: 0.4341 | NSS: 1.3386\n",
      "\n",
      "Cumulative all_output  Averages over 40 samples:\n",
      "Average - KLD: 1.0595 | SIM: 0.4871 | NSS: 1.4273\n",
      "==================================================\n",
      "\n",
      "[40] Processing: sit_on - chair\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input :  blue\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output chair_002839.jpg:\n",
      " all_output Current - KLD: 1.0213 | SIM: 0.3803 | NSS: 0.6478\n",
      "\n",
      "Cumulative all_output  Averages over 41 samples:\n",
      "Average - KLD: 1.0586 | SIM: 0.4845 | NSS: 1.4083\n",
      "==================================================\n",
      "\n",
      "[41] Processing: lie_on - couch\n",
      "Selected CLIP input : couch\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output couch_003293.jpg:\n",
      " all_output Current - KLD: 0.8194 | SIM: 0.4649 | NSS: 1.4543\n",
      "\n",
      "Cumulative all_output  Averages over 42 samples:\n",
      "Average - KLD: 1.0529 | SIM: 0.4840 | NSS: 1.4094\n",
      "==================================================\n",
      "\n",
      "[42] Processing: sit_on - couch\n",
      "Selected CLIP input :  three\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output couch_000779.jpg:\n",
      " all_output Current - KLD: 0.8506 | SIM: 0.4467 | NSS: 1.5929\n",
      "\n",
      "Cumulative all_output  Averages over 43 samples:\n",
      "Average - KLD: 1.0482 | SIM: 0.4831 | NSS: 1.4137\n",
      "==================================================\n",
      "\n",
      "[43] Processing: drink_with - cup\n",
      "Selected CLIP input : cup\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output cup_000508.jpg:\n",
      " all_output Current - KLD: 0.5905 | SIM: 0.5385 | NSS: 2.5362\n",
      "\n",
      "Cumulative all_output  Averages over 44 samples:\n",
      "Average - KLD: 1.0378 | SIM: 0.4844 | NSS: 1.4392\n",
      "==================================================\n",
      "\n",
      "[44] Processing: hold - cup\n",
      "Selected CLIP input : cup\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output cup_002518.jpg:\n",
      " all_output Current - KLD: 1.2588 | SIM: 0.3371 | NSS: 1.8269\n",
      "\n",
      "Cumulative all_output  Averages over 45 samples:\n",
      "Average - KLD: 1.0427 | SIM: 0.4811 | NSS: 1.4478\n",
      "==================================================\n",
      "\n",
      "[45] Processing: pour - cup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input : cup\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output cup_001535.jpg:\n",
      " all_output Current - KLD: 1.6752 | SIM: 0.2794 | NSS: 1.3684\n",
      "\n",
      "Cumulative all_output  Averages over 46 samples:\n",
      "Average - KLD: 1.0564 | SIM: 0.4767 | NSS: 1.4461\n",
      "==================================================\n",
      "\n",
      "[46] Processing: sip - cup\n",
      "Selected CLIP input :  the\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output cup_001864.jpg:\n",
      " all_output Current - KLD: 0.3649 | SIM: 0.6663 | NSS: 1.0845\n",
      "\n",
      "Cumulative all_output  Averages over 47 samples:\n",
      "Average - KLD: 1.0417 | SIM: 0.4808 | NSS: 1.4384\n",
      "==================================================\n",
      "\n",
      "[47] Processing: wash - cup\n",
      "Selected CLIP input :  decorated\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output cup_003621.jpg:\n",
      " all_output Current - KLD: 2.7428 | SIM: 0.1157 | NSS: -0.1340\n",
      "\n",
      "Cumulative all_output  Averages over 48 samples:\n",
      "Average - KLD: 1.0772 | SIM: 0.4732 | NSS: 1.4056\n",
      "==================================================\n",
      "\n",
      "[48] Processing: throw - discus\n",
      "Selected CLIP input :  metallic\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output discus_003558.jpg:\n",
      " all_output Current - KLD: 0.5172 | SIM: 0.5922 | NSS: 0.6706\n",
      "\n",
      "Cumulative all_output  Averages over 49 samples:\n",
      "Average - KLD: 1.0657 | SIM: 0.4756 | NSS: 1.3906\n",
      "==================================================\n",
      "\n",
      "[49] Processing: beat - drum\n",
      "Selected CLIP input : drum\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output drum_002586.jpg:\n",
      " all_output Current - KLD: 0.7839 | SIM: 0.4828 | NSS: 0.6134\n",
      "\n",
      "Cumulative all_output  Averages over 50 samples:\n",
      "Average - KLD: 1.0601 | SIM: 0.4757 | NSS: 1.3751\n",
      "==================================================\n",
      "\n",
      "[50] Processing: hold - fork\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input :  handle\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output fork_000804.jpg:\n",
      " all_output Current - KLD: 0.7146 | SIM: 0.5054 | NSS: 1.9396\n",
      "\n",
      "Cumulative all_output  Averages over 51 samples:\n",
      "Average - KLD: 1.0533 | SIM: 0.4763 | NSS: 1.3862\n",
      "==================================================\n",
      "\n",
      "[51] Processing: lift - fork\n",
      "Selected CLIP input : fork\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output fork_001691.jpg:\n",
      " all_output Current - KLD: 1.6293 | SIM: 0.2320 | NSS: 0.1815\n",
      "\n",
      "Cumulative all_output  Averages over 52 samples:\n",
      "Average - KLD: 1.0644 | SIM: 0.4716 | NSS: 1.3630\n",
      "==================================================\n",
      "\n",
      "[52] Processing: stick - fork\n",
      "Selected CLIP input : fork\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output fork_000095.jpg:\n",
      " all_output Current - KLD: 0.6982 | SIM: 0.5058 | NSS: 2.0132\n",
      "\n",
      "Cumulative all_output  Averages over 53 samples:\n",
      "Average - KLD: 1.0575 | SIM: 0.4723 | NSS: 1.3753\n",
      "==================================================\n",
      "\n",
      "[53] Processing: wash - fork\n",
      "Selected CLIP input :  the\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output fork_001691.jpg:\n",
      " all_output Current - KLD: 0.9591 | SIM: 0.4053 | NSS: 2.1540\n",
      "\n",
      "Cumulative all_output  Averages over 54 samples:\n",
      "Average - KLD: 1.0557 | SIM: 0.4710 | NSS: 1.3897\n",
      "==================================================\n",
      "\n",
      "[54] Processing: catch - frisbee\n",
      "Selected CLIP input :  flat\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output frisbee_000598.jpg:\n",
      " all_output Current - KLD: 0.8140 | SIM: 0.4706 | NSS: -0.0861\n",
      "\n",
      "Cumulative all_output  Averages over 55 samples:\n",
      "Average - KLD: 1.0513 | SIM: 0.4710 | NSS: 1.3628\n",
      "==================================================\n",
      "\n",
      "[55] Processing: hold - frisbee\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input :  star\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output frisbee_001130.jpg:\n",
      " all_output Current - KLD: 2.0018 | SIM: 0.2101 | NSS: -0.5185\n",
      "\n",
      "Cumulative all_output  Averages over 56 samples:\n",
      "Average - KLD: 1.0682 | SIM: 0.4664 | NSS: 1.3292\n",
      "==================================================\n",
      "\n",
      "[56] Processing: throw - frisbee\n",
      "Selected CLIP input :  solid\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output frisbee_003249.jpg:\n",
      " all_output Current - KLD: 0.7029 | SIM: 0.5099 | NSS: 0.3768\n",
      "\n",
      "Cumulative all_output  Averages over 57 samples:\n",
      "Average - KLD: 1.0618 | SIM: 0.4671 | NSS: 1.3125\n",
      "==================================================\n",
      "\n",
      "[57] Processing: hold - golf_clubs\n",
      "Selected CLIP input :  black\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output golf_clubs_000045.jpg:\n",
      " all_output Current - KLD: 0.7653 | SIM: 0.5367 | NSS: 1.6625\n",
      "\n",
      "Cumulative all_output  Averages over 58 samples:\n",
      "Average - KLD: 1.0567 | SIM: 0.4683 | NSS: 1.3186\n",
      "==================================================\n",
      "\n",
      "[58] Processing: swing - golf_clubs\n",
      "Selected CLIP input : golf_clubs\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output golf_clubs_001992.jpg:\n",
      " all_output Current - KLD: 2.1338 | SIM: 0.1562 | NSS: 0.6689\n",
      "\n",
      "Cumulative all_output  Averages over 59 samples:\n",
      "Average - KLD: 1.0750 | SIM: 0.4630 | NSS: 1.3076\n",
      "==================================================\n",
      "\n",
      "[59] Processing: hit - hammer\n",
      "Selected CLIP input : hammer\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output hammer_001006.jpg:\n",
      " all_output Current - KLD: 1.8774 | SIM: 0.1937 | NSS: 0.2779\n",
      "\n",
      "Cumulative all_output  Averages over 60 samples:\n",
      "Average - KLD: 1.0884 | SIM: 0.4585 | NSS: 1.2904\n",
      "==================================================\n",
      "\n",
      "[60] Processing: hold - hammer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input :  handle\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output hammer_000215.jpg:\n",
      " all_output Current - KLD: 0.9788 | SIM: 0.3882 | NSS: 2.5001\n",
      "\n",
      "Cumulative all_output  Averages over 61 samples:\n",
      "Average - KLD: 1.0866 | SIM: 0.4574 | NSS: 1.3102\n",
      "==================================================\n",
      "\n",
      "[61] Processing: eat - hot_dog\n",
      "Selected CLIP input : hot_dog\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output hot_dog_002166.jpg:\n",
      " all_output Current - KLD: 0.1889 | SIM: 0.7694 | NSS: 1.1958\n",
      "\n",
      "Cumulative all_output  Averages over 62 samples:\n",
      "Average - KLD: 1.0721 | SIM: 0.4624 | NSS: 1.3084\n",
      "==================================================\n",
      "\n",
      "[62] Processing: throw - javelin\n",
      "Selected CLIP input :  yellow\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output javelin_001474.jpg:\n",
      " all_output Current - KLD: 0.1957 | SIM: 0.8225 | NSS: 3.6327\n",
      "\n",
      "Cumulative all_output  Averages over 63 samples:\n",
      "Average - KLD: 1.0582 | SIM: 0.4681 | NSS: 1.3453\n",
      "==================================================\n",
      "\n",
      "[63] Processing: type_on - keyboard\n",
      "Selected CLIP input : keyboard\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output keyboard_000439.jpg:\n",
      " all_output Current - KLD: 0.2796 | SIM: 0.7237 | NSS: 1.3746\n",
      "\n",
      "Cumulative all_output  Averages over 64 samples:\n",
      "Average - KLD: 1.0460 | SIM: 0.4721 | NSS: 1.3457\n",
      "==================================================\n",
      "\n",
      "[64] Processing: cut_with - knife\n",
      "Selected CLIP input : knife\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output knife_001749.jpg:\n",
      " all_output Current - KLD: 0.3065 | SIM: 0.7296 | NSS: 2.4062\n",
      "\n",
      "Cumulative all_output  Averages over 65 samples:\n",
      "Average - KLD: 1.0346 | SIM: 0.4761 | NSS: 1.3621\n",
      "==================================================\n",
      "\n",
      "[65] Processing: hold - knife\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input :  black\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output knife_002682.jpg:\n",
      " all_output Current - KLD: 0.2292 | SIM: 0.7697 | NSS: 3.3138\n",
      "\n",
      "Cumulative all_output  Averages over 66 samples:\n",
      "Average - KLD: 1.0224 | SIM: 0.4805 | NSS: 1.3916\n",
      "==================================================\n",
      "\n",
      "[66] Processing: stick - knife\n",
      "Selected CLIP input : knife\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output knife_001072.jpg:\n",
      " all_output Current - KLD: 1.5181 | SIM: 0.2527 | NSS: 1.9174\n",
      "\n",
      "Cumulative all_output  Averages over 67 samples:\n",
      "Average - KLD: 1.0298 | SIM: 0.4771 | NSS: 1.3995\n",
      "==================================================\n",
      "\n",
      "[67] Processing: wash - knife\n",
      "Selected CLIP input : knife\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output knife_002720.jpg:\n",
      " all_output Current - KLD: 0.7094 | SIM: 0.5390 | NSS: 2.7525\n",
      "\n",
      "Cumulative all_output  Averages over 68 samples:\n",
      "Average - KLD: 1.0251 | SIM: 0.4780 | NSS: 1.4194\n",
      "==================================================\n",
      "\n",
      "[68] Processing: type_on - laptop\n",
      "Selected CLIP input :  keyboard\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output laptop_000585.jpg:\n",
      " all_output Current - KLD: 0.4968 | SIM: 0.5994 | NSS: 1.9287\n",
      "\n",
      "Cumulative all_output  Averages over 69 samples:\n",
      "Average - KLD: 1.0175 | SIM: 0.4798 | NSS: 1.4268\n",
      "==================================================\n",
      "\n",
      "[69] Processing: open - microwave\n",
      "Selected CLIP input :  beige\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output microwave_001049.jpg:\n",
      " all_output Current - KLD: 1.3981 | SIM: 0.3073 | NSS: 0.3616\n",
      "\n",
      "Cumulative all_output  Averages over 70 samples:\n",
      "Average - KLD: 1.0229 | SIM: 0.4773 | NSS: 1.4115\n",
      "==================================================\n",
      "\n",
      "[70] Processing: push - motorcycle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input :  rear\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output motorcycle_003541.jpg:\n",
      " all_output Current - KLD: 2.2713 | SIM: 0.1649 | NSS: 0.1626\n",
      "\n",
      "Cumulative all_output  Averages over 71 samples:\n",
      "Average - KLD: 1.0405 | SIM: 0.4729 | NSS: 1.3939\n",
      "==================================================\n",
      "\n",
      "[71] Processing: ride - motorcycle\n",
      "Selected CLIP input :  the\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output motorcycle_002198.jpg:\n",
      " all_output Current - KLD: 0.8268 | SIM: 0.4984 | NSS: 1.7397\n",
      "\n",
      "Cumulative all_output  Averages over 72 samples:\n",
      "Average - KLD: 1.0375 | SIM: 0.4733 | NSS: 1.3987\n",
      "==================================================\n",
      "\n",
      "[72] Processing: sit_on - motorcycle\n",
      "Selected CLIP input :  black\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output motorcycle_000837.jpg:\n",
      " all_output Current - KLD: 1.6376 | SIM: 0.2258 | NSS: 1.8426\n",
      "\n",
      "Cumulative all_output  Averages over 73 samples:\n",
      "Average - KLD: 1.0457 | SIM: 0.4699 | NSS: 1.4048\n",
      "==================================================\n",
      "\n",
      "[73] Processing: cut - orange\n",
      "Selected CLIP input : orange\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output orange_001193.jpg:\n",
      " all_output Current - KLD: 0.7380 | SIM: 0.6147 | NSS: 1.3356\n",
      "\n",
      "Cumulative all_output  Averages over 74 samples:\n",
      "Average - KLD: 1.0416 | SIM: 0.4719 | NSS: 1.4039\n",
      "==================================================\n",
      "\n",
      "[74] Processing: eat - orange\n",
      "Selected CLIP input : orange\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output orange_001193.jpg:\n",
      " all_output Current - KLD: 0.9389 | SIM: 0.5490 | NSS: 1.1089\n",
      "\n",
      "Cumulative all_output  Averages over 75 samples:\n",
      "Average - KLD: 1.0402 | SIM: 0.4729 | NSS: 1.4000\n",
      "==================================================\n",
      "\n",
      "[75] Processing: peel - orange\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input : orange\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output orange_001193.jpg:\n",
      " all_output Current - KLD: 0.6967 | SIM: 0.6197 | NSS: 1.3296\n",
      "\n",
      "Cumulative all_output  Averages over 76 samples:\n",
      "Average - KLD: 1.0357 | SIM: 0.4748 | NSS: 1.3990\n",
      "==================================================\n",
      "\n",
      "[76] Processing: wash - orange\n",
      "Selected CLIP input : orange\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output orange_001193.jpg:\n",
      " all_output Current - KLD: 0.7213 | SIM: 0.6127 | NSS: 1.2241\n",
      "\n",
      "Cumulative all_output  Averages over 77 samples:\n",
      "Average - KLD: 1.0316 | SIM: 0.4766 | NSS: 1.3968\n",
      "==================================================\n",
      "\n",
      "[77] Processing: open - oven\n",
      "Selected CLIP input : oven\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output oven_001370.jpg:\n",
      " all_output Current - KLD: 0.9908 | SIM: 0.4124 | NSS: 1.5617\n",
      "\n",
      "Cumulative all_output  Averages over 78 samples:\n",
      "Average - KLD: 1.0311 | SIM: 0.4758 | NSS: 1.3989\n",
      "==================================================\n",
      "\n",
      "[78] Processing: write - pen\n",
      "Selected CLIP input : pen\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output pen_003590.jpg:\n",
      " all_output Current - KLD: 1.1512 | SIM: 0.3537 | NSS: 1.9244\n",
      "\n",
      "Cumulative all_output  Averages over 79 samples:\n",
      "Average - KLD: 1.0326 | SIM: 0.4742 | NSS: 1.4055\n",
      "==================================================\n",
      "\n",
      "[79] Processing: boxing - punching_bag\n",
      "Selected CLIP input :  red\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output punching_bag_001845.jpg:\n",
      " all_output Current - KLD: 0.4566 | SIM: 0.6281 | NSS: 0.6060\n",
      "\n",
      "Cumulative all_output  Averages over 80 samples:\n",
      "Average - KLD: 1.0254 | SIM: 0.4762 | NSS: 1.3955\n",
      "==================================================\n",
      "\n",
      "[80] Processing: kick - punching_bag\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input :  Ever\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output punching_bag_001639.jpg:\n",
      " all_output Current - KLD: 0.8681 | SIM: 0.4437 | NSS: 0.5156\n",
      "\n",
      "Cumulative all_output  Averages over 81 samples:\n",
      "Average - KLD: 1.0235 | SIM: 0.4758 | NSS: 1.3847\n",
      "==================================================\n",
      "\n",
      "[81] Processing: open - refrigerator\n",
      "Selected CLIP input :  water\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output refrigerator_002162.jpg:\n",
      " all_output Current - KLD: 2.1990 | SIM: 0.2202 | NSS: 0.1886\n",
      "\n",
      "Cumulative all_output  Averages over 82 samples:\n",
      "Average - KLD: 1.0378 | SIM: 0.4727 | NSS: 1.3701\n",
      "==================================================\n",
      "\n",
      "[82] Processing: catch - rugby_ball\n",
      "Selected CLIP input :  green\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output rugby_ball_003522.jpg:\n",
      " all_output Current - KLD: 1.5723 | SIM: 0.3857 | NSS: 0.1631\n",
      "\n",
      "Cumulative all_output  Averages over 83 samples:\n",
      "Average - KLD: 1.0442 | SIM: 0.4716 | NSS: 1.3555\n",
      "==================================================\n",
      "\n",
      "[83] Processing: kick - rugby_ball\n",
      "Selected CLIP input :  the\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output rugby_ball_002080.jpg:\n",
      " all_output Current - KLD: 0.2183 | SIM: 0.7638 | NSS: 0.9421\n",
      "\n",
      "Cumulative all_output  Averages over 84 samples:\n",
      "Average - KLD: 1.0344 | SIM: 0.4751 | NSS: 1.3506\n",
      "==================================================\n",
      "\n",
      "[84] Processing: throw - rugby_ball\n",
      "Selected CLIP input : rugby_ball\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output rugby_ball_000001.jpg:\n",
      " all_output Current - KLD: 0.2582 | SIM: 0.7341 | NSS: 0.9066\n",
      "\n",
      "Cumulative all_output  Averages over 85 samples:\n",
      "Average - KLD: 1.0253 | SIM: 0.4781 | NSS: 1.3454\n",
      "==================================================\n",
      "\n",
      "[85] Processing: cut_with - scissors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input :  the\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output scissors_002479.jpg:\n",
      " all_output Current - KLD: 1.3428 | SIM: 0.2877 | NSS: 1.5040\n",
      "\n",
      "Cumulative all_output  Averages over 86 samples:\n",
      "Average - KLD: 1.0290 | SIM: 0.4759 | NSS: 1.3472\n",
      "==================================================\n",
      "\n",
      "[86] Processing: hold - scissors\n",
      "Selected CLIP input :  the\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output scissors_002479.jpg:\n",
      " all_output Current - KLD: 0.7391 | SIM: 0.4906 | NSS: 1.3736\n",
      "\n",
      "Cumulative all_output  Averages over 87 samples:\n",
      "Average - KLD: 1.0256 | SIM: 0.4761 | NSS: 1.3475\n",
      "==================================================\n",
      "\n",
      "[87] Processing: carry - skateboard\n",
      "Selected CLIP input : skateboard\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output skateboard_002668.jpg:\n",
      " all_output Current - KLD: 0.1871 | SIM: 0.7725 | NSS: 0.8932\n",
      "\n",
      "Cumulative all_output  Averages over 88 samples:\n",
      "Average - KLD: 1.0161 | SIM: 0.4795 | NSS: 1.3424\n",
      "==================================================\n",
      "\n",
      "[88] Processing: hold - skateboard\n",
      "Selected CLIP input : deck\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output skateboard_002387.jpg:\n",
      " all_output Current - KLD: 0.7524 | SIM: 0.5636 | NSS: 0.9504\n",
      "\n",
      "Cumulative all_output  Averages over 89 samples:\n",
      "Average - KLD: 1.0131 | SIM: 0.4804 | NSS: 1.3380\n",
      "==================================================\n",
      "\n",
      "[89] Processing: jump - skateboard\n",
      "Selected CLIP input : skateboard\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output skateboard_002387.jpg:\n",
      " all_output Current - KLD: 1.0663 | SIM: 0.3921 | NSS: 1.1756\n",
      "\n",
      "Cumulative all_output  Averages over 90 samples:\n",
      "Average - KLD: 1.0137 | SIM: 0.4794 | NSS: 1.3362\n",
      "==================================================\n",
      "\n",
      "[90] Processing: sit_on - skateboard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input :  galaxy\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output skateboard_001460.jpg:\n",
      " all_output Current - KLD: 0.1165 | SIM: 0.8346 | NSS: 1.1116\n",
      "\n",
      "Cumulative all_output  Averages over 91 samples:\n",
      "Average - KLD: 1.0039 | SIM: 0.4833 | NSS: 1.3337\n",
      "==================================================\n",
      "\n",
      "[91] Processing: carry - skis\n",
      "Selected CLIP input : skis\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output skis_002829.jpg:\n",
      " all_output Current - KLD: 2.8446 | SIM: 0.0861 | NSS: -0.2812\n",
      "\n",
      "Cumulative all_output  Averages over 92 samples:\n",
      "Average - KLD: 1.0239 | SIM: 0.4790 | NSS: 1.3162\n",
      "==================================================\n",
      "\n",
      "[92] Processing: hold - skis\n",
      "Selected CLIP input : skis\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output skis_001357.jpg:\n",
      " all_output Current - KLD: 2.2711 | SIM: 0.1481 | NSS: 0.5846\n",
      "\n",
      "Cumulative all_output  Averages over 93 samples:\n",
      "Average - KLD: 1.0373 | SIM: 0.4754 | NSS: 1.3083\n",
      "==================================================\n",
      "\n",
      "[93] Processing: jump - skis\n",
      "Selected CLIP input :  length\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output skis_002829.jpg:\n",
      " all_output Current - KLD: 2.1363 | SIM: 0.1623 | NSS: 0.0535\n",
      "\n",
      "Cumulative all_output  Averages over 94 samples:\n",
      "Average - KLD: 1.0490 | SIM: 0.4721 | NSS: 1.2949\n",
      "==================================================\n",
      "\n",
      "[94] Processing: pick_up - skis\n",
      "Selected CLIP input : V\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output skis_001547.jpg:\n",
      " all_output Current - KLD: 4.5511 | SIM: 0.0225 | NSS: -0.3522\n",
      "\n",
      "Cumulative all_output  Averages over 95 samples:\n",
      "Average - KLD: 1.0858 | SIM: 0.4674 | NSS: 1.2776\n",
      "==================================================\n",
      "\n",
      "[95] Processing: carry - snowboard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input : snowboard\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output snowboard_001325.jpg:\n",
      " all_output Current - KLD: 1.3215 | SIM: 0.2977 | NSS: 2.1932\n",
      "\n",
      "Cumulative all_output  Averages over 96 samples:\n",
      "Average - KLD: 1.0883 | SIM: 0.4656 | NSS: 1.2871\n",
      "==================================================\n",
      "\n",
      "[96] Processing: hold - snowboard\n",
      "Selected CLIP input :  top\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output snowboard_001704.jpg:\n",
      " all_output Current - KLD: 1.8384 | SIM: 0.2108 | NSS: -0.0188\n",
      "\n",
      "Cumulative all_output  Averages over 97 samples:\n",
      "Average - KLD: 1.0960 | SIM: 0.4630 | NSS: 1.2737\n",
      "==================================================\n",
      "\n",
      "[97] Processing: jump - snowboard\n",
      "Selected CLIP input :  central\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output snowboard_001704.jpg:\n",
      " all_output Current - KLD: 1.0310 | SIM: 0.4001 | NSS: 0.2159\n",
      "\n",
      "Cumulative all_output  Averages over 98 samples:\n",
      "Average - KLD: 1.0954 | SIM: 0.4623 | NSS: 1.2629\n",
      "==================================================\n",
      "\n",
      "[98] Processing: catch - soccer_ball\n",
      "Selected CLIP input :  the\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output soccer_ball_003333.jpg:\n",
      " all_output Current - KLD: 0.0785 | SIM: 0.8688 | NSS: 1.3501\n",
      "\n",
      "Cumulative all_output  Averages over 99 samples:\n",
      "Average - KLD: 1.0851 | SIM: 0.4665 | NSS: 1.2638\n",
      "==================================================\n",
      "\n",
      "[99] Processing: kick - soccer_ball\n",
      "Selected CLIP input : soccer_ball\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output soccer_ball_001588.jpg:\n",
      " all_output Current - KLD: 0.1009 | SIM: 0.8532 | NSS: 2.2819\n",
      "\n",
      "Cumulative all_output  Averages over 100 samples:\n",
      "Average - KLD: 1.0753 | SIM: 0.4703 | NSS: 1.2739\n",
      "==================================================\n",
      "\n",
      "[100] Processing: drag - suitcase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input : able\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output suitcase_002998.jpg:\n",
      " all_output Current - KLD: 1.2728 | SIM: 0.3435 | NSS: 4.4482\n",
      "\n",
      "Cumulative all_output  Averages over 101 samples:\n",
      "Average - KLD: 1.0772 | SIM: 0.4691 | NSS: 1.3054\n",
      "==================================================\n",
      "\n",
      "[101] Processing: hold - suitcase\n",
      "Selected CLIP input :  extended\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output suitcase_003687.jpg:\n",
      " all_output Current - KLD: 1.2926 | SIM: 0.3381 | NSS: 2.0076\n",
      "\n",
      "Cumulative all_output  Averages over 102 samples:\n",
      "Average - KLD: 1.0793 | SIM: 0.4678 | NSS: 1.3123\n",
      "==================================================\n",
      "\n",
      "[102] Processing: open - suitcase\n",
      "Selected CLIP input : suitcase\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output suitcase_000520.jpg:\n",
      " all_output Current - KLD: 2.0507 | SIM: 0.1789 | NSS: 0.1128\n",
      "\n",
      "Cumulative all_output  Averages over 103 samples:\n",
      "Average - KLD: 1.0888 | SIM: 0.4650 | NSS: 1.3006\n",
      "==================================================\n",
      "\n",
      "[103] Processing: pack - suitcase\n",
      "Selected CLIP input : suitcase\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output suitcase_002212.jpg:\n",
      " all_output Current - KLD: 0.8519 | SIM: 0.4424 | NSS: 1.0431\n",
      "\n",
      "Cumulative all_output  Averages over 104 samples:\n",
      "Average - KLD: 1.0865 | SIM: 0.4648 | NSS: 1.2981\n",
      "==================================================\n",
      "\n",
      "[104] Processing: pick_up - suitcase\n",
      "Selected CLIP input :  top\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output suitcase_002493.jpg:\n",
      " all_output Current - KLD: 0.6931 | SIM: 0.5564 | NSS: 3.1575\n",
      "\n",
      "Cumulative all_output  Averages over 105 samples:\n",
      "Average - KLD: 1.0827 | SIM: 0.4656 | NSS: 1.3158\n",
      "==================================================\n",
      "\n",
      "[105] Processing: carry - surfboard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input : surfboard\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output surfboard_002422.jpg:\n",
      " all_output Current - KLD: 3.0310 | SIM: 0.1017 | NSS: -0.2487\n",
      "\n",
      "Cumulative all_output  Averages over 106 samples:\n",
      "Average - KLD: 1.1011 | SIM: 0.4622 | NSS: 1.3011\n",
      "==================================================\n",
      "\n",
      "[106] Processing: hold - surfboard\n",
      "Selected CLIP input : surfboard\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output surfboard_002631.jpg:\n",
      " all_output Current - KLD: 0.5616 | SIM: 0.5703 | NSS: 2.9427\n",
      "\n",
      "Cumulative all_output  Averages over 107 samples:\n",
      "Average - KLD: 1.0961 | SIM: 0.4632 | NSS: 1.3164\n",
      "==================================================\n",
      "\n",
      "[107] Processing: jump - surfboard\n",
      "Selected CLIP input : surfboard\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output surfboard_000658.jpg:\n",
      " all_output Current - KLD: 0.8358 | SIM: 0.4597 | NSS: 0.4650\n",
      "\n",
      "Cumulative all_output  Averages over 108 samples:\n",
      "Average - KLD: 1.0937 | SIM: 0.4632 | NSS: 1.3085\n",
      "==================================================\n",
      "\n",
      "[108] Processing: lie_on - surfboard\n",
      "Selected CLIP input : surfboard\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output surfboard_000221.jpg:\n",
      " all_output Current - KLD: 0.0646 | SIM: 0.8901 | NSS: 2.3054\n",
      "\n",
      "Cumulative all_output  Averages over 109 samples:\n",
      "Average - KLD: 1.0842 | SIM: 0.4671 | NSS: 1.3177\n",
      "==================================================\n",
      "\n",
      "[109] Processing: sit_on - surfboard\n",
      "Selected CLIP input : surfboard\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output surfboard_000010.jpg:\n",
      " all_output Current - KLD: 0.1697 | SIM: 0.7712 | NSS: 0.3030\n",
      "\n",
      "Cumulative all_output  Averages over 110 samples:\n",
      "Average - KLD: 1.0759 | SIM: 0.4699 | NSS: 1.3085\n",
      "==================================================\n",
      "\n",
      "[110] Processing: hit - tennis_racket\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input : tennis_racket\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output tennis_racket_002268.jpg:\n",
      " all_output Current - KLD: 3.9741 | SIM: 0.0443 | NSS: -0.5188\n",
      "\n",
      "Cumulative all_output  Averages over 111 samples:\n",
      "Average - KLD: 1.1020 | SIM: 0.4660 | NSS: 1.2920\n",
      "==================================================\n",
      "\n",
      "[111] Processing: hold - tennis_racket\n",
      "Selected CLIP input :  handle\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output tennis_racket_001785.jpg:\n",
      " all_output Current - KLD: 0.3827 | SIM: 0.6561 | NSS: 3.3551\n",
      "\n",
      "Cumulative all_output  Averages over 112 samples:\n",
      "Average - KLD: 1.0956 | SIM: 0.4677 | NSS: 1.3104\n",
      "==================================================\n",
      "\n",
      "[112] Processing: swing - tennis_racket\n",
      "Selected CLIP input :  handle\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output tennis_racket_003066.jpg:\n",
      " all_output Current - KLD: 0.8158 | SIM: 0.4790 | NSS: 2.0501\n",
      "\n",
      "Cumulative all_output  Averages over 113 samples:\n",
      "Average - KLD: 1.0931 | SIM: 0.4678 | NSS: 1.3170\n",
      "==================================================\n",
      "\n",
      "[113] Processing: brush_with - toothbrush\n",
      "Selected CLIP input : toothbrush\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output toothbrush_001764.jpg:\n",
      " all_output Current - KLD: 0.9293 | SIM: 0.4062 | NSS: 3.4693\n",
      "\n",
      "Cumulative all_output  Averages over 114 samples:\n",
      "Average - KLD: 1.0917 | SIM: 0.4673 | NSS: 1.3358\n",
      "==================================================\n",
      "\n",
      "[114] Processing: hold - toothbrush\n",
      "Selected CLIP input : toothbrush\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output toothbrush_003341.jpg:\n",
      " all_output Current - KLD: 1.5450 | SIM: 0.2604 | NSS: 1.4343\n",
      "\n",
      "Cumulative all_output  Averages over 115 samples:\n",
      "Average - KLD: 1.0956 | SIM: 0.4655 | NSS: 1.3367\n",
      "==================================================\n",
      "\n",
      "[115] Processing: wash - toothbrush\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input :  the\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output toothbrush_001991.jpg:\n",
      " all_output Current - KLD: 1.6829 | SIM: 0.2252 | NSS: 1.0944\n",
      "\n",
      "Cumulative all_output  Averages over 116 samples:\n",
      "Average - KLD: 1.1007 | SIM: 0.4634 | NSS: 1.3346\n",
      "==================================================\n",
      "\n",
      "[116] Processing: drink_with - wine_glass\n",
      "Selected CLIP input :  bowl\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output wine_glass_003343.jpg:\n",
      " all_output Current - KLD: 1.5753 | SIM: 0.2406 | NSS: 0.9172\n",
      "\n",
      "Cumulative all_output  Averages over 117 samples:\n",
      "Average - KLD: 1.1047 | SIM: 0.4615 | NSS: 1.3310\n",
      "==================================================\n",
      "\n",
      "[117] Processing: hold - wine_glass\n",
      "Selected CLIP input : wine_glass\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output wine_glass_002374.jpg:\n",
      " all_output Current - KLD: 0.9523 | SIM: 0.4141 | NSS: 1.3138\n",
      "\n",
      "Cumulative all_output  Averages over 118 samples:\n",
      "Average - KLD: 1.1034 | SIM: 0.4611 | NSS: 1.3309\n",
      "==================================================\n",
      "\n",
      "[118] Processing: pour - wine_glass\n",
      "Selected CLIP input : wine_glass\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output wine_glass_000186.jpg:\n",
      " all_output Current - KLD: 0.9956 | SIM: 0.4118 | NSS: 1.6109\n",
      "\n",
      "Cumulative all_output  Averages over 119 samples:\n",
      "Average - KLD: 1.1025 | SIM: 0.4607 | NSS: 1.3333\n",
      "==================================================\n",
      "\n",
      "[119] Processing: sip - wine_glass\n",
      "Selected CLIP input :  bowl\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output wine_glass_003343.jpg:\n",
      " all_output Current - KLD: 1.5734 | SIM: 0.2414 | NSS: 0.9335\n",
      "\n",
      "Cumulative all_output  Averages over 120 samples:\n",
      "Average - KLD: 1.1065 | SIM: 0.4589 | NSS: 1.3299\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics_tracker_alloutput = MetricsTracker(name=\"all_output\")\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 저장할 디렉토리 생성\n",
    "Layername = \"2_top1_exp75\"\n",
    "output_dir = f\"./exo_{Layername}\"  # 디렉토리 이름 변경 (구분 위해)s\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Contrastive Subtraction 강도 설정 (0.5 ~ 1.0 추천)\n",
    "patch_size = 24\n",
    "POS_ALPHA = 0\n",
    "results_list = []\n",
    "pos_map = np.zeros((patch_size, patch_size), dtype=np.float32)\n",
    "for i in range(24):\n",
    "    i += 1\n",
    "    pkl_path = f\"output_results2/exo_attention_result_32B_2_{i}.pkl\"\n",
    "    if not os.path.exists(pkl_path):\n",
    "        continue\n",
    "        \n",
    "    df_output = pd.read_pickle(pkl_path)\n",
    "\n",
    "    for idx, row in df_output.iterrows():\n",
    "        object_name = row['object']\n",
    "        action = row['action']\n",
    "        filename = row['filename']\n",
    "        output_description = row['output_sentence']\n",
    "        output_attentions = row['output_attentions']\n",
    "        PLSP_name = prompt_dict_obj[action][object_name]\n",
    "        exo_name =   os.path.basename(row['random_exo_filename'])\n",
    "\n",
    "        sum_heatmap = np.zeros((patch_size, patch_size), dtype=np.float32)\n",
    "        \n",
    "        exo_img = cv2.imread(row['random_exo_filename'])\n",
    "        exo_img = cv2.cvtColor(exo_img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        \n",
    "        file_name_real = f\"{AGD20K_PATH}/Seen/testset/egocentric/{action}/{object_name}/{filename}\"\n",
    "        gt_path = f\"{AGD20K_PATH}/Seen/testset/GT/{action}/{object_name}/{filename.split('.')[0]}.png\"\n",
    "            \n",
    "        # 이미지 로드\n",
    "        if not os.path.exists(file_name_real):\n",
    "            print(f\"Image not found: {file_name_real}\")\n",
    "            continue\n",
    "\n",
    "        orig_img = cv2.imread(file_name_real)\n",
    "        orig_img = cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB)\n",
    "        h, w, _ = orig_img.shape\n",
    "\n",
    "        print(f\"[{idx}] Processing: {action} - {object_name}\")\n",
    "\n",
    "        # --- 2. [변경] Contrastive Attention Map 계산 ---\n",
    "        token_scores = []\n",
    "        token_idx = 0\n",
    "        for token in output_attentions:\n",
    "            # 토큰별 히트맵 초기화\n",
    "            token_heatmap = np.zeros((patch_size, patch_size), dtype=np.float32)\n",
    "            token_head_count = 0\n",
    "            \n",
    "            attention_value = token['attentions']\n",
    "            decoded_str = token['token_str'] # 디버깅용\n",
    "\n",
    "            for each_attention in attention_value:\n",
    "                layer = each_attention['layer']\n",
    "                head = each_attention['head']\n",
    "                \n",
    "                # # 사용자가 설정한 특정 레이어 필터링 (여기선 Layer 0 유지)\n",
    "                # if each_attention['layer'] != 0:\n",
    "                if 1==1: # (layer <=45) and (layer >= 20): #1==1: # (layer == 26) : #and( head ==20)) : #or ((layer == 24) and( head ==31)):\n",
    "                    sum_heatmap += each_attention['heatmap']\n",
    "                    token_heatmap += each_attention['heatmap']\n",
    "                    token_head_count += 1\n",
    "\n",
    "            \n",
    "            # 해당 레이어의 헤드가 하나도 없으면 스킵\n",
    "            if token_head_count == 0:\n",
    "                continue\n",
    "\n",
    "            # Visual Dependency Score (S_img) 계산: 맵의 총합\n",
    "            s_img = token_heatmap.sum()\n",
    "\n",
    "            # 리스트에 저장\n",
    "            token_scores.append({\n",
    "                \"token\": decoded_str,\n",
    "                \"token_idx\" : token_idx,\n",
    "                \"score\": s_img,\n",
    "                \"heatmap\": token_heatmap, \n",
    "                \"count\": token_head_count\n",
    "            })\n",
    "            token_idx +=1\n",
    "        # 예외 처리: 토큰이 없을 경우\n",
    "        if len(token_scores) == 0:\n",
    "            print(\"No valid tokens found.\")\n",
    "            continue\n",
    "\n",
    "        # 정렬 (Score 기준 오름차순)\n",
    "        sorted_tokens = sorted(token_scores, key=lambda x: x['score'])\n",
    "        \n",
    "        # Top 5 (Signal) & Bottom 5 (Noise) 선정\n",
    "        # 토큰 개수가 10개 미만일 경우 처리\n",
    "        num_select = min(1, len(sorted_tokens) // 2)\n",
    "        if num_select < 1: num_select = 1 # 최소 1개\n",
    "\n",
    "        bottom_tokens = sorted_tokens[:num_select]       # Noise (기능어, 배경 등)\n",
    "        top_tokens = sorted_tokens[-num_select:][::-1]   # Signal (명사, 핵심어)\n",
    "\n",
    "        top_token_idx  = top_tokens[-1]['token_idx']\n",
    "        top_token_text  = top_tokens[-1]['token']\n",
    "\n",
    "        following_token_idx = top_token_idx + 1\n",
    "        following_token = None\n",
    "        for item in token_scores:\n",
    "            if item['token_idx'] == following_token_idx:\n",
    "                following_token = item\n",
    "                break\n",
    "        following_text = following_token['token']\n",
    "\n",
    "        clip_object_heatmap = get_clipseg_heatmap(\n",
    "            file_name_real,\n",
    "            clip_model,\n",
    "            clip_processor,\n",
    "            object_name,\n",
    "        )\n",
    "\n",
    "        clip_top_heatmap = get_clipseg_heatmap(\n",
    "            file_name_real,\n",
    "            clip_model,\n",
    "            clip_processor,\n",
    "            top_token_text + ' ' + following_text,\n",
    "        )\n",
    "        pos_map = np.sum([t['heatmap'] for t in top_tokens], axis=0)\n",
    "        pos_map /= len(top_tokens)\n",
    "        \n",
    "        # Noise Map (Negative) 평균\n",
    "        neg_map = np.sum([t['heatmap'] for t in bottom_tokens], axis=0)\n",
    "        neg_map /= len(bottom_tokens)\n",
    "\n",
    "\n",
    "\n",
    "        # 정규화 (스케일 맞추기 위해 0~1로 변환 후 뺄셈 진행)\n",
    "        if pos_map.max() > 0: pos_map /= pos_map.max()\n",
    "        if neg_map.max() > 0: neg_map /= neg_map.max()\n",
    "\n",
    "        # ✨ Contrastive Subtraction (Signal - alpha * Noise)\n",
    "        CONTRASTIVE_ALPHA = 0\n",
    "        contrastive_heatmap = (pos_map) - (CONTRASTIVE_ALPHA * neg_map)\n",
    "        # contrastive_heatmap = sum_heatmap / (token_head_count + 1e-8)\n",
    "        # --- 3. 정규화 및 후처리 (기존 코드 흐름 연결) ---\n",
    "        # Contrastive Map을 avg_norm 변수로 사용 (0~1 정규화)\n",
    "        h_min, h_max = contrastive_heatmap.min(), contrastive_heatmap.max()\n",
    "\n",
    "        \n",
    "        avg_norm = (contrastive_heatmap - h_min) / (h_max - h_min + 1e-8)\n",
    "\n",
    "        if check_heatmap_containment(clip_top_heatmap,clip_object_heatmap):\n",
    "            clip_heatmap = clip_top_heatmap\n",
    "            clipseg_input_text = top_token_text+ ' ' + following_text\n",
    "            print(f\"Selected CLIP input : {top_token_text}\")\n",
    "            # Signal Map (Positive) 평균\n",
    "\n",
    "\n",
    "\n",
    "        else:\n",
    "            clip_heatmap = clip_object_heatmap\n",
    "            clipseg_input_text = object_name\n",
    "            # h_min, h_max = token_heatmap.min(), token_heatmap.max()\n",
    "            # avg_norm = (token_heatmap - h_min) / (h_max - h_min + 1e-8)\n",
    "\n",
    "            print(f\"Selected CLIP input : {object_name}\")\n",
    "\n",
    "        clip_heatmap_resized = cv2.resize(clip_heatmap, (patch_size, patch_size), interpolation=cv2.INTER_LINEAR)\n",
    "        clip_binary_mask = (clip_heatmap_resized > 0.15).astype(np.float32) # 필요시 사용\n",
    "\n",
    "\n",
    "        # CLIPSeg와 Hadamard Product\n",
    "        avg_norm_cliped = avg_norm * clip_heatmap_resized\n",
    "        gamma =  0.75  # 0\n",
    "        avg_norm_cliped = np.power(avg_norm_cliped, gamma)\n",
    "        # 리사이즈 및 블러링\n",
    "        avg_norm_cliped_rescaled = cv2.resize(avg_norm_cliped, (w, h), interpolation=cv2.INTER_LINEAR)\n",
    "        \n",
    "        sig = min(w, h) * 0.05\n",
    "        k_val = int(sig * 3) * 2 + 1 \n",
    "        kernel_size = (k_val, k_val)\n",
    "\n",
    "        # 블러 적용\n",
    "        blur_map = cv2.GaussianBlur(avg_norm_cliped_rescaled, kernel_size, sig)\n",
    "\n",
    "        # 블러 후 다시 정규화\n",
    "        blur_map = min_max_normalize(blur_map) # 함수가 정의되어 있다고 가정\n",
    "        avg_norm_cliped_blur = blur_map\n",
    "        \n",
    "        # 시각화를 위해 31x31 맵도 원본 크기로 리사이즈\n",
    "        avg_norm_resized_vis = cv2.resize(avg_norm, (w, h), interpolation=cv2.INTER_LINEAR)\n",
    "        clip_vis = cv2.resize(clip_heatmap_resized, (w, h), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        # --- 4. GT 평가 및 메트릭 계산 ---\n",
    "        gt_map = load_ground_truth(gt_path) # 함수 정의 가정\n",
    "        if gt_map is not None:\n",
    "            metrics_dino = calculate_metrics(avg_norm_cliped_blur, gt_map) # 함수 정의 가정\n",
    "            metrics_tracker_alloutput.update(metrics_dino) # 객체 정의 가정\n",
    "            \n",
    "            # 메트릭 텍스트\n",
    "            metrics_text = f\"[{object_name} {action}] KLD: {metrics_dino['KLD']:.4f} | SIM: {metrics_dino['SIM']:.4f} | NSS: {metrics_dino['NSS']:.4f}\"\n",
    "            metrics_tracker_alloutput.print_metrics(metrics_dino, filename)\n",
    "        else:\n",
    "            print(\"NO GT!!!\")\n",
    "            metrics_text = \"No GT Available\"\n",
    "            continue\n",
    "        \n",
    "        results_list.append({\n",
    "            'object': object_name,\n",
    "            'action': action,\n",
    "            'filename': filename,\n",
    "            'output_sentence': output_description,\n",
    "            'top_token_text': top_token_text,\n",
    "            'following_text': following_text,\n",
    "            'clip_input': clipseg_input_text,\n",
    "            'KLD': metrics_dino['KLD'],\n",
    "            'SIM': metrics_dino['SIM'],\n",
    "            'NSS': metrics_dino['NSS']\n",
    "        })\n",
    "\n",
    "        # --- 5. 시각화 ---\n",
    "        fig, axes = plt.subplots(1, 7, figsize=(24, 5)) # 사이즈 살짝 조정\n",
    "        \n",
    "        # Signal 단어와 Noise 단어 표시 (제목용)\n",
    "        top_words = \",\".join([f\"'{t['token'].strip()}'\" for t in top_tokens[:5]])\n",
    "        \n",
    "        main_title = f\"Obj: {object_name} | Act: {action} |{metrics_text}\\nTop Tokens: [{top_words}({top_token_idx } ), clipseg input : {top_token_text} {following_text}] \\n Whole answer : {output_description}\"\n",
    "        fig.suptitle(main_title, fontsize=14, fontweight='bold', y=0.98)\n",
    "\n",
    "        # (1) 원본 이미지\n",
    "        axes[0].imshow(orig_img)\n",
    "        axes[0].set_title(f\"Original\\n({object_name})\")\n",
    "        axes[0].axis('off')\n",
    "\n",
    "        # (2) Contrastive Attention (Pos - Neg)\n",
    "        im1 = axes[1].imshow(avg_norm_resized_vis, cmap='jet', interpolation='bilinear')\n",
    "        axes[1].set_title(f\"Attention Map {Layername}\")\n",
    "        axes[1].axis('off')\n",
    "        plt.colorbar(im1, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "\n",
    "        # (3) CLIPSeg Result\n",
    "        axes[2].imshow(clip_vis, cmap='gray')\n",
    "        axes[2].set_title(f\"CLIPSeg {clipseg_input_text}\")\n",
    "        axes[2].axis('off')\n",
    "\n",
    "        # (4) Hadamard (Contrastive x CLIPSeg)\n",
    "        # 리사이즈하여 시각화\n",
    "        hadamard_vis = cv2.resize(avg_norm_cliped, (w, h), interpolation=cv2.INTER_LINEAR)\n",
    "        im3 = axes[3].imshow(hadamard_vis, cmap='jet', interpolation='bilinear')\n",
    "        axes[3].set_title(\"Hadamard\\n(Contrastive x CLIP)\")\n",
    "        axes[3].axis('off')\n",
    "        plt.colorbar(im3, ax=axes[3], fraction=0.046, pad=0.04)\n",
    "\n",
    "        # (5) Final Blurred Result\n",
    "        im4 = axes[4].imshow(avg_norm_cliped_blur, cmap='jet', interpolation='bilinear')\n",
    "        axes[4].set_title(\"Final Blurred\")\n",
    "        axes[4].axis('off')\n",
    "        plt.colorbar(im4, ax=axes[4], fraction=0.046, pad=0.04)\n",
    "\n",
    "        # (6) Ground Truth\n",
    "        axes[5].imshow(gt_map, cmap='gray') # GT는 보통 binary 혹은 gray\n",
    "        axes[5].set_title(\"Ground Truth\")\n",
    "        axes[5].axis('off')\n",
    "\n",
    "        # (6) exo Image\n",
    "        axes[6].imshow(exo_img, cmap='gray') # GT는 보통 binary 혹은 gray\n",
    "        axes[6].set_title(\"Ground Truth\")\n",
    "        axes[6].axis('off')\n",
    "\n",
    "\n",
    "        # 파일 저장\n",
    "        save_path = os.path.join(output_dir, f\"exo_{object_name}_{action}_{filename.split('.')[0]}_{exo_name.split('.')[0]}.png\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path, bbox_inches='tight', dpi=150)\n",
    "        plt.close(fig)\n",
    "\n",
    "df_analy = pd.DataFrame(results_list)\n",
    "df_analy.to_pickle(\"2_exo_attention_top1.pkl\")\n",
    "        # print(f\"clipseg_input_text : {clipseg_input_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a3ebd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 24)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  TOP1 : KLD: 1.1065 | SIM: 0.4589 | NSS: 1.3299\n",
    "# All Token : Average - KLD: 1.0833 | SIM: 0.4528 | NSS: 1.3326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec9eb2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analy.to_csv(\"results_top1_following_gamma.csv\",sep=\"$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db9b6ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['object', 'action', 'filename', 'output_sentence', 'top_token_text',\n",
       "       'following_text', 'clip_input', 'KLD', 'SIM', 'NSS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9879dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object</th>\n",
       "      <th>action</th>\n",
       "      <th>filename</th>\n",
       "      <th>output_sentence</th>\n",
       "      <th>top_token_text</th>\n",
       "      <th>following_text</th>\n",
       "      <th>clip_input</th>\n",
       "      <th>KLD</th>\n",
       "      <th>SIM</th>\n",
       "      <th>NSS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apple</td>\n",
       "      <td>eat</td>\n",
       "      <td>apple_001541.jpg</td>\n",
       "      <td>Based on the first image, the entire flesh of ...</td>\n",
       "      <td>the</td>\n",
       "      <td>apple</td>\n",
       "      <td>the  apple</td>\n",
       "      <td>0.048497</td>\n",
       "      <td>0.878917</td>\n",
       "      <td>1.272056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>axe</td>\n",
       "      <td>hit</td>\n",
       "      <td>axe_000961.jpg</td>\n",
       "      <td>Based on the first image, the sharp, curved bl...</td>\n",
       "      <td>curved</td>\n",
       "      <td>blade</td>\n",
       "      <td>curved  blade</td>\n",
       "      <td>2.671174</td>\n",
       "      <td>0.101751</td>\n",
       "      <td>-0.233426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>axe</td>\n",
       "      <td>hold</td>\n",
       "      <td>axe_001552.jpg</td>\n",
       "      <td>Based on the first image, the handle of the ax...</td>\n",
       "      <td>red</td>\n",
       "      <td>and</td>\n",
       "      <td>red  and</td>\n",
       "      <td>0.207951</td>\n",
       "      <td>0.750536</td>\n",
       "      <td>2.564849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>badminton_racket</td>\n",
       "      <td>hold</td>\n",
       "      <td>badminton_racket_002255.jpg</td>\n",
       "      <td>Based on the first image, the handle (or grip)...</td>\n",
       "      <td>handle</td>\n",
       "      <td>(</td>\n",
       "      <td>handle  (</td>\n",
       "      <td>0.832631</td>\n",
       "      <td>0.456883</td>\n",
       "      <td>2.228246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>banana</td>\n",
       "      <td>peel</td>\n",
       "      <td>banana_000480.jpg</td>\n",
       "      <td>Based on the first image, the outer yellow ski...</td>\n",
       "      <td>yellow</td>\n",
       "      <td>skin</td>\n",
       "      <td>yellow  skin</td>\n",
       "      <td>1.416590</td>\n",
       "      <td>0.310270</td>\n",
       "      <td>0.906147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bed</td>\n",
       "      <td>lie_on</td>\n",
       "      <td>bed_002880.jpg</td>\n",
       "      <td>Based on the first image, when people perform ...</td>\n",
       "      <td>gray</td>\n",
       "      <td>bedding</td>\n",
       "      <td>gray  bedding</td>\n",
       "      <td>0.217538</td>\n",
       "      <td>0.750239</td>\n",
       "      <td>2.923309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bed</td>\n",
       "      <td>sit_on</td>\n",
       "      <td>bed_003622.jpg</td>\n",
       "      <td>Based on the first image, when people perform ...</td>\n",
       "      <td>blue</td>\n",
       "      <td>du</td>\n",
       "      <td>blue  du</td>\n",
       "      <td>0.570610</td>\n",
       "      <td>0.578344</td>\n",
       "      <td>1.676782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bench</td>\n",
       "      <td>lie_on</td>\n",
       "      <td>bench_003727.jpg</td>\n",
       "      <td>Based on the first image, when people perform ...</td>\n",
       "      <td>by</td>\n",
       "      <td>legs</td>\n",
       "      <td>by  legs</td>\n",
       "      <td>1.351450</td>\n",
       "      <td>0.378122</td>\n",
       "      <td>0.763257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>bicycle</td>\n",
       "      <td>push</td>\n",
       "      <td>bicycle_002432.jpg</td>\n",
       "      <td>Based on the first image, when people perform ...</td>\n",
       "      <td>a</td>\n",
       "      <td>bicycle</td>\n",
       "      <td>a  bicycle</td>\n",
       "      <td>2.785041</td>\n",
       "      <td>0.102958</td>\n",
       "      <td>-0.034037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>bicycle</td>\n",
       "      <td>ride</td>\n",
       "      <td>bicycle_003046.jpg</td>\n",
       "      <td>Based on the first image, the part of the bicy...</td>\n",
       "      <td>seat</td>\n",
       "      <td>,</td>\n",
       "      <td>seat ,</td>\n",
       "      <td>0.920077</td>\n",
       "      <td>0.479077</td>\n",
       "      <td>1.575963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>bicycle</td>\n",
       "      <td>sit_on</td>\n",
       "      <td>bicycle_002100.jpg</td>\n",
       "      <td>Based on the first image, the part of the bicy...</td>\n",
       "      <td>the</td>\n",
       "      <td>bicycle</td>\n",
       "      <td>the  bicycle</td>\n",
       "      <td>1.444522</td>\n",
       "      <td>0.298922</td>\n",
       "      <td>2.352401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>bottle</td>\n",
       "      <td>drink_with</td>\n",
       "      <td>bottle_003259.jpg</td>\n",
       "      <td>The mouth of the bottle is used for 'drink_wit...</td>\n",
       "      <td>the</td>\n",
       "      <td>bottle</td>\n",
       "      <td>the  bottle</td>\n",
       "      <td>1.713565</td>\n",
       "      <td>0.209257</td>\n",
       "      <td>1.697339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>bottle</td>\n",
       "      <td>open</td>\n",
       "      <td>bottle_001033.jpg</td>\n",
       "      <td>Based on the first image, the top part of the ...</td>\n",
       "      <td>green</td>\n",
       "      <td>cap</td>\n",
       "      <td>green  cap</td>\n",
       "      <td>0.465599</td>\n",
       "      <td>0.625174</td>\n",
       "      <td>3.723509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>bottle</td>\n",
       "      <td>pour</td>\n",
       "      <td>bottle_002780.jpg</td>\n",
       "      <td>Based on the first image, the narrow, tapered ...</td>\n",
       "      <td>pink</td>\n",
       "      <td>cap</td>\n",
       "      <td>pink  cap</td>\n",
       "      <td>4.288736</td>\n",
       "      <td>0.057089</td>\n",
       "      <td>-0.262622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>bowl</td>\n",
       "      <td>hold</td>\n",
       "      <td>bowl_000546.jpg</td>\n",
       "      <td>Based on the first image, when people hold a b...</td>\n",
       "      <td>outer</td>\n",
       "      <td>rim</td>\n",
       "      <td>outer  rim</td>\n",
       "      <td>0.231860</td>\n",
       "      <td>0.743596</td>\n",
       "      <td>0.891838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>bowl</td>\n",
       "      <td>stir</td>\n",
       "      <td>bowl_000134.jpg</td>\n",
       "      <td>Based on the first image, the top opening of t...</td>\n",
       "      <td>creamy</td>\n",
       "      <td>contents</td>\n",
       "      <td>creamy  contents</td>\n",
       "      <td>1.049518</td>\n",
       "      <td>0.481345</td>\n",
       "      <td>0.897744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>camera</td>\n",
       "      <td>take_photo</td>\n",
       "      <td>camera_002534.jpg</td>\n",
       "      <td>Based on the first image, the shutter button o...</td>\n",
       "      <td>the</td>\n",
       "      <td>camera</td>\n",
       "      <td>the  camera</td>\n",
       "      <td>0.734123</td>\n",
       "      <td>0.504208</td>\n",
       "      <td>0.377324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>cell_phone</td>\n",
       "      <td>take_photo</td>\n",
       "      <td>cell_phone_000601.jpg</td>\n",
       "      <td>Based on the first image, when people perform ...</td>\n",
       "      <td>the</td>\n",
       "      <td>phone</td>\n",
       "      <td>the  phone</td>\n",
       "      <td>0.386950</td>\n",
       "      <td>0.647893</td>\n",
       "      <td>1.596167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>cell_phone</td>\n",
       "      <td>text_on</td>\n",
       "      <td>cell_phone_003361.jpg</td>\n",
       "      <td>Based on the first image, when people perform ...</td>\n",
       "      <td>the</td>\n",
       "      <td>screen</td>\n",
       "      <td>the  screen</td>\n",
       "      <td>0.923461</td>\n",
       "      <td>0.434130</td>\n",
       "      <td>1.338623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>chair</td>\n",
       "      <td>sit_on</td>\n",
       "      <td>chair_002839.jpg</td>\n",
       "      <td>Based on the first image, the part of the chai...</td>\n",
       "      <td>blue</td>\n",
       "      <td>and</td>\n",
       "      <td>blue  and</td>\n",
       "      <td>1.021340</td>\n",
       "      <td>0.380349</td>\n",
       "      <td>0.647831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>couch</td>\n",
       "      <td>sit_on</td>\n",
       "      <td>couch_000779.jpg</td>\n",
       "      <td>Based on the first image, the main seating are...</td>\n",
       "      <td>three</td>\n",
       "      <td>cushion</td>\n",
       "      <td>three  cushion</td>\n",
       "      <td>0.850645</td>\n",
       "      <td>0.446726</td>\n",
       "      <td>1.592862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>cup</td>\n",
       "      <td>sip</td>\n",
       "      <td>cup_001864.jpg</td>\n",
       "      <td>Based on the first image, the rim of the cup i...</td>\n",
       "      <td>the</td>\n",
       "      <td>cup</td>\n",
       "      <td>the  cup</td>\n",
       "      <td>0.364921</td>\n",
       "      <td>0.666311</td>\n",
       "      <td>1.084496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>cup</td>\n",
       "      <td>wash</td>\n",
       "      <td>cup_003621.jpg</td>\n",
       "      <td>Based on the first image, when people perform ...</td>\n",
       "      <td>decorated</td>\n",
       "      <td>body</td>\n",
       "      <td>decorated  body</td>\n",
       "      <td>2.742813</td>\n",
       "      <td>0.115659</td>\n",
       "      <td>-0.133980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>discus</td>\n",
       "      <td>throw</td>\n",
       "      <td>discus_003558.jpg</td>\n",
       "      <td>Based on the first image, the central metallic...</td>\n",
       "      <td>metallic</td>\n",
       "      <td>hub</td>\n",
       "      <td>metallic  hub</td>\n",
       "      <td>0.517178</td>\n",
       "      <td>0.592233</td>\n",
       "      <td>0.670623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>fork</td>\n",
       "      <td>hold</td>\n",
       "      <td>fork_000804.jpg</td>\n",
       "      <td>Based on the first image, the handle of the fo...</td>\n",
       "      <td>handle</td>\n",
       "      <td>of</td>\n",
       "      <td>handle  of</td>\n",
       "      <td>0.714619</td>\n",
       "      <td>0.505429</td>\n",
       "      <td>1.939612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>fork</td>\n",
       "      <td>wash</td>\n",
       "      <td>fork_001691.jpg</td>\n",
       "      <td>Based on the first image, when people wash a f...</td>\n",
       "      <td>the</td>\n",
       "      <td>entire</td>\n",
       "      <td>the  entire</td>\n",
       "      <td>0.959103</td>\n",
       "      <td>0.405269</td>\n",
       "      <td>2.154047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>frisbee</td>\n",
       "      <td>catch</td>\n",
       "      <td>frisbee_000598.jpg</td>\n",
       "      <td>Based on the first image, the flat, circular s...</td>\n",
       "      <td>flat</td>\n",
       "      <td>,</td>\n",
       "      <td>flat ,</td>\n",
       "      <td>0.813959</td>\n",
       "      <td>0.470619</td>\n",
       "      <td>-0.086120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>frisbee</td>\n",
       "      <td>hold</td>\n",
       "      <td>frisbee_001130.jpg</td>\n",
       "      <td>Based on the first image, the frisbee is held ...</td>\n",
       "      <td>star</td>\n",
       "      <td>graphic</td>\n",
       "      <td>star  graphic</td>\n",
       "      <td>2.001801</td>\n",
       "      <td>0.210061</td>\n",
       "      <td>-0.518460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>frisbee</td>\n",
       "      <td>throw</td>\n",
       "      <td>frisbee_003249.jpg</td>\n",
       "      <td>Based on the first image, the central, solid p...</td>\n",
       "      <td>solid</td>\n",
       "      <td>portion</td>\n",
       "      <td>solid  portion</td>\n",
       "      <td>0.702910</td>\n",
       "      <td>0.509880</td>\n",
       "      <td>0.376825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>golf_clubs</td>\n",
       "      <td>hold</td>\n",
       "      <td>golf_clubs_000045.jpg</td>\n",
       "      <td>Based on the first image, the black, textured ...</td>\n",
       "      <td>black</td>\n",
       "      <td>,</td>\n",
       "      <td>black ,</td>\n",
       "      <td>0.765289</td>\n",
       "      <td>0.536735</td>\n",
       "      <td>1.662469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>hammer</td>\n",
       "      <td>hold</td>\n",
       "      <td>hammer_000215.jpg</td>\n",
       "      <td>Based on the first image, the handle of the ha...</td>\n",
       "      <td>handle</td>\n",
       "      <td>of</td>\n",
       "      <td>handle  of</td>\n",
       "      <td>0.978825</td>\n",
       "      <td>0.388227</td>\n",
       "      <td>2.500097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>javelin</td>\n",
       "      <td>throw</td>\n",
       "      <td>javelin_001474.jpg</td>\n",
       "      <td>Based on the first image, the part of the jave...</td>\n",
       "      <td>yellow</td>\n",
       "      <td>-colored</td>\n",
       "      <td>yellow -colored</td>\n",
       "      <td>0.195666</td>\n",
       "      <td>0.822492</td>\n",
       "      <td>3.632657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>knife</td>\n",
       "      <td>hold</td>\n",
       "      <td>knife_002682.jpg</td>\n",
       "      <td>Based on the first image, when people perform ...</td>\n",
       "      <td>black</td>\n",
       "      <td>handle</td>\n",
       "      <td>black  handle</td>\n",
       "      <td>0.229159</td>\n",
       "      <td>0.769653</td>\n",
       "      <td>3.313839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>laptop</td>\n",
       "      <td>type_on</td>\n",
       "      <td>laptop_000585.jpg</td>\n",
       "      <td>Based on the first image, the keyboard is the ...</td>\n",
       "      <td>keyboard</td>\n",
       "      <td>is</td>\n",
       "      <td>keyboard  is</td>\n",
       "      <td>0.496758</td>\n",
       "      <td>0.599362</td>\n",
       "      <td>1.928662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>microwave</td>\n",
       "      <td>open</td>\n",
       "      <td>microwave_001049.jpg</td>\n",
       "      <td>Based on the first image, the beige handle loc...</td>\n",
       "      <td>beige</td>\n",
       "      <td>handle</td>\n",
       "      <td>beige  handle</td>\n",
       "      <td>1.398069</td>\n",
       "      <td>0.307349</td>\n",
       "      <td>0.361574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>motorcycle</td>\n",
       "      <td>push</td>\n",
       "      <td>motorcycle_003541.jpg</td>\n",
       "      <td>Based on the second image, when people push a ...</td>\n",
       "      <td>rear</td>\n",
       "      <td>wheel</td>\n",
       "      <td>rear  wheel</td>\n",
       "      <td>2.271270</td>\n",
       "      <td>0.164927</td>\n",
       "      <td>0.162561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>motorcycle</td>\n",
       "      <td>ride</td>\n",
       "      <td>motorcycle_002198.jpg</td>\n",
       "      <td>Based on the first image, the part of the moto...</td>\n",
       "      <td>the</td>\n",
       "      <td>motorcycle</td>\n",
       "      <td>the  motorcycle</td>\n",
       "      <td>0.826814</td>\n",
       "      <td>0.498427</td>\n",
       "      <td>1.739709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>motorcycle</td>\n",
       "      <td>sit_on</td>\n",
       "      <td>motorcycle_000837.jpg</td>\n",
       "      <td>Based on the first image, the part of the moto...</td>\n",
       "      <td>black</td>\n",
       "      <td>,</td>\n",
       "      <td>black ,</td>\n",
       "      <td>1.637634</td>\n",
       "      <td>0.225825</td>\n",
       "      <td>1.842644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>punching_bag</td>\n",
       "      <td>boxing</td>\n",
       "      <td>punching_bag_001845.jpg</td>\n",
       "      <td>Based on the first image, the main red and bla...</td>\n",
       "      <td>red</td>\n",
       "      <td>and</td>\n",
       "      <td>red  and</td>\n",
       "      <td>0.456583</td>\n",
       "      <td>0.628089</td>\n",
       "      <td>0.606045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>punching_bag</td>\n",
       "      <td>kick</td>\n",
       "      <td>punching_bag_001639.jpg</td>\n",
       "      <td>Based on the first image, the main body or fro...</td>\n",
       "      <td>Ever</td>\n",
       "      <td>last</td>\n",
       "      <td>Ever last</td>\n",
       "      <td>0.868119</td>\n",
       "      <td>0.443704</td>\n",
       "      <td>0.515587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>refrigerator</td>\n",
       "      <td>open</td>\n",
       "      <td>refrigerator_002162.jpg</td>\n",
       "      <td>Based on the first image, the left door of the...</td>\n",
       "      <td>water</td>\n",
       "      <td>and</td>\n",
       "      <td>water  and</td>\n",
       "      <td>2.198962</td>\n",
       "      <td>0.220247</td>\n",
       "      <td>0.188627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>rugby_ball</td>\n",
       "      <td>catch</td>\n",
       "      <td>rugby_ball_003522.jpg</td>\n",
       "      <td>When catching a rugby ball, people typically u...</td>\n",
       "      <td>green</td>\n",
       "      <td>l</td>\n",
       "      <td>green  l</td>\n",
       "      <td>1.572308</td>\n",
       "      <td>0.385669</td>\n",
       "      <td>0.163138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>rugby_ball</td>\n",
       "      <td>kick</td>\n",
       "      <td>rugby_ball_002080.jpg</td>\n",
       "      <td>Based on the first image, when people perform ...</td>\n",
       "      <td>the</td>\n",
       "      <td>rugby</td>\n",
       "      <td>the  rugby</td>\n",
       "      <td>0.218267</td>\n",
       "      <td>0.763812</td>\n",
       "      <td>0.942119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>scissors</td>\n",
       "      <td>cut_with</td>\n",
       "      <td>scissors_002479.jpg</td>\n",
       "      <td>The blades of the scissors are used for 'cut_w...</td>\n",
       "      <td>the</td>\n",
       "      <td>scissors</td>\n",
       "      <td>the  scissors</td>\n",
       "      <td>1.342794</td>\n",
       "      <td>0.287668</td>\n",
       "      <td>1.504042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>scissors</td>\n",
       "      <td>hold</td>\n",
       "      <td>scissors_002479.jpg</td>\n",
       "      <td>Based on the first image, the handles of the s...</td>\n",
       "      <td>the</td>\n",
       "      <td>scissors</td>\n",
       "      <td>the  scissors</td>\n",
       "      <td>0.739086</td>\n",
       "      <td>0.490557</td>\n",
       "      <td>1.373576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>skateboard</td>\n",
       "      <td>hold</td>\n",
       "      <td>skateboard_002387.jpg</td>\n",
       "      <td>Based on the first image, when people perform ...</td>\n",
       "      <td>deck</td>\n",
       "      <td>**</td>\n",
       "      <td>deck **</td>\n",
       "      <td>0.752420</td>\n",
       "      <td>0.563604</td>\n",
       "      <td>0.950367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>skateboard</td>\n",
       "      <td>sit_on</td>\n",
       "      <td>skateboard_001460.jpg</td>\n",
       "      <td>Based on the first image, the deck (the flat, ...</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>pattern</td>\n",
       "      <td>galaxy  pattern</td>\n",
       "      <td>0.116484</td>\n",
       "      <td>0.834559</td>\n",
       "      <td>1.111620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>skis</td>\n",
       "      <td>jump</td>\n",
       "      <td>skis_002829.jpg</td>\n",
       "      <td>When people perform a jump with skis, the enti...</td>\n",
       "      <td>length</td>\n",
       "      <td>of</td>\n",
       "      <td>length  of</td>\n",
       "      <td>2.136331</td>\n",
       "      <td>0.162259</td>\n",
       "      <td>0.053530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>skis</td>\n",
       "      <td>pick_up</td>\n",
       "      <td>skis_001547.jpg</td>\n",
       "      <td>Based on the first image, the top end (tip) of...</td>\n",
       "      <td>V</td>\n",
       "      <td>öl</td>\n",
       "      <td>V öl</td>\n",
       "      <td>4.551119</td>\n",
       "      <td>0.022544</td>\n",
       "      <td>-0.352152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>snowboard</td>\n",
       "      <td>hold</td>\n",
       "      <td>snowboard_001704.jpg</td>\n",
       "      <td>Based on the first image, the part of the snow...</td>\n",
       "      <td>top</td>\n",
       "      <td>surface</td>\n",
       "      <td>top  surface</td>\n",
       "      <td>1.838449</td>\n",
       "      <td>0.210843</td>\n",
       "      <td>-0.018791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>snowboard</td>\n",
       "      <td>jump</td>\n",
       "      <td>snowboard_001704.jpg</td>\n",
       "      <td>Based on the first image, when people perform ...</td>\n",
       "      <td>central</td>\n",
       "      <td>area</td>\n",
       "      <td>central  area</td>\n",
       "      <td>1.031035</td>\n",
       "      <td>0.400117</td>\n",
       "      <td>0.215897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>soccer_ball</td>\n",
       "      <td>catch</td>\n",
       "      <td>soccer_ball_003333.jpg</td>\n",
       "      <td>Based on the first image, when people perform ...</td>\n",
       "      <td>the</td>\n",
       "      <td>ball</td>\n",
       "      <td>the  ball</td>\n",
       "      <td>0.078484</td>\n",
       "      <td>0.868794</td>\n",
       "      <td>1.350087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>suitcase</td>\n",
       "      <td>drag</td>\n",
       "      <td>suitcase_002998.jpg</td>\n",
       "      <td>Based on the first image, the part of the suit...</td>\n",
       "      <td>able</td>\n",
       "      <td>telesc</td>\n",
       "      <td>able  telesc</td>\n",
       "      <td>1.272793</td>\n",
       "      <td>0.343482</td>\n",
       "      <td>4.448220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>suitcase</td>\n",
       "      <td>hold</td>\n",
       "      <td>suitcase_003687.jpg</td>\n",
       "      <td>Based on the first image, the part of the suit...</td>\n",
       "      <td>extended</td>\n",
       "      <td>telesc</td>\n",
       "      <td>extended  telesc</td>\n",
       "      <td>1.292622</td>\n",
       "      <td>0.338115</td>\n",
       "      <td>2.007571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>suitcase</td>\n",
       "      <td>pick_up</td>\n",
       "      <td>suitcase_002493.jpg</td>\n",
       "      <td>Based on the first image, people perform the '...</td>\n",
       "      <td>top</td>\n",
       "      <td>handle</td>\n",
       "      <td>top  handle</td>\n",
       "      <td>0.693142</td>\n",
       "      <td>0.556388</td>\n",
       "      <td>3.157528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>tennis_racket</td>\n",
       "      <td>hold</td>\n",
       "      <td>tennis_racket_001785.jpg</td>\n",
       "      <td>Based on the first image, the handle of the te...</td>\n",
       "      <td>handle</td>\n",
       "      <td>of</td>\n",
       "      <td>handle  of</td>\n",
       "      <td>0.382704</td>\n",
       "      <td>0.656062</td>\n",
       "      <td>3.355089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>tennis_racket</td>\n",
       "      <td>swing</td>\n",
       "      <td>tennis_racket_003066.jpg</td>\n",
       "      <td>Based on the first image, the handle of the te...</td>\n",
       "      <td>handle</td>\n",
       "      <td>of</td>\n",
       "      <td>handle  of</td>\n",
       "      <td>0.815831</td>\n",
       "      <td>0.478990</td>\n",
       "      <td>2.050146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>toothbrush</td>\n",
       "      <td>wash</td>\n",
       "      <td>toothbrush_001991.jpg</td>\n",
       "      <td>Based on the first image, the bristle head at ...</td>\n",
       "      <td>the</td>\n",
       "      <td>tooth</td>\n",
       "      <td>the  tooth</td>\n",
       "      <td>1.682891</td>\n",
       "      <td>0.225198</td>\n",
       "      <td>1.094393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>wine_glass</td>\n",
       "      <td>drink_with</td>\n",
       "      <td>wine_glass_003343.jpg</td>\n",
       "      <td>Based on the first image, the bowl of the wine...</td>\n",
       "      <td>bowl</td>\n",
       "      <td>of</td>\n",
       "      <td>bowl  of</td>\n",
       "      <td>1.575323</td>\n",
       "      <td>0.240579</td>\n",
       "      <td>0.917182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>wine_glass</td>\n",
       "      <td>sip</td>\n",
       "      <td>wine_glass_003343.jpg</td>\n",
       "      <td>Based on the first image, the bowl of the wine...</td>\n",
       "      <td>bowl</td>\n",
       "      <td>of</td>\n",
       "      <td>bowl  of</td>\n",
       "      <td>1.573366</td>\n",
       "      <td>0.241423</td>\n",
       "      <td>0.933471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               object      action                     filename  \\\n",
       "1               apple         eat             apple_001541.jpg   \n",
       "3                 axe         hit               axe_000961.jpg   \n",
       "4                 axe        hold               axe_001552.jpg   \n",
       "5    badminton_racket        hold  badminton_racket_002255.jpg   \n",
       "9              banana        peel            banana_000480.jpg   \n",
       "15                bed      lie_on               bed_002880.jpg   \n",
       "16                bed      sit_on               bed_003622.jpg   \n",
       "17              bench      lie_on             bench_003727.jpg   \n",
       "19            bicycle        push           bicycle_002432.jpg   \n",
       "20            bicycle        ride           bicycle_003046.jpg   \n",
       "21            bicycle      sit_on           bicycle_002100.jpg   \n",
       "25             bottle  drink_with            bottle_003259.jpg   \n",
       "27             bottle        open            bottle_001033.jpg   \n",
       "28             bottle        pour            bottle_002780.jpg   \n",
       "29               bowl        hold              bowl_000546.jpg   \n",
       "30               bowl        stir              bowl_000134.jpg   \n",
       "33             camera  take_photo            camera_002534.jpg   \n",
       "37         cell_phone  take_photo        cell_phone_000601.jpg   \n",
       "39         cell_phone     text_on        cell_phone_003361.jpg   \n",
       "40              chair      sit_on             chair_002839.jpg   \n",
       "42              couch      sit_on             couch_000779.jpg   \n",
       "46                cup         sip               cup_001864.jpg   \n",
       "47                cup        wash               cup_003621.jpg   \n",
       "48             discus       throw            discus_003558.jpg   \n",
       "50               fork        hold              fork_000804.jpg   \n",
       "53               fork        wash              fork_001691.jpg   \n",
       "54            frisbee       catch           frisbee_000598.jpg   \n",
       "55            frisbee        hold           frisbee_001130.jpg   \n",
       "56            frisbee       throw           frisbee_003249.jpg   \n",
       "57         golf_clubs        hold        golf_clubs_000045.jpg   \n",
       "60             hammer        hold            hammer_000215.jpg   \n",
       "62            javelin       throw           javelin_001474.jpg   \n",
       "65              knife        hold             knife_002682.jpg   \n",
       "68             laptop     type_on            laptop_000585.jpg   \n",
       "69          microwave        open         microwave_001049.jpg   \n",
       "70         motorcycle        push        motorcycle_003541.jpg   \n",
       "71         motorcycle        ride        motorcycle_002198.jpg   \n",
       "72         motorcycle      sit_on        motorcycle_000837.jpg   \n",
       "79       punching_bag      boxing      punching_bag_001845.jpg   \n",
       "80       punching_bag        kick      punching_bag_001639.jpg   \n",
       "81       refrigerator        open      refrigerator_002162.jpg   \n",
       "82         rugby_ball       catch        rugby_ball_003522.jpg   \n",
       "83         rugby_ball        kick        rugby_ball_002080.jpg   \n",
       "85           scissors    cut_with          scissors_002479.jpg   \n",
       "86           scissors        hold          scissors_002479.jpg   \n",
       "88         skateboard        hold        skateboard_002387.jpg   \n",
       "90         skateboard      sit_on        skateboard_001460.jpg   \n",
       "93               skis        jump              skis_002829.jpg   \n",
       "94               skis     pick_up              skis_001547.jpg   \n",
       "96          snowboard        hold         snowboard_001704.jpg   \n",
       "97          snowboard        jump         snowboard_001704.jpg   \n",
       "98        soccer_ball       catch       soccer_ball_003333.jpg   \n",
       "100          suitcase        drag          suitcase_002998.jpg   \n",
       "101          suitcase        hold          suitcase_003687.jpg   \n",
       "104          suitcase     pick_up          suitcase_002493.jpg   \n",
       "111     tennis_racket        hold     tennis_racket_001785.jpg   \n",
       "112     tennis_racket       swing     tennis_racket_003066.jpg   \n",
       "115        toothbrush        wash        toothbrush_001991.jpg   \n",
       "116        wine_glass  drink_with        wine_glass_003343.jpg   \n",
       "119        wine_glass         sip        wine_glass_003343.jpg   \n",
       "\n",
       "                                       output_sentence top_token_text  \\\n",
       "1    Based on the first image, the entire flesh of ...            the   \n",
       "3    Based on the first image, the sharp, curved bl...         curved   \n",
       "4    Based on the first image, the handle of the ax...            red   \n",
       "5    Based on the first image, the handle (or grip)...         handle   \n",
       "9    Based on the first image, the outer yellow ski...         yellow   \n",
       "15   Based on the first image, when people perform ...           gray   \n",
       "16   Based on the first image, when people perform ...           blue   \n",
       "17   Based on the first image, when people perform ...             by   \n",
       "19   Based on the first image, when people perform ...              a   \n",
       "20   Based on the first image, the part of the bicy...           seat   \n",
       "21   Based on the first image, the part of the bicy...            the   \n",
       "25   The mouth of the bottle is used for 'drink_wit...            the   \n",
       "27   Based on the first image, the top part of the ...          green   \n",
       "28   Based on the first image, the narrow, tapered ...           pink   \n",
       "29   Based on the first image, when people hold a b...          outer   \n",
       "30   Based on the first image, the top opening of t...         creamy   \n",
       "33   Based on the first image, the shutter button o...            the   \n",
       "37   Based on the first image, when people perform ...            the   \n",
       "39   Based on the first image, when people perform ...            the   \n",
       "40   Based on the first image, the part of the chai...           blue   \n",
       "42   Based on the first image, the main seating are...          three   \n",
       "46   Based on the first image, the rim of the cup i...            the   \n",
       "47   Based on the first image, when people perform ...      decorated   \n",
       "48   Based on the first image, the central metallic...       metallic   \n",
       "50   Based on the first image, the handle of the fo...         handle   \n",
       "53   Based on the first image, when people wash a f...            the   \n",
       "54   Based on the first image, the flat, circular s...           flat   \n",
       "55   Based on the first image, the frisbee is held ...           star   \n",
       "56   Based on the first image, the central, solid p...          solid   \n",
       "57   Based on the first image, the black, textured ...          black   \n",
       "60   Based on the first image, the handle of the ha...         handle   \n",
       "62   Based on the first image, the part of the jave...         yellow   \n",
       "65   Based on the first image, when people perform ...          black   \n",
       "68   Based on the first image, the keyboard is the ...       keyboard   \n",
       "69   Based on the first image, the beige handle loc...          beige   \n",
       "70   Based on the second image, when people push a ...           rear   \n",
       "71   Based on the first image, the part of the moto...            the   \n",
       "72   Based on the first image, the part of the moto...          black   \n",
       "79   Based on the first image, the main red and bla...            red   \n",
       "80   Based on the first image, the main body or fro...           Ever   \n",
       "81   Based on the first image, the left door of the...          water   \n",
       "82   When catching a rugby ball, people typically u...          green   \n",
       "83   Based on the first image, when people perform ...            the   \n",
       "85   The blades of the scissors are used for 'cut_w...            the   \n",
       "86   Based on the first image, the handles of the s...            the   \n",
       "88   Based on the first image, when people perform ...           deck   \n",
       "90   Based on the first image, the deck (the flat, ...         galaxy   \n",
       "93   When people perform a jump with skis, the enti...         length   \n",
       "94   Based on the first image, the top end (tip) of...              V   \n",
       "96   Based on the first image, the part of the snow...            top   \n",
       "97   Based on the first image, when people perform ...        central   \n",
       "98   Based on the first image, when people perform ...            the   \n",
       "100  Based on the first image, the part of the suit...           able   \n",
       "101  Based on the first image, the part of the suit...       extended   \n",
       "104  Based on the first image, people perform the '...            top   \n",
       "111  Based on the first image, the handle of the te...         handle   \n",
       "112  Based on the first image, the handle of the te...         handle   \n",
       "115  Based on the first image, the bristle head at ...            the   \n",
       "116  Based on the first image, the bowl of the wine...           bowl   \n",
       "119  Based on the first image, the bowl of the wine...           bowl   \n",
       "\n",
       "    following_text         clip_input       KLD       SIM       NSS  \n",
       "1            apple         the  apple  0.048497  0.878917  1.272056  \n",
       "3            blade      curved  blade  2.671174  0.101751 -0.233426  \n",
       "4              and           red  and  0.207951  0.750536  2.564849  \n",
       "5                (          handle  (  0.832631  0.456883  2.228246  \n",
       "9             skin       yellow  skin  1.416590  0.310270  0.906147  \n",
       "15         bedding      gray  bedding  0.217538  0.750239  2.923309  \n",
       "16              du           blue  du  0.570610  0.578344  1.676782  \n",
       "17            legs           by  legs  1.351450  0.378122  0.763257  \n",
       "19         bicycle         a  bicycle  2.785041  0.102958 -0.034037  \n",
       "20               ,             seat ,  0.920077  0.479077  1.575963  \n",
       "21         bicycle       the  bicycle  1.444522  0.298922  2.352401  \n",
       "25          bottle        the  bottle  1.713565  0.209257  1.697339  \n",
       "27             cap         green  cap  0.465599  0.625174  3.723509  \n",
       "28             cap          pink  cap  4.288736  0.057089 -0.262622  \n",
       "29             rim         outer  rim  0.231860  0.743596  0.891838  \n",
       "30        contents   creamy  contents  1.049518  0.481345  0.897744  \n",
       "33          camera        the  camera  0.734123  0.504208  0.377324  \n",
       "37           phone         the  phone  0.386950  0.647893  1.596167  \n",
       "39          screen        the  screen  0.923461  0.434130  1.338623  \n",
       "40             and          blue  and  1.021340  0.380349  0.647831  \n",
       "42         cushion     three  cushion  0.850645  0.446726  1.592862  \n",
       "46             cup           the  cup  0.364921  0.666311  1.084496  \n",
       "47            body    decorated  body  2.742813  0.115659 -0.133980  \n",
       "48             hub      metallic  hub  0.517178  0.592233  0.670623  \n",
       "50              of         handle  of  0.714619  0.505429  1.939612  \n",
       "53          entire        the  entire  0.959103  0.405269  2.154047  \n",
       "54               ,             flat ,  0.813959  0.470619 -0.086120  \n",
       "55         graphic      star  graphic  2.001801  0.210061 -0.518460  \n",
       "56         portion     solid  portion  0.702910  0.509880  0.376825  \n",
       "57               ,            black ,  0.765289  0.536735  1.662469  \n",
       "60              of         handle  of  0.978825  0.388227  2.500097  \n",
       "62        -colored    yellow -colored  0.195666  0.822492  3.632657  \n",
       "65          handle      black  handle  0.229159  0.769653  3.313839  \n",
       "68              is       keyboard  is  0.496758  0.599362  1.928662  \n",
       "69          handle      beige  handle  1.398069  0.307349  0.361574  \n",
       "70           wheel        rear  wheel  2.271270  0.164927  0.162561  \n",
       "71      motorcycle    the  motorcycle  0.826814  0.498427  1.739709  \n",
       "72               ,            black ,  1.637634  0.225825  1.842644  \n",
       "79             and           red  and  0.456583  0.628089  0.606045  \n",
       "80            last          Ever last  0.868119  0.443704  0.515587  \n",
       "81             and         water  and  2.198962  0.220247  0.188627  \n",
       "82               l           green  l  1.572308  0.385669  0.163138  \n",
       "83           rugby         the  rugby  0.218267  0.763812  0.942119  \n",
       "85        scissors      the  scissors  1.342794  0.287668  1.504042  \n",
       "86        scissors      the  scissors  0.739086  0.490557  1.373576  \n",
       "88              **            deck **  0.752420  0.563604  0.950367  \n",
       "90         pattern    galaxy  pattern  0.116484  0.834559  1.111620  \n",
       "93              of         length  of  2.136331  0.162259  0.053530  \n",
       "94              öl               V öl  4.551119  0.022544 -0.352152  \n",
       "96         surface       top  surface  1.838449  0.210843 -0.018791  \n",
       "97            area      central  area  1.031035  0.400117  0.215897  \n",
       "98            ball          the  ball  0.078484  0.868794  1.350087  \n",
       "100         telesc       able  telesc  1.272793  0.343482  4.448220  \n",
       "101         telesc   extended  telesc  1.292622  0.338115  2.007571  \n",
       "104         handle        top  handle  0.693142  0.556388  3.157528  \n",
       "111             of         handle  of  0.382704  0.656062  3.355089  \n",
       "112             of         handle  of  0.815831  0.478990  2.050146  \n",
       "115          tooth         the  tooth  1.682891  0.225198  1.094393  \n",
       "116             of           bowl  of  1.575323  0.240579  0.917182  \n",
       "119             of           bowl  of  1.573366  0.241423  0.933471  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analy[df_analy['clip_input'] != df_analy['object']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a9db57e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KLD    0.929405\n",
       "SIM    0.504299\n",
       "NSS    1.349262\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analy[df_analy['clip_input'] == df_analy['object']][['KLD','SIM','NSS']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a977e2fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KLD    1.222106\n",
       "SIM    0.443117\n",
       "NSS    1.227378\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analy[df_analy['clip_input'] != df_analy['object']][['KLD','SIM','NSS']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fc4a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_analy[df_analy['clip_input'] != df_analy['object']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1f5a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa1fb49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7b5666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Processing: eat - apple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Layer-wise attention maps for token: 'flesh' (Idx: 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving Layers for 'flesh': 100%|██████████| 64/64 [01:59<00:00,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved all layer maps and DataFrame to: ./output_layerhead_deep/viz_token_1_flesh\n",
      "DataFrame Head 미리보기:\n",
      "   Layer  Head  Attention_Sum  Layer_Total_Sum\n",
      "0      0     0       0.019457         2.554762\n",
      "1      0     1       0.070488         2.554762\n",
      "2      0     2       0.000568         2.554762\n",
      "3      0     3       0.040754         2.554762\n",
      "4      0     4       0.035283         2.554762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "metrics_tracker_alloutput = MetricsTracker(name=\"all_output\")\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 저장할 디렉토리 생성\n",
    "Layername = \"layerhead_deep\"\n",
    "output_dir = f\"./output_{Layername}\"  # 디렉토리 이름 변경 (구분 위해)s\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Contrastive Subtraction 강도 설정 (0.5 ~ 1.0 추천)\n",
    "\n",
    "POS_ALPHA = 0\n",
    "\n",
    "for i in range(1):\n",
    "    i += 1\n",
    "    pkl_path = f\"output_results/attention_result_full_output_32B_{i}.pkl\"\n",
    "    if not os.path.exists(pkl_path):\n",
    "        continue\n",
    "        \n",
    "    df_output = pd.read_pickle(pkl_path)\n",
    "\n",
    "    row = df_output.iloc[1]\n",
    "\n",
    "\n",
    "    object_name = row['object']\n",
    "    action = row['action']\n",
    "    filename = row['filename']\n",
    "    output_description = row['output_sentence']\n",
    "    output_attentions = row['output_attentions']\n",
    "    \n",
    "    file_name_real = f\"{AGD20K_PATH}/Seen/testset/egocentric/{action}/{object_name}/{filename}\"\n",
    "    gt_path = f\"{AGD20K_PATH}/Seen/testset/GT/{action}/{object_name}/{filename.split('.')[0]}.png\"\n",
    "        \n",
    "    # 이미지 로드\n",
    "    if not os.path.exists(file_name_real):\n",
    "        print(f\"Image not found: {file_name_real}\")\n",
    "        continue\n",
    "\n",
    "    orig_img = cv2.imread(file_name_real)\n",
    "    orig_img = cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB)\n",
    "    h, w, _ = orig_img.shape\n",
    "\n",
    "    print(f\"[Processing: {action} - {object_name}\")\n",
    "\n",
    "    # --- 1. CLIPSeg Mask 생성 ---\n",
    "\n",
    "    clip_heatmap = get_clipseg_heatmap(\n",
    "        file_name_real,\n",
    "        clip_model,\n",
    "        clip_processor,\n",
    "        object_name,\n",
    "    )\n",
    "\n",
    "    # CLIPSeg 결과를 31x31로 리사이즈\n",
    "    clip_heatmap_resized = cv2.resize(clip_heatmap, (31, 31), interpolation=cv2.INTER_LINEAR)\n",
    "    clip_binary_mask = (clip_heatmap_resized > 0.15).astype(np.float32) # 필요시 사용\n",
    "\n",
    "    # --- 2. [변경] Contrastive Attention Map 계산 ---\n",
    "    token_scores = []\n",
    "    token_idx = 0\n",
    "    for token in output_attentions:\n",
    "        # 토큰별 히트맵 초기화\n",
    "        token_heatmap = np.zeros((31, 31), dtype=np.float32)\n",
    "        token_head_count = 0\n",
    "        \n",
    "        attention_value = token['attentions']\n",
    "        decoded_str = token['token_str'] # 디버깅용\n",
    "\n",
    "        for each_attention in attention_value:\n",
    "            layer = each_attention['layer']\n",
    "            head = each_attention['head']\n",
    "            \n",
    "            # # 사용자가 설정한 특정 레이어 필터링 (여기선 Layer 0 유지)\n",
    "            # if each_attention['layer'] != 0:\n",
    "            if 1==1: # (layer <=45) and (layer >= 20): #1==1: # (layer == 26) : #and( head ==20)) : #or ((layer == 24) and( head ==31)):\n",
    "                \n",
    "                token_heatmap += each_attention['heatmap']\n",
    "                token_head_count += 1\n",
    "\n",
    "        \n",
    "        # 해당 레이어의 헤드가 하나도 없으면 스킵\n",
    "        if token_head_count == 0:\n",
    "            continue\n",
    "\n",
    "        # Visual Dependency Score (S_img) 계산: 맵의 총합\n",
    "        s_img = token_heatmap.sum()\n",
    "\n",
    "        # 리스트에 저장\n",
    "        token_scores.append({\n",
    "            \"token\": decoded_str,\n",
    "            \"token_idx\" : token_idx,\n",
    "            \"score\": s_img,\n",
    "            \"heatmap\": token_heatmap, \n",
    "            \"count\": token_head_count\n",
    "        })\n",
    "        token_idx +=1\n",
    "    # 예외 처리: 토큰이 없을 경우\n",
    "    if len(token_scores) == 0:\n",
    "        print(\"No valid tokens found.\")\n",
    "        continue\n",
    "\n",
    "    # 정렬 (Score 기준 오름차순)\n",
    "    sorted_tokens = sorted(token_scores, key=lambda x: x['score'])\n",
    "    \n",
    "    # Top 5 (Signal) & Bottom 5 (Noise) 선정\n",
    "    # 토큰 개수가 10개 미만일 경우 처리\n",
    "    num_select = min(1, len(sorted_tokens) // 2)\n",
    "    if num_select < 1: num_select = 1 # 최소 1개\n",
    "\n",
    "    bottom_tokens = sorted_tokens[:num_select]       # Noise (기능어, 배경 등)\n",
    "    top_tokens = sorted_tokens[-num_select:][::-1]   # Signal (명사, 핵심어)\n",
    "    ## 꺼꾸로 last 뽑기\n",
    "\n",
    "\n",
    "    # Signal Map (Positive) 평균\n",
    "    pos_map = np.sum([t['heatmap'] for t in top_tokens], axis=0)\n",
    "    pos_map /= len(top_tokens)\n",
    "    top_token_idx  = top_tokens[-1]['token_idx']\n",
    "    top_token_text  = top_tokens[-1]['token']\n",
    "\n",
    "    # --- 모든 레이어/헤드 어텐션 저장 로직 ---\n",
    "\n",
    "    # 1. 대상 토큰 데이터 추출 (Top 1 토큰)\n",
    "    target_token_info = top_tokens[-1] \n",
    "    target_token_str = target_token_info['token'].strip()\n",
    "    target_token_idx = target_token_info['token_idx']\n",
    "\n",
    "\n",
    "    # ... (위쪽 코드: target_token_idx, target_token_str 추출 부분) ...\n",
    "    \n",
    "    print(f\"Generating Layer-wise attention maps for token: '{target_token_str}' (Idx: {target_token_idx})\")\n",
    "\n",
    "    # --- [추가] 모든 Layer/Head Attention 시각화 저장 로직 ---\n",
    "\n",
    "    # 1. 저장할 서브 디렉토리 생성\n",
    "    # 파일명에 겹치지 않게 토큰 인덱스와 텍스트를 포함\n",
    "    safe_token_str = \"\".join([c if c.isalnum() else \"_\" for c in target_token_str])\n",
    "    vis_save_dir = os.path.join(output_dir, f\"viz_token_{target_token_idx}_{safe_token_str}\")\n",
    "    os.makedirs(vis_save_dir, exist_ok=True)\n",
    "\n",
    "    # 2. 해당 토큰의 모든 어텐션 데이터 수집 및 레이어별 분류\n",
    "    # output_attentions[target_token_idx]는 해당 토큰 위치의 정보라고 가정\n",
    "    # 만약 output_attentions가 토큰들의 리스트라면 아래와 같이 접근\n",
    "    target_token_data = output_attentions[target_token_idx]\n",
    "    \n",
    "    # 레이어별로 Head 정보를 모음: { layer_idx: [ {head: h, heatmap: map}, ... ] }\n",
    "    layer_wise_attentions = {}\n",
    "    \n",
    "    for attn_item in target_token_data['attentions']:\n",
    "        ly = attn_item['layer']\n",
    "        hd = attn_item['head']\n",
    "        hm = attn_item['heatmap']\n",
    "        \n",
    "        if ly not in layer_wise_attentions:\n",
    "            layer_wise_attentions[ly] = []\n",
    "        layer_wise_attentions[ly].append({'head': hd, 'heatmap': hm})\n",
    "\n",
    " # ... (이전 데이터 수집 단계 코드는 동일) ...\n",
    "\n",
    "# ... (이전 코드: target_token_str 추출, 디렉토리 생성 등) ...\n",
    "\n",
    "    # [추가 1] 데이터를 모을 리스트 초기화\n",
    "    att_data_list = []\n",
    "\n",
    "    # 3. 레이어별 루프를 돌며 이미지 생성 및 데이터 수집\n",
    "    sorted_layers = sorted(layer_wise_attentions.keys())\n",
    "    \n",
    "    for ly in tqdm(sorted_layers, desc=f\"Saving Layers for '{target_token_str}'\"):\n",
    "        heads_data = layer_wise_attentions[ly]\n",
    "        \n",
    "        # Head 번호 순서대로 정렬\n",
    "        heads_data.sort(key=lambda x: x['head'])\n",
    "        \n",
    "        num_heads = len(heads_data)\n",
    "        if num_heads == 0: continue\n",
    "\n",
    "        # 해당 레이어의 전체 Attention Score 합계 계산\n",
    "        layer_total_score = sum([h['heatmap'].sum() for h in heads_data])\n",
    "\n",
    "        # 격자 크기 계산\n",
    "        grid_size = int(np.ceil(np.sqrt(num_heads)))\n",
    "        \n",
    "        # 캔버스 생성\n",
    "        fig, axes = plt.subplots(grid_size, grid_size, figsize=(20, 20))\n",
    "        fig.suptitle(\n",
    "            f\"Token: '{target_token_str}' (Idx: {target_token_idx}) - Layer {ly}\\n\"\n",
    "            f\"Layer Total Attention Sum: {layer_total_score:.4f}\", \n",
    "            fontsize=24\n",
    "        )\n",
    "        \n",
    "        if isinstance(axes, np.ndarray):\n",
    "            axes_flat = axes.flatten()\n",
    "        else:\n",
    "            axes_flat = [axes]\n",
    "            \n",
    "        # 각 Head별 처리\n",
    "        for i, ax in enumerate(axes_flat):\n",
    "            if i < num_heads:\n",
    "                head_info = heads_data[i]\n",
    "                h_idx = head_info['head']\n",
    "                h_map = head_info['heatmap']\n",
    "                \n",
    "                # 개별 Head Score 계산\n",
    "                head_score = h_map.sum()\n",
    "                \n",
    "                # [추가 2] 리스트에 데이터 추가 (Layer, Head, Attention Sum)\n",
    "                att_data_list.append({\n",
    "                    'Layer': ly,\n",
    "                    'Head': h_idx,\n",
    "                    'Attention_Sum': head_score,\n",
    "                    'Layer_Total_Sum': layer_total_score  # 필요 시 레이어 총합도 함께 저장\n",
    "                })\n",
    "\n",
    "                # 시각화\n",
    "                im = ax.imshow(h_map, cmap='viridis', interpolation='nearest')\n",
    "                ax.set_title(f\"Head {h_idx}\\nSum: {head_score:.2f}\", fontsize=10)\n",
    "                ax.axis('off')\n",
    "            else:\n",
    "                ax.axis('off')\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.93])\n",
    "        save_path = os.path.join(vis_save_dir, f\"layer_{ly:03d}.png\")\n",
    "        plt.savefig(save_path)\n",
    "        plt.close(fig) \n",
    "\n",
    "    # [추가 3] DataFrame 생성 및 저장\n",
    "    df_att = pd.DataFrame(att_data_list)\n",
    "    \n",
    "    # 보기 좋게 컬럼 순서 정렬 (Layer -> Head -> Sum)\n",
    "    df_att = df_att[['Layer', 'Head', 'Attention_Sum', 'Layer_Total_Sum']]\n",
    "    \n",
    "    # CSV 파일로 저장\n",
    "    csv_path = os.path.join(vis_save_dir, \"attention_sums.csv\")\n",
    "    df_att.to_csv(csv_path, index=False)\n",
    "\n",
    "    print(f\"Saved all layer maps and DataFrame to: {vis_save_dir}\")\n",
    "    print(\"DataFrame Head 미리보기:\")\n",
    "    print(df_att.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c37288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Layer\n",
       "20    0.376303\n",
       "23    0.566991\n",
       "1     0.760726\n",
       "10    0.854804\n",
       "9     0.889243\n",
       "        ...   \n",
       "50    8.005047\n",
       "45    8.019423\n",
       "17    8.284877\n",
       "46    8.924697\n",
       "41    9.288528\n",
       "Name: Attention_Sum, Length: 64, dtype: float32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_att.groupby(['Layer'])['Attention_Sum'].sum().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767dc381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer</th>\n",
       "      <th>Head</th>\n",
       "      <th>Attention_Sum</th>\n",
       "      <th>Layer_Total_Sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>1.028297e-08</td>\n",
       "      <td>0.376303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>20</td>\n",
       "      <td>58</td>\n",
       "      <td>1.797992e-07</td>\n",
       "      <td>0.376303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>2.148592e-07</td>\n",
       "      <td>0.376303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>20</td>\n",
       "      <td>27</td>\n",
       "      <td>2.576361e-07</td>\n",
       "      <td>0.376303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>3.766697e-07</td>\n",
       "      <td>0.376303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>20</td>\n",
       "      <td>53</td>\n",
       "      <td>2.764578e-02</td>\n",
       "      <td>0.376303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>20</td>\n",
       "      <td>31</td>\n",
       "      <td>3.363384e-02</td>\n",
       "      <td>0.376303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>20</td>\n",
       "      <td>62</td>\n",
       "      <td>3.683291e-02</td>\n",
       "      <td>0.376303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1325</th>\n",
       "      <td>20</td>\n",
       "      <td>45</td>\n",
       "      <td>4.368176e-02</td>\n",
       "      <td>0.376303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322</th>\n",
       "      <td>20</td>\n",
       "      <td>42</td>\n",
       "      <td>5.164818e-02</td>\n",
       "      <td>0.376303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Layer  Head  Attention_Sum  Layer_Total_Sum\n",
       "1302     20    22   1.028297e-08         0.376303\n",
       "1338     20    58   1.797992e-07         0.376303\n",
       "1304     20    24   2.148592e-07         0.376303\n",
       "1307     20    27   2.576361e-07         0.376303\n",
       "1291     20    11   3.766697e-07         0.376303\n",
       "...     ...   ...            ...              ...\n",
       "1333     20    53   2.764578e-02         0.376303\n",
       "1311     20    31   3.363384e-02         0.376303\n",
       "1342     20    62   3.683291e-02         0.376303\n",
       "1325     20    45   4.368176e-02         0.376303\n",
       "1322     20    42   5.164818e-02         0.376303\n",
       "\n",
       "[64 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_att[df_att['Layer']==20].sort_values(\"Attention_Sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bace41e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer</th>\n",
       "      <th>Head</th>\n",
       "      <th>Attention_Sum</th>\n",
       "      <th>Layer_Total_Sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019457</td>\n",
       "      <td>2.554762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.070488</td>\n",
       "      <td>2.554762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>2.554762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.040754</td>\n",
       "      <td>2.554762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.035283</td>\n",
       "      <td>2.554762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4091</th>\n",
       "      <td>63</td>\n",
       "      <td>59</td>\n",
       "      <td>0.052509</td>\n",
       "      <td>2.854838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4092</th>\n",
       "      <td>63</td>\n",
       "      <td>60</td>\n",
       "      <td>0.032250</td>\n",
       "      <td>2.854838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4093</th>\n",
       "      <td>63</td>\n",
       "      <td>61</td>\n",
       "      <td>0.033217</td>\n",
       "      <td>2.854838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4094</th>\n",
       "      <td>63</td>\n",
       "      <td>62</td>\n",
       "      <td>0.092705</td>\n",
       "      <td>2.854838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4095</th>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>0.363023</td>\n",
       "      <td>2.854838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4096 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Layer  Head  Attention_Sum  Layer_Total_Sum\n",
       "0         0     0       0.019457         2.554762\n",
       "1         0     1       0.070488         2.554762\n",
       "2         0     2       0.000568         2.554762\n",
       "3         0     3       0.040754         2.554762\n",
       "4         0     4       0.035283         2.554762\n",
       "...     ...   ...            ...              ...\n",
       "4091     63    59       0.052509         2.854838\n",
       "4092     63    60       0.032250         2.854838\n",
       "4093     63    61       0.033217         2.854838\n",
       "4094     63    62       0.092705         2.854838\n",
       "4095     63    63       0.363023         2.854838\n",
       "\n",
       "[4096 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_att"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
