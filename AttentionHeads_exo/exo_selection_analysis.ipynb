{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b351283e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/DATA/AGD20K'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from pathlib import Path\n",
    "from scipy.stats import pearsonr\n",
    "from transformers import CLIPSegProcessor, CLIPSegForImageSegmentation\n",
    "\n",
    "clip_processor = CLIPSegProcessor.from_pretrained(\"CIDAS/clipseg-rd64-refined\")\n",
    "clip_model = CLIPSegForImageSegmentation.from_pretrained(\"CIDAS/clipseg-rd64-refined\")\n",
    "\n",
    "import os\n",
    "import sys\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(parent_dir)\n",
    "from config import AGD20K_PATH, model_name\n",
    "\n",
    "from VLM_model_dot_relative import MetricsTracker\n",
    "from file_managing import (\n",
    "    load_selected_samples,\n",
    "    get_actual_path,\n",
    "    get_gt_path,\n",
    "    load_ground_truth,\n",
    "    prompt_dict_obj,\n",
    "    get_clipseg_heatmap,\n",
    "    calculate_metrics,\n",
    "    prompt_dict_obj\n",
    ")\n",
    "\n",
    "def min_max_normalize(arr):\n",
    "    denom = arr.max() - arr.min()\n",
    "    if denom == 0:\n",
    "        return np.zeros_like(arr)\n",
    "    return (arr - arr.min()) / (denom + 1e-8)\n",
    "\n",
    "\n",
    "\n",
    "from transformers import Qwen3VLForConditionalGeneration, AutoProcessor\n",
    "model_name= f\"Qwen/Qwen3-VL-32B-Instruct\"\n",
    "processor = AutoProcessor.from_pretrained(model_name)\n",
    "tok = processor.tokenizer\n",
    "\n",
    "AGD20K_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75cd8797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def check_heatmap_containment(heatmap_top, heatmap_obj, threshold=0.15, containment_ratio=0.8):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        containment_ratio (float): Top 영역의 몇 % 이상이 Obj와 겹쳐야 포함으로 볼 것인지 (기본 0.9 = 90%)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. 텐서인 경우 numpy 변환\n",
    "    if hasattr(heatmap_top, 'cpu'):\n",
    "        heatmap_top = heatmap_top.detach().cpu().numpy()\n",
    "    if hasattr(heatmap_obj, 'cpu'):\n",
    "        heatmap_obj = heatmap_obj.detach().cpu().numpy()\n",
    "\n",
    "    # 2. 이진 마스크 생성\n",
    "    mask_top = heatmap_top > threshold\n",
    "    mask_obj = heatmap_obj > threshold\n",
    "\n",
    "    # 3. 면적 계산\n",
    "    area_top = np.sum(mask_top)\n",
    "    area_obj = np.sum(mask_obj)\n",
    "\n",
    "    # 예외 처리: Top 히트맵이 아예 활성화되지 않은 경우 (면적 0)\n",
    "    if area_top == 0:\n",
    "        return False\n",
    "\n",
    "    # 조건 1: Top의 면적이 Object 면적보다 작은가?\n",
    "    is_smaller = area_top < area_obj\n",
    "    \n",
    "    # 4. 포함 관계 확인 (수정된 부분)\n",
    "    # 교집합(Intersection) 영역 계산\n",
    "    intersection = np.logical_and(mask_top, mask_obj)\n",
    "    intersection_area = np.sum(intersection)\n",
    "\n",
    "    # [수정됨] 교집합 면적이 Top 전체 면적의 90% 이상인지 확인\n",
    "    # (intersection_area / area_top) >= 0.9 와 동일한 수식입니다.\n",
    "    is_inside = intersection_area >= (area_top * containment_ratio)\n",
    "\n",
    "    # 디버깅용: 실제 겹치는 비율 확인\n",
    "    # print(f\"Overlap Ratio: {intersection_area / area_top:.2f}\")\n",
    "\n",
    "    return is_smaller and is_inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ab1cad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exo_name : hold_axe_000384.jpg\n",
      "[0] Processing: hold - axe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/transformers/image_processing_utils.py:51: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CLIP input :  red\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output axe_001552.jpg:\n",
      " all_output Current - KLD: 0.2122 | SIM: 0.7477 | NSS: 2.5619\n",
      "\n",
      "Cumulative all_output  Averages over 1 samples:\n",
      "Average - KLD: 0.2122 | SIM: 0.7477 | NSS: 2.5619\n",
      "==================================================\n",
      "\n",
      "exo_name : hold_axe_000856.jpg\n",
      "[1] Processing: hold - axe\n",
      "Selected CLIP input :  red\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output axe_001552.jpg:\n",
      " all_output Current - KLD: 0.2113 | SIM: 0.7490 | NSS: 2.5699\n",
      "\n",
      "Cumulative all_output  Averages over 2 samples:\n",
      "Average - KLD: 0.2118 | SIM: 0.7484 | NSS: 2.5659\n",
      "==================================================\n",
      "\n",
      "exo_name : hold_axe_001123.jpg\n",
      "[2] Processing: hold - axe\n",
      "Selected CLIP input :  red\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output axe_001552.jpg:\n",
      " all_output Current - KLD: 0.2118 | SIM: 0.7482 | NSS: 2.5682\n",
      "\n",
      "Cumulative all_output  Averages over 3 samples:\n",
      "Average - KLD: 0.2118 | SIM: 0.7483 | NSS: 2.5667\n",
      "==================================================\n",
      "\n",
      "exo_name : hold_axe_003505.jpg\n",
      "[3] Processing: hold - axe\n",
      "Selected CLIP input :  red\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output axe_001552.jpg:\n",
      " all_output Current - KLD: 0.2136 | SIM: 0.7460 | NSS: 2.5551\n",
      "\n",
      "Cumulative all_output  Averages over 4 samples:\n",
      "Average - KLD: 0.2122 | SIM: 0.7477 | NSS: 2.5638\n",
      "==================================================\n",
      "\n",
      "exo_name : hold_axe_006372.jpg\n",
      "[4] Processing: hold - axe\n",
      "Selected CLIP input :  red\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output axe_001552.jpg:\n",
      " all_output Current - KLD: 0.2090 | SIM: 0.7493 | NSS: 2.5671\n",
      "\n",
      "Cumulative all_output  Averages over 5 samples:\n",
      "Average - KLD: 0.2116 | SIM: 0.7481 | NSS: 2.5644\n",
      "==================================================\n",
      "\n",
      "exo_name : hold_axe_006509.jpg\n",
      "[5] Processing: hold - axe\n",
      "Selected CLIP input :  red\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output axe_001552.jpg:\n",
      " all_output Current - KLD: 0.2143 | SIM: 0.7457 | NSS: 2.5546\n",
      "\n",
      "Cumulative all_output  Averages over 6 samples:\n",
      "Average - KLD: 0.2120 | SIM: 0.7477 | NSS: 2.5628\n",
      "==================================================\n",
      "\n",
      "exo_name : hold_axe_006933.jpg\n",
      "[6] Processing: hold - axe\n",
      "Selected CLIP input :  red\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output axe_001552.jpg:\n",
      " all_output Current - KLD: 0.2123 | SIM: 0.7469 | NSS: 2.5551\n",
      "\n",
      "Cumulative all_output  Averages over 7 samples:\n",
      "Average - KLD: 0.2121 | SIM: 0.7476 | NSS: 2.5617\n",
      "==================================================\n",
      "\n",
      "exo_name : hold_axe_008102.jpg\n",
      "[7] Processing: hold - axe\n",
      "Selected CLIP input :  red\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output axe_001552.jpg:\n",
      " all_output Current - KLD: 0.2085 | SIM: 0.7502 | NSS: 2.5669\n",
      "\n",
      "Cumulative all_output  Averages over 8 samples:\n",
      "Average - KLD: 0.2116 | SIM: 0.7479 | NSS: 2.5623\n",
      "==================================================\n",
      "\n",
      "exo_name : hold_axe_008636.jpg\n",
      "[8] Processing: hold - axe\n",
      "Selected CLIP input :  red\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output axe_001552.jpg:\n",
      " all_output Current - KLD: 0.2077 | SIM: 0.7510 | NSS: 2.5691\n",
      "\n",
      "Cumulative all_output  Averages over 9 samples:\n",
      "Average - KLD: 0.2112 | SIM: 0.7482 | NSS: 2.5631\n",
      "==================================================\n",
      "\n",
      "exo_name : hold_axe_009211.jpg\n",
      "[9] Processing: hold - axe\n",
      "Selected CLIP input :  red\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output axe_001552.jpg:\n",
      " all_output Current - KLD: 0.2076 | SIM: 0.7515 | NSS: 2.5760\n",
      "\n",
      "Cumulative all_output  Averages over 10 samples:\n",
      "Average - KLD: 0.2108 | SIM: 0.7486 | NSS: 2.5644\n",
      "==================================================\n",
      "\n",
      "exo_name : hold_axe_009894.jpg\n",
      "[10] Processing: hold - axe\n",
      "Selected CLIP input :  red\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output axe_001552.jpg:\n",
      " all_output Current - KLD: 0.2236 | SIM: 0.7391 | NSS: 2.5383\n",
      "\n",
      "Cumulative all_output  Averages over 11 samples:\n",
      "Average - KLD: 0.2120 | SIM: 0.7477 | NSS: 2.5620\n",
      "==================================================\n",
      "\n",
      "exo_name : hold_axe_010133.jpg\n",
      "[11] Processing: hold - axe\n",
      "Selected CLIP input :  black\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output axe_001552.jpg:\n",
      " all_output Current - KLD: 0.6713 | SIM: 0.5435 | NSS: 1.9507\n",
      "\n",
      "Cumulative all_output  Averages over 12 samples:\n",
      "Average - KLD: 0.2503 | SIM: 0.7307 | NSS: 2.5111\n",
      "==================================================\n",
      "\n",
      "exo_name : hold_axe_011424.jpg\n",
      "[12] Processing: hold - axe\n",
      "Selected CLIP input :  red\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output axe_001552.jpg:\n",
      " all_output Current - KLD: 0.2075 | SIM: 0.7535 | NSS: 2.5870\n",
      "\n",
      "Cumulative all_output  Averages over 13 samples:\n",
      "Average - KLD: 0.2470 | SIM: 0.7324 | NSS: 2.5169\n",
      "==================================================\n",
      "\n",
      "exo_name : hold_axe_011805.jpg\n",
      "[13] Processing: hold - axe\n",
      "Selected CLIP input :  red\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output axe_001552.jpg:\n",
      " all_output Current - KLD: 0.2133 | SIM: 0.7457 | NSS: 2.5559\n",
      "\n",
      "Cumulative all_output  Averages over 14 samples:\n",
      "Average - KLD: 0.2446 | SIM: 0.7334 | NSS: 2.5197\n",
      "==================================================\n",
      "\n",
      "exo_name : hold_axe_012581.jpg\n",
      "[14] Processing: hold - axe\n",
      "Selected CLIP input :  red\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output axe_001552.jpg:\n",
      " all_output Current - KLD: 0.2076 | SIM: 0.7510 | NSS: 2.5664\n",
      "\n",
      "Cumulative all_output  Averages over 15 samples:\n",
      "Average - KLD: 0.2421 | SIM: 0.7346 | NSS: 2.5228\n",
      "==================================================\n",
      "\n",
      "exo_name : hold_axe_012759.jpg\n",
      "[15] Processing: hold - axe\n",
      "Selected CLIP input :  red\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output axe_001552.jpg:\n",
      " all_output Current - KLD: 0.2151 | SIM: 0.7445 | NSS: 2.5512\n",
      "\n",
      "Cumulative all_output  Averages over 16 samples:\n",
      "Average - KLD: 0.2404 | SIM: 0.7352 | NSS: 2.5246\n",
      "==================================================\n",
      "\n",
      "exo_name : hold_axe_013837.jpg\n",
      "[16] Processing: hold - axe\n",
      "Selected CLIP input :  red\n",
      "\n",
      "==================================================\n",
      "Metrics for all_output axe_001552.jpg:\n",
      " all_output Current - KLD: 0.2080 | SIM: 0.7516 | NSS: 2.5728\n",
      "\n",
      "Cumulative all_output  Averages over 17 samples:\n",
      "Average - KLD: 0.2385 | SIM: 0.7362 | NSS: 2.5274\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics_tracker_alloutput = MetricsTracker(name=\"all_output\")\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 저장할 디렉토리 생성\n",
    "Layername = \"selection_hold_axe\"\n",
    "output_dir = f\"./exo_{Layername}\"  # 디렉토리 이름 변경 (구분 위해)s\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Contrastive Subtraction 강도 설정 (0.5 ~ 1.0 추천)\n",
    "patch_size = 24\n",
    "POS_ALPHA = 0\n",
    "results_list = []\n",
    "pos_map = np.zeros((patch_size, patch_size), dtype=np.float32)\n",
    "\n",
    "pkl_path = f\"output_exo_selection/exo_sample_32B_hold_axe.pkl\"\n",
    "if not os.path.exists(pkl_path):\n",
    "    raise FileNotFoundError(f\"File not found: {pkl_path}\")\n",
    "    \n",
    "df_output = pd.read_pickle(pkl_path)\n",
    "\n",
    "for idx, row in df_output.iterrows():\n",
    "    object_name = row['object']\n",
    "    action = row['action']\n",
    "    filename = row['filename']\n",
    "    output_description = row['output_sentence']\n",
    "    output_attentions = row['output_attentions']\n",
    "    PLSP_name = prompt_dict_obj[action][object_name]\n",
    "    exo_name =  os.path.basename(row['exo_filename'])\n",
    "    print(f\"exo_name : {exo_name}\")\n",
    "    exo_base_path = Path(f\"{AGD20K_PATH}/Seen/trainset/exocentric/{action}/{object_name}/{exo_name}\")\n",
    "\n",
    "    sum_heatmap = np.zeros((patch_size, patch_size), dtype=np.float32)\n",
    "    \n",
    "    exo_img = cv2.imread(str(exo_base_path))\n",
    "    exo_img = cv2.cvtColor(exo_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    \n",
    "    file_name_real = f\"{AGD20K_PATH}/Seen/testset/egocentric/{action}/{object_name}/{filename}\"\n",
    "    gt_path = f\"{AGD20K_PATH}/Seen/testset/GT/{action}/{object_name}/{filename.split('.')[0]}.png\"\n",
    "        \n",
    "    # 이미지 로드\n",
    "    if not os.path.exists(file_name_real):\n",
    "        print(f\"Image not found: {file_name_real}\")\n",
    "        continue\n",
    "\n",
    "    orig_img = cv2.imread(file_name_real)\n",
    "    orig_img = cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB)\n",
    "    h, w, _ = orig_img.shape\n",
    "\n",
    "    print(f\"[{idx}] Processing: {action} - {object_name}\")\n",
    "\n",
    "    # --- 2. [변경] Contrastive Attention Map 계산 ---\n",
    "    token_scores = []\n",
    "    token_idx = 0\n",
    "    for token in output_attentions:\n",
    "        # 토큰별 히트맵 초기화\n",
    "        token_heatmap = np.zeros((patch_size, patch_size), dtype=np.float32)\n",
    "        token_head_count = 0\n",
    "        \n",
    "        attention_value = token['attentions']\n",
    "        decoded_str = token['token_str'] # 디버깅용\n",
    "\n",
    "        for each_attention in attention_value:\n",
    "            layer = each_attention['layer']\n",
    "            head = each_attention['head']\n",
    "            \n",
    "            # # 사용자가 설정한 특정 레이어 필터링 (여기선 Layer 0 유지)\n",
    "            # if each_attention['layer'] != 0:\n",
    "            if 1==1: # (layer <=45) and (layer >= 20): #1==1: # (layer == 26) : #and( head ==20)) : #or ((layer == 24) and( head ==31)):\n",
    "                sum_heatmap += each_attention['heatmap']\n",
    "                token_heatmap += each_attention['heatmap']\n",
    "                token_head_count += 1\n",
    "\n",
    "        \n",
    "        # 해당 레이어의 헤드가 하나도 없으면 스킵\n",
    "        if token_head_count == 0:\n",
    "            continue\n",
    "\n",
    "        # Visual Dependency Score (S_img) 계산: 맵의 총합\n",
    "        s_img = token_heatmap.sum()\n",
    "\n",
    "        # 리스트에 저장\n",
    "        token_scores.append({\n",
    "            \"token\": decoded_str,\n",
    "            \"token_idx\" : token_idx,\n",
    "            \"score\": s_img,\n",
    "            \"heatmap\": token_heatmap, \n",
    "            \"count\": token_head_count\n",
    "        })\n",
    "        token_idx +=1\n",
    "    # 예외 처리: 토큰이 없을 경우\n",
    "    if len(token_scores) == 0:\n",
    "        print(\"No valid tokens found.\")\n",
    "        continue\n",
    "\n",
    "    # 정렬 (Score 기준 오름차순)\n",
    "    sorted_tokens = sorted(token_scores, key=lambda x: x['score'])\n",
    "    \n",
    "    # Top 5 (Signal) & Bottom 5 (Noise) 선정\n",
    "    # 토큰 개수가 10개 미만일 경우 처리\n",
    "    num_select = min(1, len(sorted_tokens) // 2)\n",
    "    if num_select < 1: num_select = 1 # 최소 1개\n",
    "\n",
    "    bottom_tokens = sorted_tokens[:num_select]       # Noise (기능어, 배경 등)\n",
    "    top_tokens = sorted_tokens[-num_select:][::-1]   # Signal (명사, 핵심어)\n",
    "\n",
    "    top_token_idx  = top_tokens[-1]['token_idx']\n",
    "    top_token_text  = top_tokens[-1]['token']\n",
    "\n",
    "    following_token_idx = top_token_idx + 1\n",
    "    following_token = None\n",
    "    for item in token_scores:\n",
    "        if item['token_idx'] == following_token_idx:\n",
    "            following_token = item\n",
    "            break\n",
    "    following_text = following_token['token']\n",
    "\n",
    "    clip_object_heatmap = get_clipseg_heatmap(\n",
    "        file_name_real,\n",
    "        clip_model,\n",
    "        clip_processor,\n",
    "        object_name,\n",
    "    )\n",
    "\n",
    "    clip_top_heatmap = get_clipseg_heatmap(\n",
    "        file_name_real,\n",
    "        clip_model,\n",
    "        clip_processor,\n",
    "        top_token_text + ' ' + following_text,\n",
    "    )\n",
    "    pos_map = np.sum([t['heatmap'] for t in top_tokens], axis=0)\n",
    "    pos_map /= len(top_tokens)\n",
    "    \n",
    "    # Noise Map (Negative) 평균\n",
    "    neg_map = np.sum([t['heatmap'] for t in bottom_tokens], axis=0)\n",
    "    neg_map /= len(bottom_tokens)\n",
    "\n",
    "\n",
    "\n",
    "    # 정규화 (스케일 맞추기 위해 0~1로 변환 후 뺄셈 진행)\n",
    "    if pos_map.max() > 0: pos_map /= pos_map.max()\n",
    "    if neg_map.max() > 0: neg_map /= neg_map.max()\n",
    "\n",
    "    # ✨ Contrastive Subtraction (Signal - alpha * Noise)\n",
    "    CONTRASTIVE_ALPHA = 0\n",
    "    contrastive_heatmap = (pos_map) - (CONTRASTIVE_ALPHA * neg_map)\n",
    "    # contrastive_heatmap = sum_heatmap / (token_head_count + 1e-8)\n",
    "    # --- 3. 정규화 및 후처리 (기존 코드 흐름 연결) ---\n",
    "    # Contrastive Map을 avg_norm 변수로 사용 (0~1 정규화)\n",
    "    h_min, h_max = contrastive_heatmap.min(), contrastive_heatmap.max()\n",
    "\n",
    "    \n",
    "    avg_norm = (contrastive_heatmap - h_min) / (h_max - h_min + 1e-8)\n",
    "\n",
    "    if check_heatmap_containment(clip_top_heatmap,clip_object_heatmap):\n",
    "        clip_heatmap = clip_top_heatmap\n",
    "        clipseg_input_text = top_token_text+ ' ' + following_text\n",
    "        print(f\"Selected CLIP input : {top_token_text}\")\n",
    "        # Signal Map (Positive) 평균\n",
    "\n",
    "\n",
    "\n",
    "    else:\n",
    "        clip_heatmap = clip_object_heatmap\n",
    "        clipseg_input_text = object_name\n",
    "        # h_min, h_max = token_heatmap.min(), token_heatmap.max()\n",
    "        # avg_norm = (token_heatmap - h_min) / (h_max - h_min + 1e-8)\n",
    "\n",
    "        print(f\"Selected CLIP input : {object_name}\")\n",
    "\n",
    "    clip_heatmap_resized = cv2.resize(clip_heatmap, (patch_size, patch_size), interpolation=cv2.INTER_LINEAR)\n",
    "    clip_binary_mask = (clip_heatmap_resized > 0.15).astype(np.float32) # 필요시 사용\n",
    "\n",
    "\n",
    "    # CLIPSeg와 Hadamard Product\n",
    "    avg_norm_cliped = avg_norm * clip_heatmap_resized\n",
    "    gamma =  0.75  # 0\n",
    "    avg_norm_cliped = np.power(avg_norm_cliped, gamma)\n",
    "    # 리사이즈 및 블러링\n",
    "    avg_norm_cliped_rescaled = cv2.resize(avg_norm_cliped, (w, h), interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "    sig = min(w, h) * 0.05\n",
    "    k_val = int(sig * 3) * 2 + 1 \n",
    "    kernel_size = (k_val, k_val)\n",
    "\n",
    "    # 블러 적용\n",
    "    blur_map = cv2.GaussianBlur(avg_norm_cliped_rescaled, kernel_size, sig)\n",
    "\n",
    "    # 블러 후 다시 정규화\n",
    "    blur_map = min_max_normalize(blur_map) # 함수가 정의되어 있다고 가정\n",
    "    avg_norm_cliped_blur = blur_map\n",
    "    \n",
    "    # 시각화를 위해 31x31 맵도 원본 크기로 리사이즈\n",
    "    avg_norm_resized_vis = cv2.resize(avg_norm, (w, h), interpolation=cv2.INTER_LINEAR)\n",
    "    clip_vis = cv2.resize(clip_heatmap_resized, (w, h), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    # --- 4. GT 평가 및 메트릭 계산 ---\n",
    "    gt_map = load_ground_truth(gt_path) # 함수 정의 가정\n",
    "    if gt_map is not None:\n",
    "        metrics_dino = calculate_metrics(avg_norm_cliped_blur, gt_map) # 함수 정의 가정\n",
    "        metrics_tracker_alloutput.update(metrics_dino) # 객체 정의 가정\n",
    "        \n",
    "        # 메트릭 텍스트\n",
    "        metrics_text = f\"[{object_name} {action}] KLD: {metrics_dino['KLD']:.4f} | SIM: {metrics_dino['SIM']:.4f} | NSS: {metrics_dino['NSS']:.4f}\"\n",
    "        metrics_tracker_alloutput.print_metrics(metrics_dino, filename)\n",
    "    else:\n",
    "        print(\"NO GT!!!\")\n",
    "        metrics_text = \"No GT Available\"\n",
    "        continue\n",
    "    \n",
    "    results_list.append({\n",
    "        'object': object_name,\n",
    "        'action': action,\n",
    "        'filename': filename,\n",
    "        'output_sentence': output_description,\n",
    "        'top_token_text': top_token_text,\n",
    "        'following_text': following_text,\n",
    "        'clip_input': clipseg_input_text,\n",
    "        'KLD': metrics_dino['KLD'],\n",
    "        'SIM': metrics_dino['SIM'],\n",
    "        'NSS': metrics_dino['NSS']\n",
    "    })\n",
    "\n",
    "    # --- 5. 시각화 ---\n",
    "    fig, axes = plt.subplots(1, 7, figsize=(24, 5)) # 사이즈 살짝 조정\n",
    "    \n",
    "    # Signal 단어와 Noise 단어 표시 (제목용)\n",
    "    top_words = \",\".join([f\"'{t['token'].strip()}'\" for t in top_tokens[:5]])\n",
    "    \n",
    "    main_title = f\"Obj: {object_name} | Act: {action} |{metrics_text}\\nTop Tokens: [{top_words}({top_token_idx } ), clipseg input : {top_token_text} {following_text}] \\n Whole answer : {output_description}\"\n",
    "    fig.suptitle(main_title, fontsize=14, fontweight='bold', y=0.98)\n",
    "\n",
    "    # (1) 원본 이미지\n",
    "    axes[0].imshow(orig_img)\n",
    "    axes[0].set_title(f\"Original\\n({object_name})\")\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    # (2) Contrastive Attention (Pos - Neg)\n",
    "    im1 = axes[1].imshow(avg_norm_resized_vis, cmap='jet', interpolation='bilinear')\n",
    "    axes[1].set_title(f\"Attention Map {Layername}\")\n",
    "    axes[1].axis('off')\n",
    "    plt.colorbar(im1, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "\n",
    "    # (3) CLIPSeg Result\n",
    "    axes[2].imshow(clip_vis, cmap='gray')\n",
    "    axes[2].set_title(f\"CLIPSeg {clipseg_input_text}\")\n",
    "    axes[2].axis('off')\n",
    "\n",
    "    # (4) Hadamard (Contrastive x CLIPSeg)\n",
    "    # 리사이즈하여 시각화\n",
    "    hadamard_vis = cv2.resize(avg_norm_cliped, (w, h), interpolation=cv2.INTER_LINEAR)\n",
    "    im3 = axes[3].imshow(hadamard_vis, cmap='jet', interpolation='bilinear')\n",
    "    axes[3].set_title(\"Hadamard\\n(Contrastive x CLIP)\")\n",
    "    axes[3].axis('off')\n",
    "    plt.colorbar(im3, ax=axes[3], fraction=0.046, pad=0.04)\n",
    "\n",
    "    # (5) Final Blurred Result\n",
    "    im4 = axes[4].imshow(avg_norm_cliped_blur, cmap='jet', interpolation='bilinear')\n",
    "    axes[4].set_title(\"Final Blurred\")\n",
    "    axes[4].axis('off')\n",
    "    plt.colorbar(im4, ax=axes[4], fraction=0.046, pad=0.04)\n",
    "\n",
    "    # (6) Ground Truth\n",
    "    axes[5].imshow(gt_map, cmap='gray') # GT는 보통 binary 혹은 gray\n",
    "    axes[5].set_title(\"Ground Truth\")\n",
    "    axes[5].axis('off')\n",
    "\n",
    "    # (6) exo Image\n",
    "    axes[6].imshow(exo_img, cmap='gray') # GT는 보통 binary 혹은 gray\n",
    "    axes[6].set_title(\"Ground Truth\")\n",
    "    axes[6].axis('off')\n",
    "\n",
    "\n",
    "    # 파일 저장\n",
    "    save_path = os.path.join(output_dir, f\"exo_{object_name}_{action}_{filename.split('.')[0]}_{exo_name.split('.')[0]}.png\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, bbox_inches='tight', dpi=150)\n",
    "    plt.close(fig)\n",
    "\n",
    "df_analy = pd.DataFrame(results_list)\n",
    "df_analy.to_pickle(\"exo_selection_hold_axe.pkl\")\n",
    "        # print(f\"clipseg_input_text : {clipseg_input_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaabd173",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analy.to_pickle(\"exo_selection_hold_badminton_racket.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b0a982b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object</th>\n",
       "      <th>action</th>\n",
       "      <th>filename</th>\n",
       "      <th>output_sentence</th>\n",
       "      <th>top_token_text</th>\n",
       "      <th>following_text</th>\n",
       "      <th>clip_input</th>\n",
       "      <th>KLD</th>\n",
       "      <th>SIM</th>\n",
       "      <th>NSS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>axe</td>\n",
       "      <td>hold</td>\n",
       "      <td>axe_001552.jpg</td>\n",
       "      <td>Based on the first image, the handle of the ax...</td>\n",
       "      <td>black</td>\n",
       "      <td>and</td>\n",
       "      <td>black  and</td>\n",
       "      <td>0.671341</td>\n",
       "      <td>0.543523</td>\n",
       "      <td>1.950700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>axe</td>\n",
       "      <td>hold</td>\n",
       "      <td>axe_001552.jpg</td>\n",
       "      <td>Based on the first image, the part of the axe ...</td>\n",
       "      <td>red</td>\n",
       "      <td>and</td>\n",
       "      <td>red  and</td>\n",
       "      <td>0.223632</td>\n",
       "      <td>0.739141</td>\n",
       "      <td>2.538331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>axe</td>\n",
       "      <td>hold</td>\n",
       "      <td>axe_001552.jpg</td>\n",
       "      <td>Based on the first image, the handle of the ax...</td>\n",
       "      <td>red</td>\n",
       "      <td>and</td>\n",
       "      <td>red  and</td>\n",
       "      <td>0.215088</td>\n",
       "      <td>0.744543</td>\n",
       "      <td>2.551214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>axe</td>\n",
       "      <td>hold</td>\n",
       "      <td>axe_001552.jpg</td>\n",
       "      <td>Based on the first image, the handle of the ax...</td>\n",
       "      <td>red</td>\n",
       "      <td>and</td>\n",
       "      <td>red  and</td>\n",
       "      <td>0.214253</td>\n",
       "      <td>0.745661</td>\n",
       "      <td>2.554565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>axe</td>\n",
       "      <td>hold</td>\n",
       "      <td>axe_001552.jpg</td>\n",
       "      <td>Based on the first image, the handle of the ax...</td>\n",
       "      <td>red</td>\n",
       "      <td>and</td>\n",
       "      <td>red  and</td>\n",
       "      <td>0.212254</td>\n",
       "      <td>0.746921</td>\n",
       "      <td>2.555052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>axe</td>\n",
       "      <td>hold</td>\n",
       "      <td>axe_001552.jpg</td>\n",
       "      <td>Based on the first image, the handle of the ax...</td>\n",
       "      <td>red</td>\n",
       "      <td>and</td>\n",
       "      <td>red  and</td>\n",
       "      <td>0.213585</td>\n",
       "      <td>0.746024</td>\n",
       "      <td>2.555101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>axe</td>\n",
       "      <td>hold</td>\n",
       "      <td>axe_001552.jpg</td>\n",
       "      <td>Based on the first image, the handle of the ax...</td>\n",
       "      <td>red</td>\n",
       "      <td>and</td>\n",
       "      <td>red  and</td>\n",
       "      <td>0.213250</td>\n",
       "      <td>0.745724</td>\n",
       "      <td>2.555855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>axe</td>\n",
       "      <td>hold</td>\n",
       "      <td>axe_001552.jpg</td>\n",
       "      <td>Based on the first image, the handle (specific...</td>\n",
       "      <td>red</td>\n",
       "      <td>and</td>\n",
       "      <td>red  and</td>\n",
       "      <td>0.212207</td>\n",
       "      <td>0.747732</td>\n",
       "      <td>2.561917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>axe</td>\n",
       "      <td>hold</td>\n",
       "      <td>axe_001552.jpg</td>\n",
       "      <td>Based on the first image, the handle of the ax...</td>\n",
       "      <td>red</td>\n",
       "      <td>and</td>\n",
       "      <td>red  and</td>\n",
       "      <td>0.207569</td>\n",
       "      <td>0.750961</td>\n",
       "      <td>2.566384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>axe</td>\n",
       "      <td>hold</td>\n",
       "      <td>axe_001552.jpg</td>\n",
       "      <td>Based on the first image, the handle of the ax...</td>\n",
       "      <td>red</td>\n",
       "      <td>and</td>\n",
       "      <td>red  and</td>\n",
       "      <td>0.208520</td>\n",
       "      <td>0.750213</td>\n",
       "      <td>2.566911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>axe</td>\n",
       "      <td>hold</td>\n",
       "      <td>axe_001552.jpg</td>\n",
       "      <td>Based on the first image, the handle of the ax...</td>\n",
       "      <td>red</td>\n",
       "      <td>and</td>\n",
       "      <td>red  and</td>\n",
       "      <td>0.209041</td>\n",
       "      <td>0.749335</td>\n",
       "      <td>2.567095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>axe</td>\n",
       "      <td>hold</td>\n",
       "      <td>axe_001552.jpg</td>\n",
       "      <td>Based on the first image, the handle of the ax...</td>\n",
       "      <td>red</td>\n",
       "      <td>and</td>\n",
       "      <td>red  and</td>\n",
       "      <td>0.211832</td>\n",
       "      <td>0.748184</td>\n",
       "      <td>2.568171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>axe</td>\n",
       "      <td>hold</td>\n",
       "      <td>axe_001552.jpg</td>\n",
       "      <td>Based on the first image, the handle of the ax...</td>\n",
       "      <td>red</td>\n",
       "      <td>and</td>\n",
       "      <td>red  and</td>\n",
       "      <td>0.207704</td>\n",
       "      <td>0.751000</td>\n",
       "      <td>2.569087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>axe</td>\n",
       "      <td>hold</td>\n",
       "      <td>axe_001552.jpg</td>\n",
       "      <td>Based on the first image, the handle of the ax...</td>\n",
       "      <td>red</td>\n",
       "      <td>and</td>\n",
       "      <td>red  and</td>\n",
       "      <td>0.211295</td>\n",
       "      <td>0.749038</td>\n",
       "      <td>2.569879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>axe</td>\n",
       "      <td>hold</td>\n",
       "      <td>axe_001552.jpg</td>\n",
       "      <td>Based on the first image, the handle of the ax...</td>\n",
       "      <td>red</td>\n",
       "      <td>and</td>\n",
       "      <td>red  and</td>\n",
       "      <td>0.207986</td>\n",
       "      <td>0.751628</td>\n",
       "      <td>2.572797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>axe</td>\n",
       "      <td>hold</td>\n",
       "      <td>axe_001552.jpg</td>\n",
       "      <td>Based on the first image, the handle of the ax...</td>\n",
       "      <td>red</td>\n",
       "      <td>and</td>\n",
       "      <td>red  and</td>\n",
       "      <td>0.207584</td>\n",
       "      <td>0.751547</td>\n",
       "      <td>2.576042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>axe</td>\n",
       "      <td>hold</td>\n",
       "      <td>axe_001552.jpg</td>\n",
       "      <td>Based on the first image, the handle of the ax...</td>\n",
       "      <td>red</td>\n",
       "      <td>and</td>\n",
       "      <td>red  and</td>\n",
       "      <td>0.207541</td>\n",
       "      <td>0.753528</td>\n",
       "      <td>2.587021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   object action        filename  \\\n",
       "11    axe   hold  axe_001552.jpg   \n",
       "10    axe   hold  axe_001552.jpg   \n",
       "15    axe   hold  axe_001552.jpg   \n",
       "5     axe   hold  axe_001552.jpg   \n",
       "6     axe   hold  axe_001552.jpg   \n",
       "3     axe   hold  axe_001552.jpg   \n",
       "13    axe   hold  axe_001552.jpg   \n",
       "0     axe   hold  axe_001552.jpg   \n",
       "14    axe   hold  axe_001552.jpg   \n",
       "7     axe   hold  axe_001552.jpg   \n",
       "4     axe   hold  axe_001552.jpg   \n",
       "2     axe   hold  axe_001552.jpg   \n",
       "8     axe   hold  axe_001552.jpg   \n",
       "1     axe   hold  axe_001552.jpg   \n",
       "16    axe   hold  axe_001552.jpg   \n",
       "9     axe   hold  axe_001552.jpg   \n",
       "12    axe   hold  axe_001552.jpg   \n",
       "\n",
       "                                      output_sentence top_token_text  \\\n",
       "11  Based on the first image, the handle of the ax...          black   \n",
       "10  Based on the first image, the part of the axe ...            red   \n",
       "15  Based on the first image, the handle of the ax...            red   \n",
       "5   Based on the first image, the handle of the ax...            red   \n",
       "6   Based on the first image, the handle of the ax...            red   \n",
       "3   Based on the first image, the handle of the ax...            red   \n",
       "13  Based on the first image, the handle of the ax...            red   \n",
       "0   Based on the first image, the handle (specific...            red   \n",
       "14  Based on the first image, the handle of the ax...            red   \n",
       "7   Based on the first image, the handle of the ax...            red   \n",
       "4   Based on the first image, the handle of the ax...            red   \n",
       "2   Based on the first image, the handle of the ax...            red   \n",
       "8   Based on the first image, the handle of the ax...            red   \n",
       "1   Based on the first image, the handle of the ax...            red   \n",
       "16  Based on the first image, the handle of the ax...            red   \n",
       "9   Based on the first image, the handle of the ax...            red   \n",
       "12  Based on the first image, the handle of the ax...            red   \n",
       "\n",
       "   following_text   clip_input       KLD       SIM       NSS  \n",
       "11            and   black  and  0.671341  0.543523  1.950700  \n",
       "10            and     red  and  0.223632  0.739141  2.538331  \n",
       "15            and     red  and  0.215088  0.744543  2.551214  \n",
       "5             and     red  and  0.214253  0.745661  2.554565  \n",
       "6             and     red  and  0.212254  0.746921  2.555052  \n",
       "3             and     red  and  0.213585  0.746024  2.555101  \n",
       "13            and     red  and  0.213250  0.745724  2.555855  \n",
       "0             and     red  and  0.212207  0.747732  2.561917  \n",
       "14            and     red  and  0.207569  0.750961  2.566384  \n",
       "7             and     red  and  0.208520  0.750213  2.566911  \n",
       "4             and     red  and  0.209041  0.749335  2.567095  \n",
       "2             and     red  and  0.211832  0.748184  2.568171  \n",
       "8             and     red  and  0.207704  0.751000  2.569087  \n",
       "1             and     red  and  0.211295  0.749038  2.569879  \n",
       "16            and     red  and  0.207986  0.751628  2.572797  \n",
       "9             and     red  and  0.207584  0.751547  2.576042  \n",
       "12            and     red  and  0.207541  0.753528  2.587021  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analy.sort_values([\"NSS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1268fbd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object</th>\n",
       "      <th>action</th>\n",
       "      <th>filename</th>\n",
       "      <th>output_sentence</th>\n",
       "      <th>top_token_text</th>\n",
       "      <th>following_text</th>\n",
       "      <th>clip_input</th>\n",
       "      <th>KLD</th>\n",
       "      <th>SIM</th>\n",
       "      <th>NSS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>badminton_racket</td>\n",
       "      <td>hold</td>\n",
       "      <td>badminton_racket_002255.jpg</td>\n",
       "      <td>Based on the first image, the handle (or grip)...</td>\n",
       "      <td>handle</td>\n",
       "      <td>(</td>\n",
       "      <td>handle  (</td>\n",
       "      <td>0.833763</td>\n",
       "      <td>0.456510</td>\n",
       "      <td>2.224909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>badminton_racket</td>\n",
       "      <td>hold</td>\n",
       "      <td>badminton_racket_002255.jpg</td>\n",
       "      <td>Based on the first image, the handle (or grip)...</td>\n",
       "      <td>handle</td>\n",
       "      <td>(</td>\n",
       "      <td>handle  (</td>\n",
       "      <td>0.829190</td>\n",
       "      <td>0.458288</td>\n",
       "      <td>2.231138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>badminton_racket</td>\n",
       "      <td>hold</td>\n",
       "      <td>badminton_racket_002255.jpg</td>\n",
       "      <td>Based on the first image, the handle (or grip)...</td>\n",
       "      <td>handle</td>\n",
       "      <td>(</td>\n",
       "      <td>handle  (</td>\n",
       "      <td>0.830226</td>\n",
       "      <td>0.458051</td>\n",
       "      <td>2.231992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>badminton_racket</td>\n",
       "      <td>hold</td>\n",
       "      <td>badminton_racket_002255.jpg</td>\n",
       "      <td>Based on the first image, the handle (or grip)...</td>\n",
       "      <td>handle</td>\n",
       "      <td>(</td>\n",
       "      <td>handle  (</td>\n",
       "      <td>0.826313</td>\n",
       "      <td>0.459504</td>\n",
       "      <td>2.232696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>badminton_racket</td>\n",
       "      <td>hold</td>\n",
       "      <td>badminton_racket_002255.jpg</td>\n",
       "      <td>Based on the first image, the handle (or grip)...</td>\n",
       "      <td>handle</td>\n",
       "      <td>(</td>\n",
       "      <td>handle  (</td>\n",
       "      <td>0.823134</td>\n",
       "      <td>0.460721</td>\n",
       "      <td>2.232715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>badminton_racket</td>\n",
       "      <td>hold</td>\n",
       "      <td>badminton_racket_002255.jpg</td>\n",
       "      <td>Based on the first image, the handle (or grip)...</td>\n",
       "      <td>handle</td>\n",
       "      <td>(</td>\n",
       "      <td>handle  (</td>\n",
       "      <td>0.829356</td>\n",
       "      <td>0.458138</td>\n",
       "      <td>2.233707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>badminton_racket</td>\n",
       "      <td>hold</td>\n",
       "      <td>badminton_racket_002255.jpg</td>\n",
       "      <td>Based on the first image, the handle (or grip)...</td>\n",
       "      <td>handle</td>\n",
       "      <td>(</td>\n",
       "      <td>handle  (</td>\n",
       "      <td>0.828423</td>\n",
       "      <td>0.458777</td>\n",
       "      <td>2.233982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>badminton_racket</td>\n",
       "      <td>hold</td>\n",
       "      <td>badminton_racket_002255.jpg</td>\n",
       "      <td>Based on the first image, the handle (or grip)...</td>\n",
       "      <td>handle</td>\n",
       "      <td>(</td>\n",
       "      <td>handle  (</td>\n",
       "      <td>0.827386</td>\n",
       "      <td>0.458944</td>\n",
       "      <td>2.235275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>badminton_racket</td>\n",
       "      <td>hold</td>\n",
       "      <td>badminton_racket_002255.jpg</td>\n",
       "      <td>Based on the first image, the handle (or grip)...</td>\n",
       "      <td>handle</td>\n",
       "      <td>(</td>\n",
       "      <td>handle  (</td>\n",
       "      <td>0.827909</td>\n",
       "      <td>0.458500</td>\n",
       "      <td>2.235811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>badminton_racket</td>\n",
       "      <td>hold</td>\n",
       "      <td>badminton_racket_002255.jpg</td>\n",
       "      <td>Based on the first image, the handle (or grip)...</td>\n",
       "      <td>handle</td>\n",
       "      <td>(</td>\n",
       "      <td>handle  (</td>\n",
       "      <td>0.823897</td>\n",
       "      <td>0.460539</td>\n",
       "      <td>2.236242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>badminton_racket</td>\n",
       "      <td>hold</td>\n",
       "      <td>badminton_racket_002255.jpg</td>\n",
       "      <td>Based on the first image, the handle (or grip)...</td>\n",
       "      <td>handle</td>\n",
       "      <td>(</td>\n",
       "      <td>handle  (</td>\n",
       "      <td>0.826657</td>\n",
       "      <td>0.459442</td>\n",
       "      <td>2.237389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>badminton_racket</td>\n",
       "      <td>hold</td>\n",
       "      <td>badminton_racket_002255.jpg</td>\n",
       "      <td>Based on the first image, the handle (or grip)...</td>\n",
       "      <td>handle</td>\n",
       "      <td>(</td>\n",
       "      <td>handle  (</td>\n",
       "      <td>0.831272</td>\n",
       "      <td>0.457944</td>\n",
       "      <td>2.238018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>badminton_racket</td>\n",
       "      <td>hold</td>\n",
       "      <td>badminton_racket_002255.jpg</td>\n",
       "      <td>Based on the first image, the handle (or grip)...</td>\n",
       "      <td>handle</td>\n",
       "      <td>(</td>\n",
       "      <td>handle  (</td>\n",
       "      <td>0.823546</td>\n",
       "      <td>0.460668</td>\n",
       "      <td>2.238529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>badminton_racket</td>\n",
       "      <td>hold</td>\n",
       "      <td>badminton_racket_002255.jpg</td>\n",
       "      <td>Based on the first image, the handle (or grip)...</td>\n",
       "      <td>handle</td>\n",
       "      <td>(</td>\n",
       "      <td>handle  (</td>\n",
       "      <td>0.822585</td>\n",
       "      <td>0.461135</td>\n",
       "      <td>2.238853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>badminton_racket</td>\n",
       "      <td>hold</td>\n",
       "      <td>badminton_racket_002255.jpg</td>\n",
       "      <td>Based on the first image, the handle (or grip)...</td>\n",
       "      <td>handle</td>\n",
       "      <td>(</td>\n",
       "      <td>handle  (</td>\n",
       "      <td>0.824318</td>\n",
       "      <td>0.460316</td>\n",
       "      <td>2.238940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>badminton_racket</td>\n",
       "      <td>hold</td>\n",
       "      <td>badminton_racket_002255.jpg</td>\n",
       "      <td>Based on the first image, the handle (or grip)...</td>\n",
       "      <td>handle</td>\n",
       "      <td>(</td>\n",
       "      <td>handle  (</td>\n",
       "      <td>0.815543</td>\n",
       "      <td>0.464052</td>\n",
       "      <td>2.245319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>badminton_racket</td>\n",
       "      <td>hold</td>\n",
       "      <td>badminton_racket_002255.jpg</td>\n",
       "      <td>Based on the first image, the handle (or grip)...</td>\n",
       "      <td>handle</td>\n",
       "      <td>(</td>\n",
       "      <td>handle  (</td>\n",
       "      <td>0.820561</td>\n",
       "      <td>0.462001</td>\n",
       "      <td>2.245480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>badminton_racket</td>\n",
       "      <td>hold</td>\n",
       "      <td>badminton_racket_002255.jpg</td>\n",
       "      <td>Based on the first image, the handle (or grip)...</td>\n",
       "      <td>handle</td>\n",
       "      <td>(</td>\n",
       "      <td>handle  (</td>\n",
       "      <td>0.811544</td>\n",
       "      <td>0.465618</td>\n",
       "      <td>2.250462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>badminton_racket</td>\n",
       "      <td>hold</td>\n",
       "      <td>badminton_racket_002255.jpg</td>\n",
       "      <td>Based on the first image, the handle (or grip)...</td>\n",
       "      <td>handle</td>\n",
       "      <td>(</td>\n",
       "      <td>handle  (</td>\n",
       "      <td>0.811746</td>\n",
       "      <td>0.465695</td>\n",
       "      <td>2.251553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              object action                     filename  \\\n",
       "8   badminton_racket   hold  badminton_racket_002255.jpg   \n",
       "12  badminton_racket   hold  badminton_racket_002255.jpg   \n",
       "2   badminton_racket   hold  badminton_racket_002255.jpg   \n",
       "3   badminton_racket   hold  badminton_racket_002255.jpg   \n",
       "1   badminton_racket   hold  badminton_racket_002255.jpg   \n",
       "9   badminton_racket   hold  badminton_racket_002255.jpg   \n",
       "0   badminton_racket   hold  badminton_racket_002255.jpg   \n",
       "18  badminton_racket   hold  badminton_racket_002255.jpg   \n",
       "4   badminton_racket   hold  badminton_racket_002255.jpg   \n",
       "7   badminton_racket   hold  badminton_racket_002255.jpg   \n",
       "5   badminton_racket   hold  badminton_racket_002255.jpg   \n",
       "17  badminton_racket   hold  badminton_racket_002255.jpg   \n",
       "6   badminton_racket   hold  badminton_racket_002255.jpg   \n",
       "16  badminton_racket   hold  badminton_racket_002255.jpg   \n",
       "13  badminton_racket   hold  badminton_racket_002255.jpg   \n",
       "10  badminton_racket   hold  badminton_racket_002255.jpg   \n",
       "15  badminton_racket   hold  badminton_racket_002255.jpg   \n",
       "11  badminton_racket   hold  badminton_racket_002255.jpg   \n",
       "14  badminton_racket   hold  badminton_racket_002255.jpg   \n",
       "\n",
       "                                      output_sentence top_token_text  \\\n",
       "8   Based on the first image, the handle (or grip)...         handle   \n",
       "12  Based on the first image, the handle (or grip)...         handle   \n",
       "2   Based on the first image, the handle (or grip)...         handle   \n",
       "3   Based on the first image, the handle (or grip)...         handle   \n",
       "1   Based on the first image, the handle (or grip)...         handle   \n",
       "9   Based on the first image, the handle (or grip)...         handle   \n",
       "0   Based on the first image, the handle (or grip)...         handle   \n",
       "18  Based on the first image, the handle (or grip)...         handle   \n",
       "4   Based on the first image, the handle (or grip)...         handle   \n",
       "7   Based on the first image, the handle (or grip)...         handle   \n",
       "5   Based on the first image, the handle (or grip)...         handle   \n",
       "17  Based on the first image, the handle (or grip)...         handle   \n",
       "6   Based on the first image, the handle (or grip)...         handle   \n",
       "16  Based on the first image, the handle (or grip)...         handle   \n",
       "13  Based on the first image, the handle (or grip)...         handle   \n",
       "10  Based on the first image, the handle (or grip)...         handle   \n",
       "15  Based on the first image, the handle (or grip)...         handle   \n",
       "11  Based on the first image, the handle (or grip)...         handle   \n",
       "14  Based on the first image, the handle (or grip)...         handle   \n",
       "\n",
       "   following_text  clip_input       KLD       SIM       NSS  \n",
       "8               (   handle  (  0.833763  0.456510  2.224909  \n",
       "12              (   handle  (  0.829190  0.458288  2.231138  \n",
       "2               (   handle  (  0.830226  0.458051  2.231992  \n",
       "3               (   handle  (  0.826313  0.459504  2.232696  \n",
       "1               (   handle  (  0.823134  0.460721  2.232715  \n",
       "9               (   handle  (  0.829356  0.458138  2.233707  \n",
       "0               (   handle  (  0.828423  0.458777  2.233982  \n",
       "18              (   handle  (  0.827386  0.458944  2.235275  \n",
       "4               (   handle  (  0.827909  0.458500  2.235811  \n",
       "7               (   handle  (  0.823897  0.460539  2.236242  \n",
       "5               (   handle  (  0.826657  0.459442  2.237389  \n",
       "17              (   handle  (  0.831272  0.457944  2.238018  \n",
       "6               (   handle  (  0.823546  0.460668  2.238529  \n",
       "16              (   handle  (  0.822585  0.461135  2.238853  \n",
       "13              (   handle  (  0.824318  0.460316  2.238940  \n",
       "10              (   handle  (  0.815543  0.464052  2.245319  \n",
       "15              (   handle  (  0.820561  0.462001  2.245480  \n",
       "11              (   handle  (  0.811544  0.465618  2.250462  \n",
       "14              (   handle  (  0.811746  0.465695  2.251553  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analy.sort_values([\"NSS\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
