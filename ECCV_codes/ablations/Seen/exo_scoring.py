import os
import sys
import torch
import pandas as pd
from tqdm import tqdm
from transformers import Qwen3VLForConditionalGeneration, AutoProcessor

# --- ê²½ë¡œ ì„¤ì • ---
# í˜„ì¬ íŒŒì¼ ìœ„ì¹˜ ê¸°ì¤€
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append("/home/bongo/porter_notebook/research/qwen3")

# ëª¨ë“ˆ ì„í¬íŠ¸
from config import AGD20K_PATH, model_name
from file_managing import make_input_image

# ------------------------------------------------------
# 1. í™˜ê²½ ë° ëª¨ë¸ ì„¤ì •
# ------------------------------------------------------
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
os.environ["PYTORCH_ENABLE_SDPA"] = "1"

INPUT_PKL_PATH = "/home/bongo/porter_notebook/research/qwen3/ECCV_codes/ablations/Seen/2B_all_trials_metrics.pkl"
OUTPUT_PKL_PATH = "/home/bongo/porter_notebook/research/qwen3/ECCV_codes/ablations/Seen/2B_all_trials_scored.pkl"

print(f"ğŸ“‚ Reading DataFrame from: {INPUT_PKL_PATH}")
df = pd.read_pickle(INPUT_PKL_PATH)
print(f"   Total rows: {len(df)}")

print(f"ğŸ¤– Loading Model: {model_name}...")
model = Qwen3VLForConditionalGeneration.from_pretrained(
    model_name,
    torch_dtype=torch.bfloat16,
    attn_implementation="eager",
    device_map="cuda", 
)
processor = AutoProcessor.from_pretrained(model_name)
device = model.device

# ------------------------------------------------------
# 2. Scoring í•¨ìˆ˜ ì •ì˜
# ------------------------------------------------------
def calculate_targeted_score(model, processor, image_path, target_action, object_name):
    # ì´ˆê¸°ê°’ ì„¤ì •
    has_text = "N"
    
    # 1. ì „ì²˜ë¦¬: í•µì‹¬ ë™ì‚¬ ì¶”ì¶œ (ì˜ˆ: 'hold_monitor' -> 'hold')
    core_action = target_action.split('_')[0].lower()
    
    # 2. ì§ˆë¬¸ êµ¬ì„±
    query = f"What actions is the person doing with the {object_name}? list all the possible verbs. Only list the verbs."
    
    # 3. ì´ë¯¸ì§€ ë° ì…ë ¥ ìƒì„±
    try:
        image_base64 = make_input_image(str(image_path))
    except Exception as e:
        print(f"Error reading image {image_path}: {e}")
        return 0.0, "image_error", "N"

    messages = [
        {"role": "user", "content": [
            {"type": "image", "image": f"data:image/jpeg;base64,{image_base64}"},
            {"type": "text", "text": query}
        ]}
    ]
    
    inputs = processor.apply_chat_template(
        messages, 
        tokenize=True, 
        add_generation_prompt=True, 
        return_dict=True, 
        return_tensors="pt"
    ).to(device)
    
    # Vision Token ì¸ë±ìŠ¤ ì°¾ê¸° (ì…ë ¥ í”„ë¡¬í”„íŠ¸ ë‚´ì—ì„œ)
    input_ids_list = inputs.input_ids[0].tolist()
    vis_start_id = processor.tokenizer.convert_tokens_to_ids("<|vision_start|>")
    vis_end_id = processor.tokenizer.convert_tokens_to_ids("<|vision_end|>")
    
    try:
        vis_start_idx = input_ids_list.index(vis_start_id)
        vis_end_idx = input_ids_list.index(vis_end_id)
    except ValueError:
        # í˜¹ì‹œ vision tokenì´ ì—†ëŠ” ê²½ìš° ë°©ì–´
        return 0.0, "token_error", "N"

    # Inference
    with torch.no_grad():
        generated_ids = model.generate(
            **inputs, 
            max_new_tokens=30, 
            output_attentions=True, 
            return_dict_in_generate=True,
            do_sample=False  # Deterministic ê²°ê³¼
        )
        
    output_ids = generated_ids.sequences[0][inputs.input_ids.shape[1]:]
    full_text = processor.decode(output_ids, skip_special_tokens=True).lower()
    
    # 4. [1ì°¨ í•„í„°] ë¬¸ì¥ ì „ì²´ì— í•µì‹¬ ë™ì‚¬ê°€ ì—†ìœ¼ë©´ 0ì 
    if core_action not in full_text:
        return 0.0, full_text, has_text

    # 5. Targeted Scoring (Attention Energy Calculation)
    total_vis_score = 0.0     # ë§¤ì¹­ëœ í† í°ë“¤ì˜ í•©
    matched_count = 0         # ë§¤ì¹­ëœ í† í° ìˆ˜
    
    all_tokens_energy_sum = 0.0 # (Safety Netìš©)
    valid_token_count = 0       # (Safety Netìš©)
    
    # generated_ids.attentionsëŠ” íŠœí”Œ(ìƒì„±ëœ í† í° ìˆ˜)ë¡œ êµ¬ì„±ë¨
    # ê° ìš”ì†ŒëŠ” íŠœí”Œ(ë ˆì´ì–´ ìˆ˜) -> í…ì„œ(ë°°ì¹˜, í—¤ë“œ, ì‹œí€€ìŠ¤, ì‹œí€€ìŠ¤)
    
    for i, token_id in enumerate(output_ids):
        # ì¸ë±ìŠ¤ ë²”ìœ„ ì²´í¬ (ìƒì„±ëœ í† í° ê¸¸ì´ë³´ë‹¤ attentions ê¸¸ì´ê°€ ì§§ì„ ìˆ˜ ìˆìŒ - ìºì‹± ë•Œë¬¸)
        if i >= len(generated_ids.attentions): 
            break
            
        token_str = processor.decode([token_id], skip_special_tokens=True).lower().strip()
        if not token_str: continue 

        # --- [ì—ë„ˆì§€ ê³„ì‚°] ---
        token_energy = 0.0
        # ëª¨ë“  ë ˆì´ì–´ì˜ ì–´í…ì…˜ í•©ì‚°
        for layer_attn in generated_ids.attentions[i]:
            # layer_attn shape: [1, num_heads, 1, current_total_seq_len]
            # vision token ì˜ì—­: vis_start_idx+1 ~ vis_end_idx
            vision_attn = layer_attn[0, :, 0, vis_start_idx+1 : vis_end_idx]
            token_energy += vision_attn.sum().item()
        
        all_tokens_energy_sum += token_energy
        valid_token_count += 1

        # --- [í† í° ë§¤ì¹­ í™•ì¸] ---
        # 1. Core Actionì´ Tokenì„ í¬í•¨ OR 2. Tokenì´ Core Actionì„ í¬í•¨
        if (core_action in token_str) or (token_str in core_action and len(token_str) > 1): 
            has_text = "Y"
            total_vis_score += token_energy
            matched_count += 1
            
    # [ê²°ê³¼ ë°˜í™˜ ë¡œì§]
    if matched_count > 0:
        # ì •í™•íˆ ë§¤ì¹­ëœ í† í°ë“¤ì˜ í‰ê·  ì—ë„ˆì§€
        final_score = total_vis_score / matched_count
    else:
        # [Safety Net] í…ìŠ¤íŠ¸ì—” ìˆì§€ë§Œ í† í° ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ -> ì „ì²´ ë¬¸ì¥ í‰ê·  ì—ë„ˆì§€
        if valid_token_count > 0:
            final_score = all_tokens_energy_sum / valid_token_count
        else:
            final_score = 0.0

    return final_score, full_text, has_text

# ------------------------------------------------------
# 3. Main Loop
# ------------------------------------------------------
# ê²°ê³¼ë¥¼ ë‹´ì„ ë¦¬ìŠ¤íŠ¸ (ë”•ì…”ë„ˆë¦¬ í˜•íƒœê°€ ì•ˆì „í•¨)
results = []

print("ğŸš€ Starting Scoring Loop...")

for idx, row in tqdm(df.iterrows(), total=len(df), desc="Scoring Exo Images"):
    
    # ê³„ì‚° ìˆ˜í–‰
    score, text, has_text_flag = calculate_targeted_score(
        model, 
        processor, 
        row['exo_path'], 
        row['action'], 
        row['object']
    )
    
    # ê²°ê³¼ ì €ì¥ (ê¸°ì¡´ row ë°ì´í„°ë¥¼ ë³µì‚¬ í›„ ì¶”ê°€)
    new_row = row.to_dict()
    new_row['attn_score'] = score
    new_row['gen_text'] = text
    new_row['has_action_text'] = has_text_flag
    
    results.append(new_row)
    
    # 100ê°œë§ˆë‹¤ ì¤‘ê°„ ì €ì¥ (ì•ˆì „ì¥ì¹˜)
    if (idx + 1) % 100 == 0:
        temp_df = pd.DataFrame(results)
        temp_df.to_pickle(OUTPUT_PKL_PATH)

# ------------------------------------------------------
# 4. Final Save
# ------------------------------------------------------
final_df = pd.DataFrame(results)
final_df.to_pickle(OUTPUT_PKL_PATH)

print("\nğŸ‰ Scoring Complete!")
print(f"ğŸ’¾ Saved to: {OUTPUT_PKL_PATH}")
print(final_df[['action', 'gen_text', 'attn_score', 'has_action_text']].head())