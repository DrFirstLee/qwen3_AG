#  nohup python -u exo_test.py >> 2b_selection.log 2>&1 & 

import os
import sys
import torch
import pandas as pd
from tqdm import tqdm
import random
from pathlib import Path
from transformers import Qwen3VLForConditionalGeneration, AutoProcessor

# --- ê²½ë¡œ ì„¤ì • ---
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.append("/home/bongo/porter_notebook/research/qwen3")

# config ë° file_managingì—ì„œ í•„ìš”í•œ ë³€ìˆ˜/í•¨ìˆ˜ ì„í¬íŠ¸
from config import AGD20K_PATH, model_name
from file_managing import make_input_image

# ------------------------------------------------------
# 1. ëª¨ë¸ ë¡œë”©
# ------------------------------------------------------
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
os.environ["PYTORCH_ENABLE_SDPA"] = "1"

print(f"ğŸ¤– Loading {model_name} for selection...")
model = Qwen3VLForConditionalGeneration.from_pretrained(
    model_name,
    torch_dtype=torch.bfloat16,
    attn_implementation="eager",
    device_map="cuda", 
)
processor = AutoProcessor.from_pretrained(model_name)
device = model.device

# ------------------------------------------------------
# 2. Scoring í•¨ìˆ˜ (Simple Listing & Targeted Scoring)
# ------------------------------------------------------
def calculate_targeted_score(model, processor, image_path, target_action, object_name):
    has_text = "N"
    # -----------------------------------------------------------
    # 1. ì „ì²˜ë¦¬: í•µì‹¬ ë™ì‚¬ ì¶”ì¶œ
    # -----------------------------------------------------------
    # ì‚¬ì „ ì—†ì´ ë‹¨ìˆœ splitë§Œ ì‚¬ìš©
    core_action = target_action.split('_')[0].lower() 
    
    # -----------------------------------------------------------
    # 2. ì§ˆë¬¸: ë™ì‚¬ ë‚˜ì—´ ìœ ë„
    # -----------------------------------------------------------
    query = f"What actions is the person doing with the {object_name}? list all the possible verbs. Only list the verbs."
    
    # 3. Inference

    image_base64 = make_input_image(str(image_path))


    messages = [
        {"role": "user", "content": [
            {"type": "image", "image": f"data:image/jpeg;base64,{image_base64}"},
            {"type": "text", "text": query}
        ]}
    ]
    inputs = processor.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_dict=True, return_tensors="pt").to(model.device)
    
    # Vision Token ì¸ë±ìŠ¤ ì°¾ê¸°
    input_ids_list = inputs.input_ids[0].tolist()
    vis_start_id = processor.tokenizer.convert_tokens_to_ids("<|vision_start|>")
    vis_end_id = processor.tokenizer.convert_tokens_to_ids("<|vision_end|>")

    vis_start_idx = input_ids_list.index(vis_start_id)
    vis_end_idx = input_ids_list.index(vis_end_id)

    with torch.no_grad():
        generated_ids = model.generate(**inputs, max_new_tokens=30, output_attentions=True, return_dict_in_generate=True)
        
    output_ids = generated_ids.sequences[0][inputs.input_ids.shape[1]:]
    full_text = processor.decode(output_ids, skip_special_tokens=True).lower()
    
    # 4. [1ì°¨ í•„í„°] ë¬¸ì¥ ì „ì²´ì— í•µì‹¬ ë™ì‚¬ê°€ ì—†ìœ¼ë©´ 0ì  (ì˜ˆ: carry ì°¾ëŠ”ë° walkë§Œ ìˆìŒ)
    if core_action not in full_text:
        return 0.0, full_text, has_text

    # -----------------------------------------------------------
    # 5. Targeted Scoring (Safety Net ì¶”ê°€)
    # -----------------------------------------------------------
    total_vis_score = 0.0     # ë§¤ì¹­ëœ í† í°ë“¤ì˜ í•©
    matched_count = 0         # ë§¤ì¹­ëœ í† í° ìˆ˜
    
    all_tokens_energy_sum = 0.0 # (Safety Netìš©) ì „ì²´ í† í° ì—ë„ˆì§€ í•©
    valid_token_count = 0       # (Safety Netìš©) ì „ì²´ ìœ íš¨ í† í° ìˆ˜
    
    for i, token_id in enumerate(output_ids):
        token_str = processor.decode([token_id], skip_special_tokens=True).lower().strip()
        if not token_str: continue # ê³µë°± í† í° ë¬´ì‹œ

        # --- [ì—ë„ˆì§€ ê³„ì‚°] ---
        # ë§¤ì¹­ ì—¬ë¶€ì™€ ìƒê´€ì—†ì´ ì¼ë‹¨ í˜„ì¬ í† í°ì˜ ì—ë„ˆì§€ë¥¼ ê³„ì‚°í•´ë‘¡ë‹ˆë‹¤.
        token_energy = 0.0
        for layer_attn in generated_ids.attentions[i]:
            # Vision Token ì˜ì—­ë§Œ ìŠ¬ë¼ì´ì‹±í•˜ì—¬ í•©ì‚°
            vision_attn = layer_attn[0, :, 0, vis_start_idx+1 : vis_end_idx]
            token_energy += vision_attn.sum().item()
        
        # Safety Netì„ ìœ„í•´ ì „ì²´ ëˆ„ì 
        all_tokens_energy_sum += token_energy
        valid_token_count += 1

        # --- [í† í° ë§¤ì¹­ í™•ì¸] ---
        # 1. Core Actionì´ Tokenì„ í¬í•¨ (ì˜ˆ: carry >= car) -> BPE íŒŒí¸í™” ëŒ€ì‘
        # 2. Tokenì´ Core Actionì„ í¬í•¨ (ì˜ˆ: carrying >= carry) -> ë³€í˜• ëŒ€ì‘
        if (core_action in token_str) or (token_str in core_action and len(token_str) > 1): 
            has_text = "Y"
            # len > 1 ì¡°ê±´: 'c', 'a' ê°™ì€ ë„ˆë¬´ ì§§ì€ íŒŒí¸ì´ ì—„í•œ ë‹¨ì–´ì— ë§¤ì¹­ë˜ëŠ” ê²ƒ ë°©ì§€
            total_vis_score += token_energy
            matched_count += 1
            
    # -----------------------------------------------------------
    # [ê²°ê³¼ ë°˜í™˜ ë¡œì§]
    # -----------------------------------------------------------
    if matched_count > 0:
        # 1. ì •í™•íˆ ë§¤ì¹­ëœ í† í°ì´ ìˆìœ¼ë©´ ê·¸ ì ìˆ˜ ì‚¬ìš© (Best)
        final_score = total_vis_score / matched_count
    else:
        # 2. [Safety Net] ë§¤ì¹­ëœ í† í°ì€ ì—†ì§€ë§Œ, full_textì—ëŠ” ì •ë‹µì´ ìˆì—ˆìŒ!
        # í† í¬ë‚˜ì´ì§• ë¬¸ì œë¡œ íŒë‹¨í•˜ê³ , ì „ì²´ ë¬¸ì¥ì˜ í‰ê·  ì—ë„ˆì§€ë¥¼ ë°˜í™˜ (Fallback)
        if valid_token_count > 0:
            final_score = all_tokens_energy_sum / valid_token_count
        else:
            return 0.0, full_text,has_text # í† í°ì´ ì—†ìœ¼ë©´ 0ì 

    return final_score, full_text, has_text


# ------------------------------------------------------
# 3. Main Selection Loop
# ------------------------------------------------------
EXO_ROOT = Path(f"{AGD20K_PATH}/Seen/trainset/exocentric")
valid_ext = {'.jpg', '.jpeg', '.png'}
save_path = "selected_best_exo_images.pkl"

selection_db = []

print(f"ğŸ“‚ Scanning directory: {EXO_ROOT}")

# Action í´ë” ìˆœíšŒ
actions = sorted([d for d in EXO_ROOT.iterdir() if d.is_dir()])

for action_dir in tqdm(actions, desc="Actions"):

    action_name = action_dir.name
    
    # Object í´ë” ìˆœíšŒ
    objects = sorted([d for d in action_dir.iterdir() if d.is_dir()])
    
    for obj_dir in objects:
        obj_name = obj_dir.name
        print(f"action: {action_name}, object: {obj_name}")
        # í•´ë‹¹ í´ë”ì˜ ëª¨ë“  ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°
        all_exo_images = [p for p in obj_dir.rglob("*") if p.suffix.lower() in valid_ext]
        
        if len(all_exo_images) == 0:
            print(f"âš ï¸ No images in {action_name}/{obj_name}")
            continue
            
        best_score = -1.0
        best_image_info = None
        
        # ê° ì´ë¯¸ì§€ í‰ê°€ (Competitive Selection)
        num_samples = min(len(all_exo_images), 20)
        for img_path in random.sample(all_exo_images, num_samples):
            
            score, text,has_text = calculate_targeted_score(model, processor, img_path, action_name, obj_name)
            print(f"img_path: {img_path}, score: {score}, text: {text} / has_text : {has_text}")
            
            # ìµœê³  ì ìˆ˜ ê°±ì‹ 
            if score > best_score:
                best_score = score
                best_image_info = {
                    "action": action_name,
                    "object": obj_name,
                    "best_exo_path": str(img_path), # ì „ì²´ ê²½ë¡œ ì €ì¥
                    "filename": img_path.name,
                    "score": score,
                    "output_text": text
                }
        
        # ê²°ê³¼ ì €ì¥ (ì ìˆ˜ê°€ 0ì´ì–´ë„ ê°€ì¥ ë‚˜ì€ ê²Œ ì—†ë‹¤ë©´ ê¸°ë¡ë˜ê±°ë‚˜, í•„í„°ë§ ê°€ëŠ¥)
        if best_image_info and best_score > 0:
            selection_db.append(best_image_info)
            # print(f"   âœ… Selected for {action_name}-{obj_name}: {best_image_info['filename']} (Score: {best_score:.2f})")
        else:
            print(f"   âŒ Failed to select for {action_name}-{obj_name} (No valid action detected)")
    # break
# ------------------------------------------------------
# 4. ê²°ê³¼ ì €ì¥
# ------------------------------------------------------
df_selected = pd.DataFrame(selection_db)
df_selected.to_pickle(save_path)

print("\n" + "="*50)
print(f"ğŸ‰ Selection Complete! Saved to {save_path}")
print(f"Total Pairs Processed: {len(df_selected)}")
print("="*50)

# ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°
print(df_selected.head())