import torch
from transformers import Qwen3VLForConditionalGeneration, AutoProcessor
from PIL import Image
from config import AGD20K_PATH, model_name

import glob
import os
import json

# 1. ëª¨ë¸ ë° í”„ë¡œì„¸ì„œ ë¡œë“œ (ì‚¬ìš©ìë‹˜ Qwen3 ì½”ë“œ ê¸°ë°˜)
print(f"ğŸ¤– {model_name} ëª¨ë¸ ë¡œë”©ì¤‘...")

# Qwen3 í´ë˜ìŠ¤ ì‚¬ìš©
model = Qwen3VLForConditionalGeneration.from_pretrained(
    model_name, dtype="auto", device_map="auto"
)
processor = AutoProcessor.from_pretrained(model_name)
tokenizer = processor.tokenizer

print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")

# 36ê°œ í–‰ë™ ë¦¬ìŠ¤íŠ¸ (ì˜ˆì‹œë¡œ ëª‡ ê°œë§Œ ì‘ì„±, ì‹¤ì œë¡œëŠ” 36ê°œ ë‹¤ ì±„ìš°ì‹œë©´ ë©ë‹ˆë‹¤)
actions =  [
    "beat", "brush_with", "catch", "cut_with", "drink_with", "hit", "jump", "lie_on", "look_out", "pack",
    "pick_up", "push", "sip", "stick", "swing", "talk_on", "throw", "wash",
    "boxing", "carry", "cut", "drag", "eat", "hold", "kick", "lift", "open", "peel", "pour", "ride",
    "sit_on", "stir", "take_photo", "text_on", "type_on", "write"
]

patterns = ["*.jpg", "*.jpeg", "*.png", "*.JPG", "*.PNG"]

action_token_map = {}
for action in actions:
    # add_special_tokens=Falseë¡œ ìˆœìˆ˜ ë‹¨ì–´ì˜ IDë§Œ ê°€ì ¸ì˜µë‹ˆë‹¤.
    ids = tokenizer.encode(action, add_special_tokens=False)
    if ids:
        # ì²« ë²ˆì§¸ í† í° IDë§Œ ì‚¬ìš© (ëŒ€ë¶€ë¶„ì˜ ë‹¨ì¼ ë‹¨ì–´ ë™ì‚¬ëŠ” 1ê°œ í† í°ì…ë‹ˆë‹¤)
        action_token_map[action] = ids[0]

print(f"Action Token Map: {action_token_map}")
target_item_dict = {
    "1":"push$bicycle",
    "2" : "hold$badminton_racket",
    "3" : "hold$axe"
}


res = {}
for num in target_item_dict.keys():
    action, object_name = target_item_dict[num].split('$')
    print(f"action, object_name : {action}, {object_name}")
    image_dir = f"{AGD20K_PATH}/Seen/trainset/exocentric/{action}/{object_name}"

    # png, jpg ë“± ì—¬ëŸ¬ í™•ì¥ìë¥¼ ëª¨ë‘ í¬í•¨í•˜ê³  ì‹¶ìœ¼ë©´:
    
    image_paths = []
    for p in patterns:
        image_paths.extend(glob.glob(os.path.join(image_dir, "**", p), recursive=True))
    image_res = {}
    for image_path in image_paths:
        print(f"file name : {image_path}")
        # 3. ì…ë ¥ êµ¬ì„±
        # ì§ˆë¬¸: "ì‚¬ëŒì´ [ê°ì²´]ì™€ ë¬´ì—‡ì„ í•˜ê³  ìˆëŠ”ê°€?" (ë‹¨ë‹µí˜• ìœ ë„)
        query = f"What is the person doing with the {object_name}? Answer with a single verb."

        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "image", "image": image_path},
                    {"type": "text", "text": query},
                ],
            }
        ]

        # 4. ì…ë ¥ ì „ì²˜ë¦¬
        # apply_chat_templateìœ¼ë¡œ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ ìƒì„±
        text = processor.apply_chat_template(
            messages, tokenize=False, add_generation_prompt=True
        )

        # ì´ë¯¸ì§€ ë¡œë“œ ë° ì…ë ¥ í…ì„œ ìƒì„±
        image = Image.open(image_path).convert("RGB")
        inputs = processor(
            text=[text],
            images=[image],
            padding=True,
            return_tensors="pt"
        ).to(model.device)

        # 5. ëª¨ë¸ ì¶”ë¡  (Forward Pass)
        # generate() ëŒ€ì‹  model()ì„ í˜¸ì¶œí•˜ì—¬ raw logitsë¥¼ ì–»ìŠµë‹ˆë‹¤.
        with torch.no_grad():
            outputs = model(**inputs)
            
            # outputs.logits shape: [batch_size, seq_len, vocab_size]
            # ìš°ë¦¬ëŠ” 'ë‹¤ìŒ í† í°'ì„ ì˜ˆì¸¡í•˜ê³  ì‹¶ìœ¼ë¯€ë¡œ ì‹œí€€ìŠ¤ì˜ ê°€ì¥ ë§ˆì§€ë§‰(-1) ë¡œì§“ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
            next_token_logits = outputs.logits[0, -1, :]

        # 6. ë¡œì§“ í”„ë¡œë¹™ (Logit Probing) & ë­í‚¹
        action_scores = {}
        for action, token_id in action_token_map.items():
            # í•´ë‹¹ í–‰ë™ í† í°ì˜ ì ìˆ˜(logit)ë§Œ ì™ ë½‘ì•„ì„œ ì €ì¥
            score = next_token_logits[token_id].item()
            action_scores[action] = score

        # ì ìˆ˜ê°€ ë†’ì€ ìˆœì„œëŒ€ë¡œ ì •ë ¬
        sorted_actions = sorted(action_scores.items(), key=lambda x: x[1], reverse=True)
        best_action = sorted_actions[0][0]

        # --- ê²°ê³¼ ì¶œë ¥ ---
        # print(f"\nğŸ–¼ï¸ Image: {image_path}")
        # print(f"â“ Query: {query}")
        # print(f"\nğŸ“Š One-Token Logit Ranking Result:")
        # for rank, (act, score) in enumerate(sorted_actions, 1):
        #     print(f"{rank}. {act}: {score:.4f}")
        image_res[os.path.basename(image_path)] = action_scores
    res[target_item_dict[num]] = image_res
    
    output_file = "results_vlm_exo_selection.json"

    # JSON íŒŒì¼ë¡œ ì €ì¥
    with open(output_file, "w", encoding="utf-16") as f:
        json.dump(res, f, indent=4, ensure_ascii=False, sort_keys=True)