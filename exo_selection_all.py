import torch
from transformers import Qwen3VLForConditionalGeneration, AutoProcessor
from PIL import Image
from config import AGD20K_PATH, model_name

import glob
import os
import json

# 1. ëª¨ë¸ ë° í”„ë¡œì„¸ì„œ ë¡œë“œ (ì‚¬ìš©ìë‹˜ Qwen3 ì½”ë“œ ê¸°ë°˜)
print(f"ğŸ¤– {model_name} ëª¨ë¸ ë¡œë”©ì¤‘...")

# Qwen3 í´ë˜ìŠ¤ ì‚¬ìš©
model = Qwen3VLForConditionalGeneration.from_pretrained(
    model_name, dtype="auto", device_map="auto"
)
processor = AutoProcessor.from_pretrained(model_name)
tokenizer = processor.tokenizer

print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")

# 36ê°œ í–‰ë™ ë¦¬ìŠ¤íŠ¸ (ì˜ˆì‹œë¡œ ëª‡ ê°œë§Œ ì‘ì„±, ì‹¤ì œë¡œëŠ” 36ê°œ ë‹¤ ì±„ìš°ì‹œë©´ ë©ë‹ˆë‹¤)
actions =  [
    "beat", "brush_with", "catch", "cut_with", "drink_with", "hit", "jump", "lie_on", "look_out", "pack",
    "pick_up", "push", "sip", "stick", "swing", "talk_on", "throw", "wash",
    "boxing", "carry", "cut", "drag", "eat", "hold", "kick", "lift", "open", "peel", "pour", "ride",
    "sit_on", "stir", "take_photo", "text_on", "type_on", "write"
]

patterns = ["*.jpg", "*.jpeg", "*.png", "*.JPG", "*.PNG"]

action_token_map = {}
for action in actions:
    # add_special_tokens=Falseë¡œ ìˆœìˆ˜ ë‹¨ì–´ì˜ IDë§Œ ê°€ì ¸ì˜µë‹ˆë‹¤.
    ids = tokenizer.encode(action, add_special_tokens=False)
    if ids:
        # ì²« ë²ˆì§¸ í† í° IDë§Œ ì‚¬ìš© (ëŒ€ë¶€ë¶„ì˜ ë‹¨ì¼ ë‹¨ì–´ ë™ì‚¬ëŠ” 1ê°œ í† í°ì…ë‹ˆë‹¤)
        action_token_map[action] = ids[0]

print(f"Action Token Map: {action_token_map}")
target_item_dict = {
'1' : 'jump$skis',
'2' : 'jump$skateboard',
'3' : 'jump$surfboard',
'4' : 'jump$snowboard',
'5' : 'peel$carrot',
'6' : 'peel$orange',
'7' : 'peel$banana',
'8' : 'peel$apple',
'9' : 'wash$toothbrush',
'10' : 'wash$cup',
'11' : 'wash$orange',
'12' : 'wash$fork',
'13' : 'wash$wine_glass',
'14' : 'wash$bowl',
'15' : 'wash$knife',
'16' : 'sit_on$chair',
'17' : 'sit_on$couch',
'18' : 'sit_on$bed',
'19' : 'sit_on$bench',
'20' : 'sit_on$bicycle',
'21' : 'sit_on$motorcycle',
'22' : 'sit_on$skateboard',
'23' : 'sit_on$surfboard',
'24' : 'drag$suitcase',
'25' : 'type_on$laptop',
'26' : 'type_on$keyboard',
'27' : 'pack$suitcase',
'28' : 'cut$carrot',
'29' : 'cut$orange',
'30' : 'cut$banana',
'31' : 'cut$apple',
'32' : 'ride$bicycle',
'33' : 'ride$motorcycle',
'34' : 'cut_with$scissors',
'35' : 'cut_with$knife',
'36' : 'sip$bottle',
'37' : 'sip$cup',
'38' : 'sip$wine_glass',
'39' : 'catch$soccer_ball',
'40' : 'catch$frisbee',
'41' : 'catch$rugby_ball',
'42' : 'lie_on$couch',
'43' : 'lie_on$bed',
'44' : 'lie_on$bench',
'45' : 'lie_on$surfboard',
'46' : 'open$bottle',
'47' : 'open$refrigerator',
'48' : 'open$oven',
'49' : 'open$book',
'50' : 'open$suitcase',
'51' : 'open$microwave',
'52' : 'text_on$cell_phone',
'53' : 'boxing$punching_bag',
'54' : 'stir$bowl',
'55' : 'hit$baseball_bat',
'56' : 'hit$tennis_racket',
'57' : 'hit$hammer',
'58' : 'hit$axe',
'59' : 'write$pen',
'60' : 'take_photo$cell_phone',
'61' : 'take_photo$camera',
'62' : 'pour$bottle',
'63' : 'pour$cup',
'64' : 'pour$wine_glass',
'65' : 'kick$soccer_ball',
'66' : 'kick$rugby_ball',
'67' : 'kick$punching_bag',
'68' : 'pick_up$skis',
'69' : 'pick_up$suitcase',
'70' : 'carry$skis',
'71' : 'carry$skateboard',
'72' : 'carry$surfboard',
'73' : 'carry$snowboard',
'74' : 'stick$fork',
'75' : 'stick$knife',
'76' : 'look_out$binoculars',
'77' : 'hold$toothbrush',
'78' : 'hold$baseball_bat',
'79' : 'hold$bottle',
'80' : 'hold$cup',
'81' : 'hold$scissors',
'82' : 'hold$skis',
'83' : 'hold$tennis_racket',
'84' : 'hold$book',
'85' : 'hold$frisbee',
'86' : 'hold$golf_clubs',
'87' : 'hold$hammer',
'88' : 'hold$fork',
'89' : 'hold$badminton_racket',
'90' : 'hold$suitcase',
'91' : 'hold$wine_glass',
'92' : 'hold$skateboard',
'93' : 'hold$axe',
'94' : 'hold$surfboard',
'95' : 'hold$snowboard',
'96' : 'hold$bowl',
'97' : 'hold$knife',
'98' : 'drink_with$bottle',
'99' : 'drink_with$cup',
'100' : 'drink_with$wine_glass',
'101' : 'brush_with$toothbrush',
'102' : 'throw$soccer_ball',
'103' : 'throw$javelin',
'104' : 'throw$frisbee',
'105' : 'throw$discus',
'106' : 'throw$rugby_ball',
'107' : 'throw$baseball',
'108' : 'throw$basketball',
'109' : 'beat$drum',
'110' : 'lift$fork',
'111' : 'talk_on$cell_phone',
'112' : 'push$bicycle',
'113' : 'push$motorcycle',
'114' : 'eat$hot_dog',
'115' : 'eat$carrot',
'116' : 'eat$orange',
'117' : 'eat$banana',
'118' : 'eat$broccoli',
'119' : 'eat$apple',
'120' : 'swing$baseball_bat',
'121' : 'swing$tennis_racket',
'122' : 'swing$golf_clubs',
'123' : 'swing$badminton_racket',
}


res = {}
for num in target_item_dict.keys():
    action, object_name = target_item_dict[num].split('$')
    print(f"action, object_name : {action}, {object_name}")
    image_dir = f"{AGD20K_PATH}/Seen/trainset/exocentric/{action}/{object_name}"

    # png, jpg ë“± ì—¬ëŸ¬ í™•ì¥ìë¥¼ ëª¨ë‘ í¬í•¨í•˜ê³  ì‹¶ìœ¼ë©´:
    
    image_paths = []
    for p in patterns:
        image_paths.extend(glob.glob(os.path.join(image_dir, "**", p), recursive=True))
    image_res = {}
    for image_path in image_paths:
        print(f"file name : {image_path}")
        # 3. ì…ë ¥ êµ¬ì„±
        # ì§ˆë¬¸: "ì‚¬ëŒì´ [ê°ì²´]ì™€ ë¬´ì—‡ì„ í•˜ê³  ìˆëŠ”ê°€?" (ë‹¨ë‹µí˜• ìœ ë„)
        query = f"What is the person doing with the {object_name}? Answer with a single verb."

        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "image", "image": image_path},
                    {"type": "text", "text": query},
                ],
            }
        ]

        # 4. ì…ë ¥ ì „ì²˜ë¦¬
        # apply_chat_templateìœ¼ë¡œ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ ìƒì„±
        text = processor.apply_chat_template(
            messages, tokenize=False, add_generation_prompt=True
        )

        # ì´ë¯¸ì§€ ë¡œë“œ ë° ì…ë ¥ í…ì„œ ìƒì„±
        image = Image.open(image_path).convert("RGB")
        inputs = processor(
            text=[text],
            images=[image],
            padding=True,
            return_tensors="pt"
        ).to(model.device)

        # 5. ëª¨ë¸ ì¶”ë¡  (Forward Pass)
        # generate() ëŒ€ì‹  model()ì„ í˜¸ì¶œí•˜ì—¬ raw logitsë¥¼ ì–»ìŠµë‹ˆë‹¤.
        with torch.no_grad():
            outputs = model(**inputs)
            
            # outputs.logits shape: [batch_size, seq_len, vocab_size]
            # ìš°ë¦¬ëŠ” 'ë‹¤ìŒ í† í°'ì„ ì˜ˆì¸¡í•˜ê³  ì‹¶ìœ¼ë¯€ë¡œ ì‹œí€€ìŠ¤ì˜ ê°€ì¥ ë§ˆì§€ë§‰(-1) ë¡œì§“ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
            next_token_logits = outputs.logits[0, -1, :]

        # 6. ë¡œì§“ í”„ë¡œë¹™ (Logit Probing) & ë­í‚¹
        action_scores = {}
        for action, token_id in action_token_map.items():
            # í•´ë‹¹ í–‰ë™ í† í°ì˜ ì ìˆ˜(logit)ë§Œ ì™ ë½‘ì•„ì„œ ì €ì¥
            score = next_token_logits[token_id].item()
            action_scores[action] = score

        # ì ìˆ˜ê°€ ë†’ì€ ìˆœì„œëŒ€ë¡œ ì •ë ¬
        sorted_actions = sorted(action_scores.items(), key=lambda x: x[1], reverse=True)
        best_action = sorted_actions[0][0]

        # --- ê²°ê³¼ ì¶œë ¥ ---
        # print(f"\nğŸ–¼ï¸ Image: {image_path}")
        # print(f"â“ Query: {query}")
        # print(f"\nğŸ“Š One-Token Logit Ranking Result:")
        # for rank, (act, score) in enumerate(sorted_actions, 1):
        #     print(f"{rank}. {act}: {score:.4f}")
        image_res[os.path.basename(image_path)] = action_scores
    res[target_item_dict[num]] = image_res
    
    output_file = "3B_exo_selection_all.json"

    # JSON íŒŒì¼ë¡œ ì €ì¥
    with open(output_file, "w", encoding="utf-16") as f:
        json.dump(res, f, indent=4, ensure_ascii=False, sort_keys=True)