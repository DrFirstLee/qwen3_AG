{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39a9770c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– Qwen/Qwen3-VL-2B-Instruct ëª¨ë¸ ë¡œë”©ì¤‘...\n",
      "âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import Qwen3VLForConditionalGeneration, AutoProcessor\n",
    "from PIL import Image\n",
    "from config import AGD20K_PATH\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# 1. ëª¨ë¸ ë° í”„ë¡œì„¸ì„œ ë¡œë“œ (ì‚¬ìš©ìë‹˜ Qwen3 ì½”ë“œ ê¸°ë°˜)\n",
    "model_name = \"Qwen/Qwen3-VL-2B-Instruct\" # ë˜ëŠ” ì‹¤ì œ ì‚¬ìš©í•˜ì‹œëŠ” ê²½ë¡œ\n",
    "print(f\"ğŸ¤– {model_name} ëª¨ë¸ ë¡œë”©ì¤‘...\")\n",
    "\n",
    "# Qwen3 í´ë˜ìŠ¤ ì‚¬ìš©\n",
    "model = Qwen3VLForConditionalGeneration.from_pretrained(\n",
    "    model_name, dtype=\"auto\", device_map=\"auto\"\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(model_name)\n",
    "tokenizer = processor.tokenizer\n",
    "\n",
    "print(\"âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45bddee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Token Map: {'beat': 22227, 'brush_with': 36061, 'catch': 7173, 'cut_with': 10242, 'drink_with': 97327, 'hit': 22492, 'jump': 43296, 'lie_on': 11567, 'look_out': 7201, 'pack': 4748, 'pick_up': 29245, 'push': 9077, 'sip': 88250, 'stick': 29033, 'swing': 85284, 'talk_on': 35241, 'throw': 7119, 'wash': 69445, 'boxing': 89174, 'carry': 73765, 'cut': 10242, 'drag': 33931, 'eat': 32066, 'hold': 6282, 'kick': 55793, 'lift': 34969, 'open': 2508, 'peel': 375, 'pour': 54519, 'ride': 1399, 'sit_on': 46865, 'stir': 267, 'take_photo': 22769, 'text_on': 1318, 'type_on': 1313, 'write': 4934}\n"
     ]
    }
   ],
   "source": [
    "# 36ê°œ í–‰ë™ ë¦¬ìŠ¤íŠ¸ (ì˜ˆì‹œë¡œ ëª‡ ê°œë§Œ ì‘ì„±, ì‹¤ì œë¡œëŠ” 36ê°œ ë‹¤ ì±„ìš°ì‹œë©´ ë©ë‹ˆë‹¤)\n",
    "actions =  [\n",
    "    \"beat\", \"brush_with\", \"catch\", \"cut_with\", \"drink_with\", \"hit\", \"jump\", \"lie_on\", \"look_out\", \"pack\",\n",
    "    \"pick_up\", \"push\", \"sip\", \"stick\", \"swing\", \"talk_on\", \"throw\", \"wash\",\n",
    "    \"boxing\", \"carry\", \"cut\", \"drag\", \"eat\", \"hold\", \"kick\", \"lift\", \"open\", \"peel\", \"pour\", \"ride\",\n",
    "    \"sit_on\", \"stir\", \"take_photo\", \"text_on\", \"type_on\", \"write\"\n",
    "]\n",
    "\n",
    "patterns = [\"*.jpg\", \"*.jpeg\", \"*.png\", \"*.JPG\", \"*.PNG\"]\n",
    "\n",
    "action_token_map = {}\n",
    "for action in actions:\n",
    "    # add_special_tokens=Falseë¡œ ìˆœìˆ˜ ë‹¨ì–´ì˜ IDë§Œ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "    ids = tokenizer.encode(action, add_special_tokens=False)\n",
    "    if ids:\n",
    "        # ì²« ë²ˆì§¸ í† í° IDë§Œ ì‚¬ìš© (ëŒ€ë¶€ë¶„ì˜ ë‹¨ì¼ ë‹¨ì–´ ë™ì‚¬ëŠ” 1ê°œ í† í°ì…ë‹ˆë‹¤)\n",
    "        action_token_map[action] = ids[0]\n",
    "\n",
    "print(f\"Action Token Map: {action_token_map}\")\n",
    "target_item_dict = {\n",
    "    \"1\":\"push$bicycle\",\n",
    "    \"2\" : \"hold$badminton_racket\",\n",
    "    \"3\" : \"hold$axe\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd97fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action, object_name : push, bicycle\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_013423.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_009954.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_013958.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_006768.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_011577.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_007511.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_001822.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_004220.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_009642.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_010795.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_004543.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_007122.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_001798.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_009562.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_010251.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_010959.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_006594.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_010721.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_001280.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_008405.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_003651.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_006220.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_007828.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_006044.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_008584.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_012653.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_005064.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_010529.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_004740.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_013710.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_010614.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_008897.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_009558.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_004366.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_008599.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_003919.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_011146.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_008917.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_001458.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_000820.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_010074.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_013304.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_011700.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_013392.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_006549.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_012603.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_012343.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_000800.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_001043.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_012006.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_003570.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_008083.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_012840.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_010286.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_002585.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_005388.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_007525.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_006504.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_004885.jpg\n",
      "action, object_name : hold, badminton_racket\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/hold/badminton_racket/hold_badminton_racket_002323.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/hold/badminton_racket/hold_badminton_racket_007309.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/hold/badminton_racket/hold_badminton_racket_011407.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/hold/badminton_racket/hold_badminton_racket_012140.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/hold/badminton_racket/hold_badminton_racket_012015.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/hold/badminton_racket/hold_badminton_racket_010197.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/hold/badminton_racket/hold_badminton_racket_011723.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/hold/badminton_racket/hold_badminton_racket_008125.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/hold/badminton_racket/hold_badminton_racket_006555.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/hold/badminton_racket/hold_badminton_racket_011862.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/hold/badminton_racket/hold_badminton_racket_000882.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/hold/badminton_racket/hold_badminton_racket_014121.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/hold/badminton_racket/hold_badminton_racket_002952.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/hold/badminton_racket/hold_badminton_racket_003632.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/hold/badminton_racket/hold_badminton_racket_003341.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/hold/badminton_racket/hold_badminton_racket_006615.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/hold/badminton_racket/hold_badminton_racket_004682.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/hold/badminton_racket/hold_badminton_racket_003971.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/hold/badminton_racket/hold_badminton_racket_011010.jpg\n",
      "action, object_name : hold, axe\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/hold/axe/hold_axe_011805.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/hold/axe/hold_axe_011424.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/hold/axe/hold_axe_010133.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/hold/axe/hold_axe_006509.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/hold/axe/hold_axe_008102.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/hold/axe/hold_axe_001123.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/hold/axe/hold_axe_000856.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/hold/axe/hold_axe_003505.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/hold/axe/hold_axe_006933.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/hold/axe/hold_axe_009894.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/hold/axe/hold_axe_006372.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/hold/axe/hold_axe_000384.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/hold/axe/hold_axe_013837.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/hold/axe/hold_axe_012581.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/hold/axe/hold_axe_009211.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/hold/axe/hold_axe_008636.jpg\n",
      "file name : /home/DATA/AGD20K/Seen/trainset/exocentric/hold/axe/hold_axe_012759.jpg\n"
     ]
    }
   ],
   "source": [
    "res = {}\n",
    "for num in target_item_dict.keys():\n",
    "    action, object_name = target_item_dict[num].split('$')\n",
    "    print(f\"action, object_name : {action}, {object_name}\")\n",
    "    image_dir = f\"{AGD20K_PATH}/Seen/trainset/exocentric/{action}/{object_name}\"\n",
    "\n",
    "    # png, jpg ë“± ì—¬ëŸ¬ í™•ì¥ìë¥¼ ëª¨ë‘ í¬í•¨í•˜ê³  ì‹¶ìœ¼ë©´:\n",
    "    \n",
    "    image_paths = []\n",
    "    for p in patterns:\n",
    "        image_paths.extend(glob.glob(os.path.join(image_dir, \"**\", p), recursive=True))\n",
    "    image_res = {}\n",
    "    for image_path in image_paths:\n",
    "        print(f\"file name : {image_path}\")\n",
    "        # 3. ì…ë ¥ êµ¬ì„±\n",
    "        # ì§ˆë¬¸: \"ì‚¬ëŒì´ [ê°ì²´]ì™€ ë¬´ì—‡ì„ í•˜ê³  ìˆëŠ”ê°€?\" (ë‹¨ë‹µí˜• ìœ ë„)\n",
    "        query = f\"What is the person doing with the {object_name}? Answer with a single verb.\"\n",
    "\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"image\", \"image\": image_path},\n",
    "                    {\"type\": \"text\", \"text\": query},\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        # 4. ì…ë ¥ ì „ì²˜ë¦¬\n",
    "        # apply_chat_templateìœ¼ë¡œ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "        text = processor.apply_chat_template(\n",
    "            messages, tokenize=False, add_generation_prompt=True\n",
    "        )\n",
    "\n",
    "        # ì´ë¯¸ì§€ ë¡œë“œ ë° ì…ë ¥ í…ì„œ ìƒì„±\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        inputs = processor(\n",
    "            text=[text],\n",
    "            images=[image],\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(model.device)\n",
    "\n",
    "        # 5. ëª¨ë¸ ì¶”ë¡  (Forward Pass)\n",
    "        # generate() ëŒ€ì‹  model()ì„ í˜¸ì¶œí•˜ì—¬ raw logitsë¥¼ ì–»ìŠµë‹ˆë‹¤.\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "            # outputs.logits shape: [batch_size, seq_len, vocab_size]\n",
    "            # ìš°ë¦¬ëŠ” 'ë‹¤ìŒ í† í°'ì„ ì˜ˆì¸¡í•˜ê³  ì‹¶ìœ¼ë¯€ë¡œ ì‹œí€€ìŠ¤ì˜ ê°€ì¥ ë§ˆì§€ë§‰(-1) ë¡œì§“ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "            next_token_logits = outputs.logits[0, -1, :]\n",
    "\n",
    "        # 6. ë¡œì§“ í”„ë¡œë¹™ (Logit Probing) & ë­í‚¹\n",
    "        action_scores = {}\n",
    "        for action, token_id in action_token_map.items():\n",
    "            # í•´ë‹¹ í–‰ë™ í† í°ì˜ ì ìˆ˜(logit)ë§Œ ì™ ë½‘ì•„ì„œ ì €ì¥\n",
    "            score = next_token_logits[token_id].item()\n",
    "            action_scores[action] = score\n",
    "\n",
    "        # ì ìˆ˜ê°€ ë†’ì€ ìˆœì„œëŒ€ë¡œ ì •ë ¬\n",
    "        sorted_actions = sorted(action_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        best_action = sorted_actions[0][0]\n",
    "\n",
    "        # --- ê²°ê³¼ ì¶œë ¥ ---\n",
    "        # print(f\"\\nğŸ–¼ï¸ Image: {image_path}\")\n",
    "        # print(f\"â“ Query: {query}\")\n",
    "        # print(f\"\\nğŸ“Š One-Token Logit Ranking Result:\")\n",
    "        # for rank, (act, score) in enumerate(sorted_actions, 1):\n",
    "        #     print(f\"{rank}. {act}: {score:.4f}\")\n",
    "        image_res[os.path.basename(image_path)] = action_scores\n",
    "    res[target_item_dict[num]] = image_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961afbc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc4e9b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Token Map: {'beat': 22227, 'brush_with': 36061, 'catch': 7173, 'cut_with': 10242, 'drink_with': 97327, 'hit': 22492, 'jump': 43296, 'lie_on': 11567, 'look_out': 7201, 'pack': 4748, 'pick_up': 29245, 'push': 9077, 'sip': 88250, 'stick': 29033, 'swing': 85284, 'talk_on': 35241, 'throw': 7119, 'wash': 69445, 'boxing': 89174, 'carry': 73765, 'cut': 10242, 'drag': 33931, 'eat': 32066, 'hold': 6282, 'kick': 55793, 'lift': 34969, 'open': 2508, 'peel': 375, 'pour': 54519, 'ride': 1399, 'sit_on': 46865, 'stir': 267, 'take_photo': 22769, 'text_on': 1318, 'type_on': 1313, 'write': 4934}\n",
      "\n",
      "ğŸ–¼ï¸ Image: /home/bongo/porter_notebook/research/WSAG-PLSP/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_007122.jpg\n",
      "â“ Query: What is the person doing with the bicycle? Answer with a single verb.\n",
      "\n",
      "ğŸ“Š One-Token Logit Ranking Result:\n",
      "1. push: 22.1250\n",
      "2. ride: 21.6250\n",
      "3. carry: 15.6250\n",
      "4. stir: 14.8125\n",
      "5. pack: 14.3125\n",
      "6. drag: 13.3750\n",
      "7. take_photo: 12.6250\n",
      "8. peel: 11.6875\n",
      "9. hold: 11.5000\n",
      "10. boxing: 11.1875\n",
      "11. look_out: 11.1250\n",
      "12. sit_on: 10.9375\n",
      "13. throw: 10.7500\n",
      "14. jump: 10.6250\n",
      "15. lift: 10.5625\n",
      "16. pour: 10.1875\n",
      "17. text_on: 9.6250\n",
      "18. brush_with: 9.0000\n",
      "19. pick_up: 9.0000\n",
      "20. stick: 8.5000\n",
      "21. open: 8.5000\n",
      "22. catch: 8.3750\n",
      "23. kick: 8.1875\n",
      "24. lie_on: 8.0000\n",
      "25. swing: 7.9688\n",
      "26. talk_on: 7.6250\n",
      "27. eat: 7.2812\n",
      "28. type_on: 6.7812\n",
      "29. cut_with: 6.6562\n",
      "30. cut: 6.6562\n",
      "31. hit: 6.2188\n",
      "32. drink_with: 6.1875\n",
      "33. beat: 5.9375\n",
      "34. wash: 5.5000\n",
      "35. write: 3.2031\n",
      "36. sip: -0.0562\n",
      "\n",
      "ğŸ† Best Action Prediction: 'push'\n"
     ]
    }
   ],
   "source": [
    "# --- ì„¤ì • ---\n",
    "image_path = \"/home/bongo/porter_notebook/research/WSAG-PLSP/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_007122.jpg\"\n",
    "target_item = \"bicycle\"\n",
    "\n",
    "# 36ê°œ í–‰ë™ ë¦¬ìŠ¤íŠ¸ (ì˜ˆì‹œë¡œ ëª‡ ê°œë§Œ ì‘ì„±, ì‹¤ì œë¡œëŠ” 36ê°œ ë‹¤ ì±„ìš°ì‹œë©´ ë©ë‹ˆë‹¤)\n",
    "actions =  [\n",
    "    \"beat\", \"brush_with\", \"catch\", \"cut_with\", \"drink_with\", \"hit\", \"jump\", \"lie_on\", \"look_out\", \"pack\",\n",
    "    \"pick_up\", \"push\", \"sip\", \"stick\", \"swing\", \"talk_on\", \"throw\", \"wash\",\n",
    "    \"boxing\", \"carry\", \"cut\", \"drag\", \"eat\", \"hold\", \"kick\", \"lift\", \"open\", \"peel\", \"pour\", \"ride\",\n",
    "    \"sit_on\", \"stir\", \"take_photo\", \"text_on\", \"type_on\", \"write\"\n",
    "]\n",
    "\n",
    "# 2. í–‰ë™ ë‹¨ì–´ë“¤ì„ í† í° IDë¡œ ë³€í™˜ (ë¯¸ë¦¬ ì¤€ë¹„)\n",
    "# ì£¼ì˜: Qwen í† í¬ë‚˜ì´ì €ê°€ ë‹¨ì–´ë¥¼ ì–´ë–»ê²Œ ìª¼ê°œëŠ”ì§€ í™•ì¸ í•„ìš”. ë³´í†µ ì²« í† í°ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "action_token_map = {}\n",
    "for action in actions:\n",
    "    # add_special_tokens=Falseë¡œ ìˆœìˆ˜ ë‹¨ì–´ì˜ IDë§Œ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "    ids = tokenizer.encode(action, add_special_tokens=False)\n",
    "    if ids:\n",
    "        # ì²« ë²ˆì§¸ í† í° IDë§Œ ì‚¬ìš© (ëŒ€ë¶€ë¶„ì˜ ë‹¨ì¼ ë‹¨ì–´ ë™ì‚¬ëŠ” 1ê°œ í† í°ì…ë‹ˆë‹¤)\n",
    "        action_token_map[action] = ids[0]\n",
    "\n",
    "print(f\"Action Token Map: {action_token_map}\")\n",
    "\n",
    "\n",
    "# 3. ì…ë ¥ êµ¬ì„±\n",
    "# ì§ˆë¬¸: \"ì‚¬ëŒì´ [ê°ì²´]ì™€ ë¬´ì—‡ì„ í•˜ê³  ìˆëŠ”ê°€?\" (ë‹¨ë‹µí˜• ìœ ë„)\n",
    "query = f\"What is the person doing with the {target_item}? Answer with a single verb.\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\", \"image\": image_path},\n",
    "            {\"type\": \"text\", \"text\": query},\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "# 4. ì…ë ¥ ì „ì²˜ë¦¬\n",
    "# apply_chat_templateìœ¼ë¡œ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "text = processor.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "# ì´ë¯¸ì§€ ë¡œë“œ ë° ì…ë ¥ í…ì„œ ìƒì„±\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "inputs = processor(\n",
    "    text=[text],\n",
    "    images=[image],\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\"\n",
    ").to(model.device)\n",
    "\n",
    "# 5. ëª¨ë¸ ì¶”ë¡  (Forward Pass)\n",
    "# generate() ëŒ€ì‹  model()ì„ í˜¸ì¶œí•˜ì—¬ raw logitsë¥¼ ì–»ìŠµë‹ˆë‹¤.\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    \n",
    "    # outputs.logits shape: [batch_size, seq_len, vocab_size]\n",
    "    # ìš°ë¦¬ëŠ” 'ë‹¤ìŒ í† í°'ì„ ì˜ˆì¸¡í•˜ê³  ì‹¶ìœ¼ë¯€ë¡œ ì‹œí€€ìŠ¤ì˜ ê°€ì¥ ë§ˆì§€ë§‰(-1) ë¡œì§“ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "    next_token_logits = outputs.logits[0, -1, :]\n",
    "\n",
    "# 6. ë¡œì§“ í”„ë¡œë¹™ (Logit Probing) & ë­í‚¹\n",
    "action_scores = {}\n",
    "for action, token_id in action_token_map.items():\n",
    "    # í•´ë‹¹ í–‰ë™ í† í°ì˜ ì ìˆ˜(logit)ë§Œ ì™ ë½‘ì•„ì„œ ì €ì¥\n",
    "    score = next_token_logits[token_id].item()\n",
    "    action_scores[action] = score\n",
    "\n",
    "# ì ìˆ˜ê°€ ë†’ì€ ìˆœì„œëŒ€ë¡œ ì •ë ¬\n",
    "sorted_actions = sorted(action_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "best_action = sorted_actions[0][0]\n",
    "\n",
    "# --- ê²°ê³¼ ì¶œë ¥ ---\n",
    "print(f\"\\nğŸ–¼ï¸ Image: {image_path}\")\n",
    "print(f\"â“ Query: {query}\")\n",
    "print(f\"\\nğŸ“Š One-Token Logit Ranking Result:\")\n",
    "for rank, (act, score) in enumerate(sorted_actions, 1):\n",
    "    print(f\"{rank}. {act}: {score:.4f}\")\n",
    "\n",
    "print(f\"\\nğŸ† Best Action Prediction: '{best_action}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "935aaed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4934"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dcf1a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.2031, device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token_logits[token_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57476848",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7829192e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongo/anaconda3/envs/qwen3/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import Qwen3VLForConditionalGeneration, AutoProcessor\n",
    "\n",
    "# default: Load the model on the available device(s)\n",
    "model = Qwen3VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen3-VL-2B-Instruct\", dtype=\"auto\", device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79432462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Yes']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# We recommend enabling flash_attention_2 for better acceleration and memory saving, especially in multi-image and video scenarios.\n",
    "# model = Qwen3VLForConditionalGeneration.from_pretrained(\n",
    "#     \"Qwen/Qwen3-VL-2B-Instruct\",\n",
    "#     dtype=torch.bfloat16,\n",
    "#     attn_implementation=\"flash_attention_2\",\n",
    "#     device_map=\"auto\",\n",
    "# )\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen3-VL-2B-Instruct\")\n",
    "\n",
    "action_text = 'ride'\n",
    "target_item = 'bicycle'\n",
    "# 1. ì§ˆë¬¸ êµ¬ì„±: ëª…í™•í•˜ê²Œ Yes/No ëŒ€ë‹µì„ ìœ ë„\n",
    "# Qwen í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì— ë§ì¶° ì§ˆë¬¸\n",
    "query = f\"Is the person {action_text} {target_item} in this image? Answer with Yes or No.\"\n",
    "image_path = \"/home/bongo/porter_notebook/research/WSAG-PLSP/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_007122.jpg\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"image\",\n",
    "                \"image\": image_path,\n",
    "            },\n",
    "            {\"type\": \"text\", \"text\": query},\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "# Preparation for inference\n",
    "inputs = processor.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=True,\n",
    "    return_dict=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "inputs = inputs.to(model.device)\n",
    "\n",
    "# Inference: Generation of the output\n",
    "generated_ids = model.generate(**inputs, max_new_tokens=128)\n",
    "generated_ids_trimmed = [\n",
    "    out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "]\n",
    "output_text = processor.batch_decode(\n",
    "    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    ")\n",
    "print(output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9af4938e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"/home/bongo/porter_notebook/research/WSAG-PLSP/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_007122.jpg\"\n",
    "\n",
    "# image_path = \"/home/bongo/porter_notebook/research/WSAG-PLSP/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_012603.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d33f6b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1fe068b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Is the person eat bicycle in this image? Answer with Yes or No.\n",
      "Action Check: eat\n",
      "probability(Yes): 0.8355\n",
      "probability(No): 0.1645\n",
      "âœ… íŒë‹¨: ë§ìŠµë‹ˆë‹¤ (True) : 0.8354835510253906\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\"Is the person [action]?\" ì§ˆë¬¸ì— ëŒ€í•´ \n",
    "ëª¨ë¸ì´ 'Yes'ë¼ê³  ëŒ€ë‹µí•  í™•ë¥ ì„ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "\"\"\"\n",
    "action_text = 'eat'\n",
    "target_item = 'bicycle'\n",
    "\n",
    "\n",
    "image_path = \"/home/bongo/porter_notebook/research/WSAG-PLSP/AGD20K/Seen/trainset/exocentric/push/bicycle/push_bicycle_007122.jpg\"\n",
    "\n",
    "# 2. ì§ˆë¬¸ êµ¬ì„±\n",
    "# \"Answer with Yes or No.\"ë¥¼ ëª…ì‹œí•˜ì—¬ ëª¨ë¸ì´ ë‹¤ë¥¸ ë§ì„ í•  í™•ë¥ ì„ ì¤„ì…ë‹ˆë‹¤.\n",
    "query = f\"Is the person {action_text} {target_item} in this image? Answer with Yes or No.\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\", \"image\": image_path},\n",
    "            {\"type\": \"text\", \"text\": query},\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "# 3. ì…ë ¥ ì²˜ë¦¬ (Generation ì½”ë“œì™€ ë™ì¼í•œ ë°©ì‹ ì‚¬ìš©)\n",
    "# tokenize=Trueë¡œ ì„¤ì •í•˜ì—¬ ë°”ë¡œ í…ì„œë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "inputs = processor.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=True, # <|im_start|>assistant\\n ê¹Œì§€ ë¶™ì—¬ì¤Œ\n",
    "    return_dict=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "inputs = inputs.to(model.device)\n",
    "\n",
    "# 4. Forward Pass (ì¶”ë¡ )\n",
    "# model.generate() ëŒ€ì‹  model()ì„ í˜¸ì¶œí•˜ì—¬ í™•ë¥  ë¶„í¬(Logits)ë¥¼ ì–»ìŠµë‹ˆë‹¤.\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    \n",
    "    # 5. ë§ˆì§€ë§‰ í† í°ì˜ Logits ì¶”ì¶œ\n",
    "    # outputs.logits í˜•íƒœ: [Batch_Size, Sequence_Length, Vocab_Size]\n",
    "    # ìš°ë¦¬ëŠ” ë¬¸ì¥ì˜ ë§¨ ë§ˆì§€ë§‰ í† í°(ë‹¤ìŒì— ì˜¬ ë‹¨ì–´ ì˜ˆì¸¡)ì˜ í™•ë¥ ì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "    next_token_logits = outputs.logits[:, -1, :]\n",
    "    \n",
    "    # 6. 'Yes'ì™€ 'No' í† í° ID ì°¾ê¸°\n",
    "    # Qwen í† í¬ë‚˜ì´ì €ì—ì„œ \"Yes\"ì™€ \"No\"ì˜ IDë¥¼ ì°¾ìŠµë‹ˆë‹¤.\n",
    "    # add_special_tokens=Falseë¡œ í•´ì•¼ ìˆœìˆ˜ ë‹¨ì–´ IDë§Œ ë‚˜ì˜µë‹ˆë‹¤.\n",
    "    yes_token_id = processor.tokenizer.encode(\"Yes\", add_special_tokens=False)[0]\n",
    "    no_token_id = processor.tokenizer.encode(\"No\", add_special_tokens=False)[0]\n",
    "    \n",
    "    # 7. ì ìˆ˜ ì¶”ì¶œ\n",
    "    yes_score = next_token_logits[0, yes_token_id].item()\n",
    "    no_score = next_token_logits[0, no_token_id].item()\n",
    "    \n",
    "    # 8. í™•ë¥  ê³„ì‚° (Softmax)\n",
    "    # ì „ì²´ ë‹¨ì–´ì¥ì´ ì•„ë‹ˆë¼, ì˜¤ì§ Yesì™€ No ë‘ í›„ë³´êµ° ì‚¬ì´ì—ì„œì˜ í™•ë¥ ì„ êµ¬í•©ë‹ˆë‹¤.\n",
    "    probs = torch.softmax(torch.tensor([yes_score, no_score]), dim=0)\n",
    "    yes_prob = probs[0].item()\n",
    "    no_prob = probs[1].item()\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Action Check: {action_text}\")\n",
    "print(f\"probability(Yes): {yes_prob:.4f}\")\n",
    "print(f\"probability(No): {no_prob:.4f}\")\n",
    "\n",
    "if yes_prob > 0.5:\n",
    "    print(f\"âœ… íŒë‹¨: ë§ìŠµë‹ˆë‹¤ (True) : {yes_prob}\")\n",
    "else:\n",
    "    print(f\"âŒ íŒë‹¨: ì•„ë‹™ë‹ˆë‹¤ (False) : {yes_prob}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "875a9775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yes_no_score(image_path, action_text,target_item):\n",
    "    query = f\"Is the person {action_text} {target_item} in this image? Answer with Yes or No.\"\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\", \"image\": image_path},\n",
    "                {\"type\": \"text\", \"text\": query},\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # 3. ì…ë ¥ ì²˜ë¦¬ (Generation ì½”ë“œì™€ ë™ì¼í•œ ë°©ì‹ ì‚¬ìš©)\n",
    "    # tokenize=Trueë¡œ ì„¤ì •í•˜ì—¬ ë°”ë¡œ í…ì„œë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "    inputs = processor.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True, # <|im_start|>assistant\\n ê¹Œì§€ ë¶™ì—¬ì¤Œ\n",
    "        return_dict=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    inputs = inputs.to(model.device)\n",
    "\n",
    "    # 4. Forward Pass (ì¶”ë¡ )\n",
    "    # model.generate() ëŒ€ì‹  model()ì„ í˜¸ì¶œí•˜ì—¬ í™•ë¥  ë¶„í¬(Logits)ë¥¼ ì–»ìŠµë‹ˆë‹¤.\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        # 5. ë§ˆì§€ë§‰ í† í°ì˜ Logits ì¶”ì¶œ\n",
    "        # outputs.logits í˜•íƒœ: [Batch_Size, Sequence_Length, Vocab_Size]\n",
    "        # ìš°ë¦¬ëŠ” ë¬¸ì¥ì˜ ë§¨ ë§ˆì§€ë§‰ í† í°(ë‹¤ìŒì— ì˜¬ ë‹¨ì–´ ì˜ˆì¸¡)ì˜ í™•ë¥ ì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "        next_token_logits = outputs.logits[:, -1, :]\n",
    "        \n",
    "        # 6. 'Yes'ì™€ 'No' í† í° ID ì°¾ê¸°\n",
    "        # Qwen í† í¬ë‚˜ì´ì €ì—ì„œ \"Yes\"ì™€ \"No\"ì˜ IDë¥¼ ì°¾ìŠµë‹ˆë‹¤.\n",
    "        # add_special_tokens=Falseë¡œ í•´ì•¼ ìˆœìˆ˜ ë‹¨ì–´ IDë§Œ ë‚˜ì˜µë‹ˆë‹¤.\n",
    "        yes_token_id = processor.tokenizer.encode(\"Yes\", add_special_tokens=False)[0]\n",
    "        no_token_id = processor.tokenizer.encode(\"No\", add_special_tokens=False)[0]\n",
    "        \n",
    "        # 7. ì ìˆ˜ ì¶”ì¶œ\n",
    "        yes_score = next_token_logits[0, yes_token_id].item()\n",
    "        no_score = next_token_logits[0, no_token_id].item()\n",
    "        \n",
    "        # 8. í™•ë¥  ê³„ì‚° (Softmax)\n",
    "        # ì „ì²´ ë‹¨ì–´ì¥ì´ ì•„ë‹ˆë¼, ì˜¤ì§ Yesì™€ No ë‘ í›„ë³´êµ° ì‚¬ì´ì—ì„œì˜ í™•ë¥ ì„ êµ¬í•©ë‹ˆë‹¤.\n",
    "        probs = torch.softmax(torch.tensor([yes_score, no_score]), dim=0)\n",
    "        yes_prob = probs[0].item()\n",
    "        no_prob = probs[1].item()\n",
    "\n",
    "    # ê²°ê³¼ ì¶œë ¥\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Action Check: {action_text}\")\n",
    "    print(f\"probability(Yes): {yes_prob:.4f}\")\n",
    "    print(f\"probability(No): {no_prob:.4f}\")\n",
    "\n",
    "    if yes_prob > 0.5:\n",
    "        print(f\"âœ… {action_text} íŒë‹¨: ë§ìŠµë‹ˆë‹¤ (True)\")\n",
    "    else:\n",
    "        print(\"âŒ {action_text}  íŒë‹¨: ì•„ë‹™ë‹ˆë‹¤ (False)\")\n",
    "\n",
    "    return yes_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31506f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Is the person beat bicyle in this image? Answer with Yes or No.\n",
      "Action Check: beat\n",
      "probability(Yes): 0.9399\n",
      "probability(No): 0.0601\n",
      "âœ… beat íŒë‹¨: ë§ìŠµë‹ˆë‹¤ (True)\n",
      "Query: Is the person brush_with bicyle in this image? Answer with Yes or No.\n",
      "Action Check: brush_with\n",
      "probability(Yes): 0.7982\n",
      "probability(No): 0.2018\n",
      "âœ… brush_with íŒë‹¨: ë§ìŠµë‹ˆë‹¤ (True)\n",
      "Query: Is the person catch bicyle in this image? Answer with Yes or No.\n",
      "Action Check: catch\n",
      "probability(Yes): 0.8355\n",
      "probability(No): 0.1645\n",
      "âœ… catch íŒë‹¨: ë§ìŠµë‹ˆë‹¤ (True)\n",
      "Query: Is the person cut_with bicyle in this image? Answer with Yes or No.\n",
      "Action Check: cut_with\n",
      "probability(Yes): 0.9325\n",
      "probability(No): 0.0675\n",
      "âœ… cut_with íŒë‹¨: ë§ìŠµë‹ˆë‹¤ (True)\n",
      "Query: Is the person drink_with bicyle in this image? Answer with Yes or No.\n",
      "Action Check: drink_with\n",
      "probability(Yes): 0.4378\n",
      "probability(No): 0.5622\n",
      "âŒ {action_text}  íŒë‹¨: ì•„ë‹™ë‹ˆë‹¤ (False)\n",
      "Query: Is the person hit bicyle in this image? Answer with Yes or No.\n",
      "Action Check: hit\n",
      "probability(Yes): 0.9325\n",
      "probability(No): 0.0675\n",
      "âœ… hit íŒë‹¨: ë§ìŠµë‹ˆë‹¤ (True)\n",
      "Query: Is the person jump bicyle in this image? Answer with Yes or No.\n",
      "Action Check: jump\n",
      "probability(Yes): 0.0534\n",
      "probability(No): 0.9466\n",
      "âŒ {action_text}  íŒë‹¨: ì•„ë‹™ë‹ˆë‹¤ (False)\n",
      "Query: Is the person lie_on bicyle in this image? Answer with Yes or No.\n",
      "Action Check: lie_on\n",
      "probability(Yes): 0.0675\n",
      "probability(No): 0.9325\n",
      "âŒ {action_text}  íŒë‹¨: ì•„ë‹™ë‹ˆë‹¤ (False)\n",
      "Query: Is the person look_out bicyle in this image? Answer with Yes or No.\n",
      "Action Check: look_out\n",
      "probability(Yes): 0.8520\n",
      "probability(No): 0.1480\n",
      "âœ… look_out íŒë‹¨: ë§ìŠµë‹ˆë‹¤ (True)\n",
      "Query: Is the person pack bicyle in this image? Answer with Yes or No.\n",
      "Action Check: pack\n",
      "probability(Yes): 0.9876\n",
      "probability(No): 0.0124\n",
      "âœ… pack íŒë‹¨: ë§ìŠµë‹ˆë‹¤ (True)\n",
      "Query: Is the person pick_up bicyle in this image? Answer with Yes or No.\n",
      "Action Check: pick_up\n",
      "probability(Yes): 0.0025\n",
      "probability(No): 0.9975\n",
      "âŒ {action_text}  íŒë‹¨: ì•„ë‹™ë‹ˆë‹¤ (False)\n",
      "Query: Is the person push bicyle in this image? Answer with Yes or No.\n",
      "Action Check: push\n",
      "probability(Yes): 0.7058\n",
      "probability(No): 0.2942\n",
      "âœ… push íŒë‹¨: ë§ìŠµë‹ˆë‹¤ (True)\n",
      "Query: Is the person sip bicyle in this image? Answer with Yes or No.\n",
      "Action Check: sip\n",
      "probability(Yes): 0.9627\n",
      "probability(No): 0.0373\n",
      "âœ… sip íŒë‹¨: ë§ìŠµë‹ˆë‹¤ (True)\n",
      "Query: Is the person stick bicyle in this image? Answer with Yes or No.\n",
      "Action Check: stick\n",
      "probability(Yes): 0.5000\n",
      "probability(No): 0.5000\n",
      "âŒ {action_text}  íŒë‹¨: ì•„ë‹™ë‹ˆë‹¤ (False)\n",
      "Query: Is the person swing bicyle in this image? Answer with Yes or No.\n",
      "Action Check: swing\n",
      "probability(Yes): 0.3486\n",
      "probability(No): 0.6514\n",
      "âŒ {action_text}  íŒë‹¨: ì•„ë‹™ë‹ˆë‹¤ (False)\n",
      "Query: Is the person talk_on bicyle in this image? Answer with Yes or No.\n",
      "Action Check: talk_on\n",
      "probability(Yes): 0.5927\n",
      "probability(No): 0.4073\n",
      "âœ… talk_on íŒë‹¨: ë§ìŠµë‹ˆë‹¤ (True)\n",
      "Query: Is the person throw bicyle in this image? Answer with Yes or No.\n",
      "Action Check: throw\n",
      "probability(Yes): 0.9890\n",
      "probability(No): 0.0110\n",
      "âœ… throw íŒë‹¨: ë§ìŠµë‹ˆë‹¤ (True)\n",
      "Query: Is the person wash bicyle in this image? Answer with Yes or No.\n",
      "Action Check: wash\n",
      "probability(Yes): 0.8355\n",
      "probability(No): 0.1645\n",
      "âœ… wash íŒë‹¨: ë§ìŠµë‹ˆë‹¤ (True)\n",
      "Query: Is the person boxing bicyle in this image? Answer with Yes or No.\n",
      "Action Check: boxing\n",
      "probability(Yes): 0.0373\n",
      "probability(No): 0.9627\n",
      "âŒ {action_text}  íŒë‹¨: ì•„ë‹™ë‹ˆë‹¤ (False)\n",
      "Query: Is the person carry bicyle in this image? Answer with Yes or No.\n",
      "Action Check: carry\n",
      "probability(Yes): 0.9890\n",
      "probability(No): 0.0110\n",
      "âœ… carry íŒë‹¨: ë§ìŠµë‹ˆë‹¤ (True)\n",
      "Query: Is the person cut bicyle in this image? Answer with Yes or No.\n",
      "Action Check: cut\n",
      "probability(Yes): 0.7982\n",
      "probability(No): 0.2018\n",
      "âœ… cut íŒë‹¨: ë§ìŠµë‹ˆë‹¤ (True)\n",
      "Query: Is the person drag bicyle in this image? Answer with Yes or No.\n",
      "Action Check: drag\n",
      "probability(Yes): 0.8670\n",
      "probability(No): 0.1330\n",
      "âœ… drag íŒë‹¨: ë§ìŠµë‹ˆë‹¤ (True)\n",
      "Query: Is the person eat bicyle in this image? Answer with Yes or No.\n",
      "Action Check: eat\n",
      "probability(Yes): 0.7773\n",
      "probability(No): 0.2227\n",
      "âœ… eat íŒë‹¨: ë§ìŠµë‹ˆë‹¤ (True)\n",
      "Query: Is the person hold bicyle in this image? Answer with Yes or No.\n",
      "Action Check: hold\n",
      "probability(Yes): 0.9985\n",
      "probability(No): 0.0015\n",
      "âœ… hold íŒë‹¨: ë§ìŠµë‹ˆë‹¤ (True)\n",
      "Query: Is the person kick bicyle in this image? Answer with Yes or No.\n",
      "Action Check: kick\n",
      "probability(Yes): 0.6792\n",
      "probability(No): 0.3208\n",
      "âœ… kick íŒë‹¨: ë§ìŠµë‹ˆë‹¤ (True)\n",
      "Query: Is the person lift bicyle in this image? Answer with Yes or No.\n",
      "Action Check: lift\n",
      "probability(Yes): 0.7058\n",
      "probability(No): 0.2942\n",
      "âœ… lift íŒë‹¨: ë§ìŠµë‹ˆë‹¤ (True)\n",
      "Query: Is the person open bicyle in this image? Answer with Yes or No.\n",
      "Action Check: open\n",
      "probability(Yes): 0.5000\n",
      "probability(No): 0.5000\n",
      "âŒ {action_text}  íŒë‹¨: ì•„ë‹™ë‹ˆë‹¤ (False)\n",
      "Query: Is the person peel bicyle in this image? Answer with Yes or No.\n",
      "Action Check: peel\n",
      "probability(Yes): 0.9669\n",
      "probability(No): 0.0331\n",
      "âœ… peel íŒë‹¨: ë§ìŠµë‹ˆë‹¤ (True)\n",
      "Query: Is the person pour bicyle in this image? Answer with Yes or No.\n",
      "Action Check: pour\n",
      "probability(Yes): 0.9890\n",
      "probability(No): 0.0110\n",
      "âœ… pour íŒë‹¨: ë§ìŠµë‹ˆë‹¤ (True)\n",
      "Query: Is the person ride bicyle in this image? Answer with Yes or No.\n",
      "Action Check: ride\n",
      "probability(Yes): 0.9972\n",
      "probability(No): 0.0028\n",
      "âœ… ride íŒë‹¨: ë§ìŠµë‹ˆë‹¤ (True)\n",
      "Query: Is the person sit_on bicyle in this image? Answer with Yes or No.\n",
      "Action Check: sit_on\n",
      "probability(Yes): 0.0759\n",
      "probability(No): 0.9241\n",
      "âŒ {action_text}  íŒë‹¨: ì•„ë‹™ë‹ˆë‹¤ (False)\n",
      "Query: Is the person stir bicyle in this image? Answer with Yes or No.\n",
      "Action Check: stir\n",
      "probability(Yes): 0.9669\n",
      "probability(No): 0.0331\n",
      "âœ… stir íŒë‹¨: ë§ìŠµë‹ˆë‹¤ (True)\n",
      "Query: Is the person take_photo bicyle in this image? Answer with Yes or No.\n",
      "Action Check: take_photo\n",
      "probability(Yes): 0.3208\n",
      "probability(No): 0.6792\n",
      "âŒ {action_text}  íŒë‹¨: ì•„ë‹™ë‹ˆë‹¤ (False)\n",
      "Query: Is the person text_on bicyle in this image? Answer with Yes or No.\n",
      "Action Check: text_on\n",
      "probability(Yes): 0.0953\n",
      "probability(No): 0.9047\n",
      "âŒ {action_text}  íŒë‹¨: ì•„ë‹™ë‹ˆë‹¤ (False)\n",
      "Query: Is the person type_on bicyle in this image? Answer with Yes or No.\n",
      "Action Check: type_on\n",
      "probability(Yes): 0.9047\n",
      "probability(No): 0.0953\n",
      "âœ… type_on íŒë‹¨: ë§ìŠµë‹ˆë‹¤ (True)\n",
      "Query: Is the person write bicyle in this image? Answer with Yes or No.\n",
      "Action Check: write\n",
      "probability(Yes): 0.9859\n",
      "probability(No): 0.0141\n",
      "âœ… write íŒë‹¨: ë§ìŠµë‹ˆë‹¤ (True)\n",
      "\n",
      "ğŸ† Top 3 Predictions:\n",
      "Checking hold... Probability: 99.85%\n",
      "Checking ride... Probability: 99.72%\n",
      "Checking throw... Probability: 98.90%\n"
     ]
    }
   ],
   "source": [
    "AGD20K_VERBS = [\n",
    "    \"beat\", \"brush_with\", \"catch\", \"cut_with\", \"drink_with\", \"hit\", \"jump\", \"lie_on\", \"look_out\", \"pack\",\n",
    "    \"pick_up\", \"push\", \"sip\", \"stick\", \"swing\", \"talk_on\", \"throw\", \"wash\",\n",
    "    \"boxing\", \"carry\", \"cut\", \"drag\", \"eat\", \"hold\", \"kick\", \"lift\", \"open\", \"peel\", \"pour\", \"ride\",\n",
    "    \"sit_on\", \"stir\", \"take_photo\", \"text_on\", \"type_on\", \"write\"\n",
    "]\n",
    "results = {}\n",
    "\n",
    "for action in AGD20K_VERBS:\n",
    "    # action í…ìŠ¤íŠ¸ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ë³€í˜• (í•„ìš”ì‹œ)\n",
    "    # ì˜ˆ: \"jumping\", \"holding a cup\" ë“± í˜„ì¬ì§„í–‰í˜• ê¶Œì¥\n",
    "    score = get_yes_no_score(image_path, action, target_item = 'bicyle')\n",
    "    results[action] = score\n",
    "    # print(f\"{action}: {score:.4f}\")\n",
    "\n",
    "# Top-3 ê²°ê³¼ ì¶œë ¥\n",
    "sorted_results = sorted(results.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"\\nğŸ† Top 3 Predictions:\")\n",
    "for act, prob in sorted_results[:3]:\n",
    "    print(f\"Checking {act}... Probability: {prob*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd6f9f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hold</th>\n",
       "      <td>0.998499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ride</th>\n",
       "      <td>0.997199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carry</th>\n",
       "      <td>0.989013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>throw</th>\n",
       "      <td>0.989013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pour</th>\n",
       "      <td>0.989013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pack</th>\n",
       "      <td>0.987568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>write</th>\n",
       "      <td>0.985936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stir</th>\n",
       "      <td>0.966914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peel</th>\n",
       "      <td>0.966914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sip</th>\n",
       "      <td>0.962673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beat</th>\n",
       "      <td>0.939913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cut_with</th>\n",
       "      <td>0.932453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hit</th>\n",
       "      <td>0.932453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type_on</th>\n",
       "      <td>0.904651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drag</th>\n",
       "      <td>0.867036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>look_out</th>\n",
       "      <td>0.851953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wash</th>\n",
       "      <td>0.835484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>catch</th>\n",
       "      <td>0.835484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brush_with</th>\n",
       "      <td>0.798187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cut</th>\n",
       "      <td>0.798187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eat</th>\n",
       "      <td>0.777300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>push</th>\n",
       "      <td>0.705785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lift</th>\n",
       "      <td>0.705785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kick</th>\n",
       "      <td>0.679179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>talk_on</th>\n",
       "      <td>0.592667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open</th>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stick</th>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drink_with</th>\n",
       "      <td>0.437824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swing</th>\n",
       "      <td>0.348645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>take_photo</th>\n",
       "      <td>0.320821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_on</th>\n",
       "      <td>0.095349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sit_on</th>\n",
       "      <td>0.075858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lie_on</th>\n",
       "      <td>0.067547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jump</th>\n",
       "      <td>0.053403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boxing</th>\n",
       "      <td>0.037327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pick_up</th>\n",
       "      <td>0.002473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0\n",
       "hold        0.998499\n",
       "ride        0.997199\n",
       "carry       0.989013\n",
       "throw       0.989013\n",
       "pour        0.989013\n",
       "pack        0.987568\n",
       "write       0.985936\n",
       "stir        0.966914\n",
       "peel        0.966914\n",
       "sip         0.962673\n",
       "beat        0.939913\n",
       "cut_with    0.932453\n",
       "hit         0.932453\n",
       "type_on     0.904651\n",
       "drag        0.867036\n",
       "look_out    0.851953\n",
       "wash        0.835484\n",
       "catch       0.835484\n",
       "brush_with  0.798187\n",
       "cut         0.798187\n",
       "eat         0.777300\n",
       "push        0.705785\n",
       "lift        0.705785\n",
       "kick        0.679179\n",
       "talk_on     0.592667\n",
       "open        0.500000\n",
       "stick       0.500000\n",
       "drink_with  0.437824\n",
       "swing       0.348645\n",
       "take_photo  0.320821\n",
       "text_on     0.095349\n",
       "sit_on      0.075858\n",
       "lie_on      0.067547\n",
       "jump        0.053403\n",
       "boxing      0.037327\n",
       "pick_up     0.002473"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([results]).T.sort_values(by=0,ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
